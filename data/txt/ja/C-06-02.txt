強化学習に基づくデータ選別を通した問題横断型小論文自動採点の精度向上

柴田拓海

1

宇都雅輝

11

電気通信大学大学院



{shibata,uto}@ai.lab.uec.ac.jp



概要

近年、小論文自動採点タスクの一つとして問題横断型自動採点が注目されている。
しかし従来の問題横断型自動採点では様々な問題に対する採点済み小論文データを全て訓練に利用するため、目的の問題の自動採点に悪影響を与えうるデータまで訓練に利用される可能性がある。
この問題を解決するために本研究では、訓練データの価値を評価し、モデル学習に悪影響を及ぼす可能性のあるデータを除外することでその採点精度を向上させる手法を提案する。


1 はじめに

近年、小論文試験の採点コストの削減や採点の一貫性を担保するアプローチの一つとして、小論文自動採点（automated essay scoring：AES）が注目されている[1, 2]。
小論文自動採点手法は問題固有型と問題横断型に大別できる。
問題固有型自動採点手法は、目的の小論文問題に対する採点済み小論文データを用いて、その問題専用の自動採点モデルを構築する手法である。
代表的な手法としては、小論文から文章長や文法誤り率などの特徴量を抽出し、これらの特徴量を用いて機械学習モデルを訓練する特徴量ベースの手法や、深層学習を用いて小論文の単語系列を入力として得点を予測する深層学習ベースの手法が知られている（e.g.,[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])。
近年では、BERT（bidirectional encoder representationsfrom transformers）[17]や DeBERTa（decoding-enhancedBERT with disentangled attention） [18]などの Trans-former エンコーダをベースにした事前学習済みの深層学習モデルを用いた自動採点モデルが高精度を達成している（e.g., [19, 20])。
問題固有型自動採点モデルは、訓練データと同一の問題に対しては高い性能を示すが、特定の問題に対して構築されたモデルを他の問題の自動採点に直接流用しても高い性能が得られるとは限らない。
そのため、一般に問題固有型自動採点で高精度を実現するためには、問題ごとに採点済み小論文データを収集してモデル訓練を行う必要がある。
しかし、問題ごとに十分な数の採点済み小論文データを収集するには大きなコストを要する。
このような問題ごとのモデル訓練のコストを軽減する方法として問題横断型自動採点手法が近年注目を集めている。
問題横断型自動採点手法では採点したい問題に対する自動採点モデルを構築するために、その問題以外の多数の問題（以下、元問題群と呼ぶ）に対応する採点済み小論文データも訓練データとして利用することで、自動採点の精度向上を目指す。
このアプローチでは目的の問題に対応する採点済み小論文データがない、あるいは数が限られている場合に目的の問題に対する自動採点モデルの精度向上が期待できる。
従来の問題横断型自動採点手法は、元問題群の全ての小論文データを学習に利用する。
しかし、元問題群に関するデータの中には、目的の問題に対する自動採点モデルの構築に悪影響を与えるデータが存在する可能性がある。
そのため、そのようなデータを選択して除外することができれば、より高精度な問題横断型自動採点が実現できると期待される。
そこで本研究では、DVRL（data valuation usingreinforcement learning） [21]と呼ばれる強化学習を用いたデータ価値推定手法を応用した問題横断型自動採点手法を提案する。
DVRL は、目的のタスクの性能向上に対する各データの寄与の度合いをデータ価値として推定する手法である。
本研究では DVRL を応用して、元問題群に関する採点済み小論文データのうち、目的の問題の自動採点の精度向上に寄与するデータに高いデータ価値を与え、精度に悪影響を与えるデータに低いデータ価値を与えるデータ価値推定器を構築する。
提案手法では、これにより得ら

図 1 DVRL の概念図れたデータ価値推定器に基づいて元問題群に関する採点済み小論文データを取捨選択して自動採点モデルを訓練することで、目的の問題に対する採点精度の向上を目指す。
本研究では小論文自動採点のベンチマークデータセットを用いて提案手法の有効性を評価する。


2 提案手法

本研究では、元問題群の各問題 𝑘（𝑘 = 1, 2, . . . , 𝐾）に関する採点済み小論文データD𝑠𝑘= {(𝑥𝑠𝑘𝑖, 𝑦𝑠𝑘𝑖)}𝑁𝑠𝑘𝑖=1と、目的の問題に対する少量の採点済み小論文データD𝑡= {(𝑥𝑡𝑖, 𝑦𝑡𝑖)}𝑁𝑡𝑖=1を利用する。
ここで、𝐾 は元問題群の総数、𝑥𝑠𝑘𝑖と 𝑥𝑡𝑖はそれぞれ元問題群の問題 𝑘と目的の問題における 𝑖 番目の小論文、𝑦𝑠𝑘𝑖と 𝑦𝑡𝑖はそれらに対応する得点、𝑁𝑠𝑘と 𝑁𝑡はそれぞれ元問題群の問題 𝑘 と目的の問題の小論文の総数である。
本研究の主たるアイディアは、元問題群の採点済み小論文データD𝑠=∪𝐾𝑘=1D𝑠𝑘から有益な部分集合データを抽出し、目的の問題における未採点小論文データに対する得点を高精度に予測できる自動採点モデルを構築することにある。
提案手法では、これを実現するために、以下に示す二つの手順を実行する。
1) DVRL を用いて元問題群の各小論文データに対してデータ価値を割り当てるデータ価値推定器を学習する。
2)データ価値推定器によって高価値が割り当てられた元問題群の小論文のみを用いて目的の問題の自動採点モデルを学習する。
以降の節で、各手順の詳細を説明する。



2.1 DVRL を用いたデータ価値推定

図 1 に DVRL を用いたデータ価値推定の概念図を示す。
この手法は、元問題群の採点済み小論文データの価値を推定するデータ価値推定器 𝑓𝜽と、小論文の予測得点を出力する予測器 𝑔𝝓の二つのモデルから構成される。
ここで 𝜽 と 𝝓 はそれぞれデータ価値推定器と予測器のモデルパラメータを表す。
なお、DVRL 全体の計算コストを抑えるため、これらのモデルには軽量なものが採用される。
図中の 𝒉𝑠𝑘𝑖と 𝒉𝑡𝑖は、それぞれ 𝑥𝑠𝑘𝑖と 𝑥𝑡𝑖に対応する特徴ベクトルを表す。
特徴ベクトルとしては、BERT や DeBERTa に基づく文章分散表現ベクトルや人手で設計された特徴ベクトル、それらの組み合わせなどが利用できる。
DVRL の学習過程は、次の最適化問題として定式化される[21]。
max𝜽𝑅𝜽(𝝓∗,P𝑡) s.t.𝝓∗= arg min𝝓𝔼(𝒉𝑠,𝑦𝑠)∼P𝑠[𝑓𝜽(𝒉𝑠, 𝑦𝑠)L(𝑔𝝓(𝒉𝑠), 𝑦𝑠)]
(1)ここで、𝑅𝜽(·, ·)は報酬を表す。
これは、元問題群の採点済み小論文データD𝑠を用いて学習した予測器𝑔𝝓∗の、目的の問題の採点済み小論文データD𝑡に対する予測精度として与えられる。
また、Lは予測器の訓練時の損失関数であり、P𝑠とP𝑡は、それぞれ元問題群の小論文データと目的の問題の小論文データの生成分布を表す。
この最適化問題を解くことで、各小論文のデータ価値を推定するデータ価値推定器 𝑓𝜽が得られる。
以降でこの最適化問題の具体的な計算手順を説明する。
DVRL ではまず、元問題群の小論文ベクトル 𝒉𝑠𝑘𝑖と対応する得点 𝑦𝑠𝑘𝑖を用いて、データ 𝑥𝑠𝑘𝑖のデータ価値 𝑝𝑠𝑘𝑖∈ [0, 1]を 𝑝𝑠𝑘𝑖= 𝑓𝜽(𝒉𝑠𝑘𝑖, 𝑦𝑠𝑘𝑖)として計算する。
ここで、データ価値推定器 𝑓𝜽は六層の全結合層からなる深層ニューラルネットワークであり、出力層はシグモイド関数を活性化関数に持つ線形層である。
なお、データ価値推定器の中間層には周辺情報 𝑚𝑠𝑘𝑖が結合される。
周辺情報 𝑚𝑠𝑘𝑖とは、問題 𝑘

の
𝑖 番目の小論文のデータ価値と相関が期待される量であり、𝑚𝑠𝑘𝑖= |𝑦𝑠𝑘𝑖− 𝑔ˆ𝝓(𝒉𝑠𝑘𝑖)| と定義される。
ここで 𝑔ˆ𝝓はD𝑡を用いて事前に学習された予測器である。
このようにして得られた採択確率 𝑝𝑠𝑘𝑖を利用して 𝑥𝑠𝑘𝑖の採択可否 𝑑𝑠𝑘𝑖∈ {0, 1} を確率 𝑝𝑠𝑘𝑖のベルヌーイ分布からのサンプリングとして決定する。
ここで𝑑𝑠𝑘𝑖= 1 は問題 𝑘 の 𝑖 番目のデータが採択されたことを，𝑑𝑠𝑘𝑖= 0 は採択されなかったことを意味する。
DVRL では次に、採択された元問題群の小論文データを用いて予測器 𝑔𝝓を学習する。
予測器 𝑔𝝓はシグモイド関数を活性化関数とする線形出力層を持つ多層パーセプトロン（multi-layer perceptron：MLP）として構成される。
予測器の学習に用いる重み付き損失関数は、Lpred=1|D𝑠selected|∑𝐾𝑘=1∑𝑁𝑠𝑘𝑖=1𝑑𝑠𝑘𝑖·L( ˆ𝑦𝑠𝑘𝑖, 𝑦𝑠𝑘𝑖)で定義される。
ここで、D𝑠selected= {(𝑥𝑠𝑘𝑖, 𝑦𝑠𝑘𝑖) | 𝑑𝑠𝑘𝑖= 1} は採択された元問題群データの集合、ˆ𝑦𝑠𝑘𝑖は元問題群の問題 𝑘における 𝑖 番目の小論文に対する予測器による予測得点である。
損失関数Lとしては、予測得点 ˆ𝑦𝑠𝑘𝑖と真の得点 𝑦𝑠𝑘𝑖の平均二乗誤差を使用する。
なお予測器 𝑔𝝓は出力層にシグモイド関数を用いているため、予測得点は[0, 1]の範囲の値になる。
そのため観測得点 𝑦𝑠𝑘𝑖も[0, 1]の範囲に正規化する必要がある。
そして学習された予測器 𝑔𝝓∗の得点予測性能を目的の問題の小論文データD𝑡を利用して評価する。
予測性能の指標としては、自動採点の研究で一般に利用される二次重み付きカッパ係数（quadratic weighted kappa：QWK）を用いる。
この値を強化学習の報酬 𝑅𝜽= 𝑄𝑊 𝐾 ({𝑔𝝓∗(𝒉𝑡𝑖), 𝑦𝑡𝑖}𝑁𝑡𝑖=1)として採用し、データ価値推定器 𝑓𝜽のパラメータ 𝜽を更新する。
パラメータの更新には、強化学習アルゴリズムの一つである REINFORCE アルゴリズム[22]を用いる。
REINFORCE アルゴリズムを適用するには、報酬 𝑅𝜽の 𝜽 による勾配が必要であるが、この勾配は ∇𝜽𝑅𝜽= 𝑅𝜽· ∇𝜽log 𝑃({𝑑𝑠𝑘𝑖} | 𝜽)で求められる[21]。
ここで、𝑃({𝑑𝑠𝑘𝑖} | 𝜽)は、パラメータ 𝜽 を所与とした採否結果データの同時確率であり、∏𝐾𝑘=1∏𝑁𝑠𝑘𝑖=1(𝑝𝑠𝑘𝑖)𝑑𝑠𝑘𝑖(1 − 𝑝𝑠𝑘𝑖)1−𝑑𝑠𝑘𝑖=∏𝐾𝑘=1∏𝑁𝑠𝑘𝑖=1( 𝑓𝜽(𝒉𝑠𝑘𝑖, 𝑦𝑠𝑘𝑖))𝑑𝑠𝑘𝑖(1 − 𝑓𝜽(𝒉𝑠𝑘𝑖, 𝑦𝑠𝑘𝑖))1−𝑑𝑠𝑘𝑖で求められる。
この勾配を用いて、パラメータ 𝜽 を勾配上昇法により 𝜽 ← 𝜽 + 𝛼∇𝜽𝑅𝜽と更新する。
ここで，𝛼 は学習率を表し、本研究では 1 × 10−3に設定している。
パラメータ更新の最適化手法としては、Adam [23]を用いる。
最後に、これまで説明したステップを繰り返すことで式(1)に則したデータ価値推定器 𝑓𝜽を学習する。

2.2 推定されたデータ価値に基づく任意



の自動採点モデルの学習

本研究では、前節の手続きで得られたデータ価値推定器 𝑓𝜽を用いて、元問題群のデータの選別を行い、選ばれたデータを用いて目的の問題に対する自動採点モデルを訓練する。
しかし、この手続きでは、データ価値の推定値に基づいてどの程度の数のデータを選択すべきかが自明ではない。
そこで本研究では、先行研究[21]と同様に以下の手順でデータ選別を行う。
1)算出されたデータ価値に基づいて元問題群の小論文を降順に並び替える。
2)データ価値の上位 10%から 100%まで 10%刻みでデータを採用し、それぞれのデータから自動採点モデルを構築する．3)構築された10パタンのモデルについてD𝑡に対する性能を平均二乗誤差で評価する。
損失の値が最も低いモデルを最適なモデルとして選択し未採点の目的の問題の小論文に対して得点予測を行う。

3 実験

本研究では、提案手法の有効性を評価するために、実データを用いて評価実験を行った。
実データとしては Automated Student Assessment Prize（ASAP）と呼ばれるデータセットを使用した。
ASAP は多くの自動採点研究においてベンチマークデータセットとして利用されており、八種類の小論文問題に対する受検者の答案が合計 12,978 個と、その答案に対する得点が与えられている。



3.1 提案手法の性能評価

本研究では、従来の問題横断型自動採点研究[5, 8]と同様に問題単位の交差検証法を用いて提案手法の得点予測精度の評価実験を行った。
問題単位の交差検証法では、一つの問題を目的の問題として設定し、残りの全ての問題を学習用の元問題群として使用する。
この手順を全ての問題について順に繰り返し、性能評価を行った。
また、提案手法では目的の問題からサンプリングされた少数の採点済み小論文データD𝑡が必要となる。
本実験では、D𝑡のデータ数を 30 と設定し、DeBERTa-v3-large [24]から得られた各小論文の分散表現ベクトルのユークリッド距離の和が最大となるようなデータ集合を選択した。
本実験では BERT，Llama-2-7B [25]，PAES（promptagnostic essay scorer） [5]，PMAES（prompt-mappingcontrastive learning for cross-prompt AES） [8]の四つ

表 1 得点予測精度の評価実験の結果モデル設定問題 1 問題 2 問題 3 問題 4 問題 5 問題 6 問題 7 問題 8 平均BERT全データ利用 0.513 0.541 0.578 0.582 0.637 0.600 0.529 0.431 0.551提案 0.640 0.581 0.684 0.631 0.683 0.636 0.597 0.628 0.635Llama-2-7B全データ利用 0.481 0.556 0.545 0.610 0.690 0.582 0.583 0.424 0.559提案 0.530 0.522 0.661 0.589 0.704 0.574 0.686 0.558 0.603PAES全データ利用 0.654 0.583 0.612 0.605 0.730 0.565 0.706 0.542 0.625提案 0.787 0.600 0.588 0.588 0.747 0.573 0.737 0.560 0.648PMAES全データ利用 0.799 0.634 0.591 0.589 0.716 0.567 0.658 0.366 0.615提案 0.800 0.627 0.559 0.606 0.749 0.613 0.664 0.523 0.643の代表的な自動採点モデルに対して、提案手法の有効性を評価した。
DVRL におけるデータ価値推定器と予測器の入力に使用する特徴量および予測器の構造は、モデルの種類によって変更した。
BERT とLlama-2-7B はセマンティックな特徴を考慮するモデルであるため、これらのモデルを利用する際には、DVRL の特徴量として DeBERTa-v3-large の分散表現ベクトルを用い、予測器として MLP を使用した。
他方で、PAES と PMAES は元々問題横断型として設計されたモデルであり、Ridley ら[5]が提案した問題非依存の特徴ベクトルFを入力に利用している。
そこで、これらのモデルに対しては、DVRL 内の特徴量も特徴ベクトルFを用い、予測器としてFeatures model（Ridley ら[5]が提案した特徴ベクトルFを入力とするロジスティック回帰モデル）を使用した。
実験は「全データ利用」と「提案」の二つの設定で行った。
まず、「全データ利用」は、自動採点モデルを全ての元問題群のデータを用いて学習する設定であり、提案手法において全ての小論文が採択された場合と等しい。
「提案」は提案手法に従って自動採点モデルを学習する設定である。
各設定における自動採点モデルの予測精度は、D𝑡として利用した 30 個のデータを除いた目的の問題の小論文データに対して得点予測を行い、QWK で評価した。
表1 に実験結果を示す。
表では各モデルに対し、問題ごとに精度が高い設定に対応する数値を太字で表現している。
表から提案手法の平均予測精度は全てのモデルにおいて「全データ利用」の設定を上回っていることが読み取れる。
この結果は、提案手法が自動採点モデルの予測精度を向上させるために有効であることを示しているといえる。

3.2 推定されたデータ価値の妥当性評価

本節では、提案手法により推定されたデータ価値が適切に機能しているかを評価する。
評価のために、上位または下位 𝑛%のデータ価値を持つ小論文図 2 問題 1 における除外した小論文データの割合とQWK の関係を除外した元問題群の小論文データを用いて学習した自動採点モデルの予測精度を算出した。
ここで除外率 𝑛 は 0%から 90%まで 10%刻みで変更した。
本実験では前節の実験で最も高い性能を示した PAESに対して実験を行った。
問題 1 に対する実験結果を図 2 に示した。
横軸は除外された小論文の割合、縦軸は QWK を表す。
青色のグラフはデータ価値の最も高い小論文から順に除外した場合の QWK の変化、橙色のグラフはデータ価値の最も低い小論文から順に除外した場合のQWK の変化を表している。
図から、データ価値の低い小論文を除外すると QWK が増加する傾向があり、反対にデータ価値の高い小論文を除外するとQWK が減少する傾向が見られる。
これらの結果から、提案手法は適切にデータ価値を推定していることが示唆される。


4 おわりに

本研究では、目的の問題に対する自動採点モデルの精度向上に効果的な元問題群の小論文データを選択するために、データ価値推定法を活用した問題横断型自動採点手法を提案した。
実データを用いた実験により、従来の様々な自動採点モデルと比較して、目的の問題における採点性能が向上することを確認した。
今後は提案手法により採択されるデータの傾向や特性に関する詳細な分析を行いたい。



謝辞

本研究は JSPS 科研費 23K17585，23K20727，24H00739 の助成を受けたものです。

参考文献


[1] Masaki Uto. A review of deep-neural automated essayscoring models. Behaviormetrika, Vol. 48, No. 2, pp.1–26, 2021.
[2] Takumi Shibata and Masaki Uto. Analytic automated es-say scoring based on deep neural networks integratingmultidimensional item response theory. In Proceedingsof the 29th International Conference on Computa-tional Linguistics, pp. 2917–2926, 2022.
[3] Yigal Attali and Jill Burstein. Automated essay scoringwith e-rater ® v.2. The Journal of Technology, Learn-ing and Assessment, Vol. 4, No. 3, pp. 1–30, 2006.
[4] Masaki Uto and Masashi Okano. Learning automatedessay scoring models using item-response-theory-basedscores to decrease dﬀects of rater biases. IEEE Trans-actions on Learning Technologies, Vol. 14, No. 6, pp.763–776, 2021.
[5] Robert Ridley, Liang He, Xinyu Dai, Shujian Huang, andJiajun Chen. Prompt agnostic essay scorer: A domaingeneralization approach to cross-prompt automated essayscoring. arXiv, 2020.
[6] Fei Dong, Yue Zhang, and Jie Yang. Attention-based re-current convolutional neural network for automatic essayscoring. In Proceedings of the 21st Conference onComputational Natural Language Learning, pp. 153–162, 2017.
[7] Cancan Jin, Ben He, Kai Hui, and Le Sun. TDNN: A two-stage deep neural network for prompt-independent auto-mated essay scoring. In Proceedings of the 56th An-nual Meeting of the Association for ComputationalLinguistics, pp. 1088–1097, 2018.
[8] Yuan Chen and Xia Li. PMAES: Prompt-mapping con-trastive lear ning for cross-prompt automated essay scor-ing. In Proceedings of the 61st Annual Meeting ofthe Association for Computational Linguistics, pp.1489–1503, 2023.
[9] Xia Li, Minping Chen, and Jian-Yun Nie. SEDNN: Sharedand enhanced deep neural network model for cross-promptautomated essay scoring. Knowledge-Based Systems,Vol. 210, p. 106491, 2020.
[10] Misato Yamaura, Itsuki Fukuda, and Masaki Uto. Neuralautomated essay scoring considering logical structure. InProceedings of the 24th Artiﬁcial Intelligence inEducation, pp. 267–278, 2023.
[11] Pedro Uria Rodriguez, Amir Jafari, and Christopher M.Ormerod. Language models and automated essay scor ing.arXiv, 2019.
[12] Masaki Uto and Yuto Takahashi. Neural automated es-say scoring for improved conﬁdence estimation and scoreprediction through integrated classiﬁcation and regression.In Proceedings of the 25th Artiﬁcial Intelligence inEducation, pp. 444–451, 2024.
[13] Masaki Uto and Kota Aramaki. Linking essay-writingtests using many-facet models and neural automated essayscoring. Behavior Research Methods, Vol. 56, No. 8,pp. 8450–8479, 2024.
[14] Kota Aramaki and Masaki Uto. Collaborative essay eval-uation with human and neural graders using item responsetheory under a nonequivalent groups design. In Proceed-ings of the 25th International Conference on Arti-ﬁcial Intelligence in Education., pp. 79–87, 2024.
[15] Masaki Uto, Itsuki Aomi, Emiko Tsutsumi, and MaomiUeno. Integration of prediction scores from various au-tomated essay scor ing models using item response the-ory. IEEE Transactions on Learning Technologies,Vol. 16, No. 6, pp. 983–1000, 2023.
[16] Takumi Shibata and Masaki Uto. Enhancing cross-promptautomated essay scor ing by selecting training data basedon reinforcement learning. In Proceedings of the FirstWorkshop on Automated Evaluation of Learningand Assessment Content, International Conferenceon Artiﬁcial Intelligence in Education, 2024.
[17] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and KristinaToutanova. BERT: Pre-training of deep bidirectional trans-formers for language understanding. In Proceedings ofthe 2019 Conference of the North American Chap-ter of the Association for Computational Linguis-tics: Human Language Technologies, pp. 4171–4186,2019.
[18] Pengcheng He, Xiaodong Liu, Jianfeng Gao, and WeizhuChen. DeBERTa: Decoding-enhanced BERT with disen-tangled attention. arXiv, 2021.
[19] Ruosong Yang, Jiannong Cao, Zhiyuan Wen, YouzhengWu, and Xiaodong He. Enhancing automated essay scor-ing performance via ﬁne-tuning pre-trained language mod-els with combination of reg ression and ranking. In Find-ings of the Association for Computational Linguis-tics, pp. 1560–1569, 2020.
[20] Yongjie Wang, Chuang Wang, Ruobing Li, and Hui Lin.On the use of Bert for automated essay scoring: Jointlearning of multi-scale essay representation. In Proceed-ings of the 2022 Conference of the North AmericanChapter of the Association for Computational Lin-guistics: Human Language Technologies, pp. 3416–3425, 2022.
[21] Jinsung Yoon, Sercan Arik, and Tomas Pﬁster. Data valua-tion using reinforcement learning. In Proceedings of the37th International Conference on Machine Learn-ing, Vol. 119, pp. 10842–10851, 2020.
[22] Ronald J Williams. Simple statistical gradient-followingalgorithms for connectionist reinforcement learning. Ma-chine learning, Vol. 8, pp. 229–256, 1992.
[23] Diederik P. Kingma and Jimmy Ba. Adam: A method forstochastic optimization. arXiv, 2017.
[24] Pengcheng He, Jianfeng Gao, and Weizhu Chen. De-BERTaV3: Improving DeBERTa using ELECTRA-stylepre-training with gradient-disentangled embedding shar-ing. arXiv, 2021.
[25] Hugo Touvron, Louis Martin, Kevin Stone, et al. Llama 2:Open foundation and ﬁne-tuned chat models. arXiv, 2023.