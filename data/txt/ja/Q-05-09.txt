自然言語での異常解釈：LLM を用いた AI 説明モデルの提案

山科 勇輔

1

須賀 圭一

1

白井 祐典

1

市川 佳彦

11

株式会社 Insight Edge



{yusuke.yamashina, keichi.suga, yusuke.shirai, yoshihiko.ichikawa}@insightedge.jp



概要

本研究では、画像異常検モデルと大規模言語モデル（LLM）と組み合わせることで、より解釈しやすくする新しいアプローチを提案する。
異常検知は、製造業や医療分野で不可欠であり、迅速かつ正確な判断が求められるが、その出力が抽象的で理解しづらいことがある。
そこで画像処理アルゴリズムによって検知された異常を、LLM を用いて自然言語で説明する言語駆動型説明可能 AI（Language-DrivenExplainable AI）を提案し、異常検知結果の信頼性と透明性の向上を図るまた、その出力が実業務に有用であるかも検証する。


1 はじめに

近年、深層学習技術の進展に伴い、画像認識における異常検知の精度は飛躍的に向上している。
特に製造業や医療分野において、製品の欠陥検出や病変の早期発見など、様々な応用が期待されている[1, 2]。
しかし、異常は一般的に稀な事象であるため、正常データに比べて異常データの収集に課題がある。
また、異常のパターンは多様で、明確に定義することが難しく、各異常はそれぞれ異なる特徴を持つため、一貫して検出するためのモデル設計も困難なものとなっている。
さらに、ラベリングが複雑で誤りが発生しやすく、アノテーションコストが高いことも課題となっている。
このため、異常検知の精度向上に向けた多方面での研究が引き続き行われている[3]。
また、既存の深層学習モデルはブラックボックスであることが多く、異常と判断した根拠を人間が理解することが困難なケースもあった。
このため、AI の判断に対する信頼性の担保や、さらなる性能向上のために、AI の意思決定プロセスを説明可能なものにする Explainable AI(XAI、説明可能なAI)技術[4, 5, 6]が注目されているが、XAI の手法で生成される説明がデータ分析に長けた専門家でないと解釈が難しい場合や、説明が多すぎて重要な情報が埋もれてしまったり、逆に説明が限定的で詳細に欠けることがあり、適切な情報量のバランスを取ることが難しいといった課題がある。
一方で、近年の LLM の発展は XAI の可能性も大幅にひろがっている。
例えば、画像キャプション生成タスク[7]のように、画像に対する異常検知結果を LLM の入力として説明文を生成することで、画像内の異常の理由を人間が理解しやすく自然な言葉で説明することが可能となる。
さらには、異常検知結果が誤っていた場合にもその間違いを正すことで異常検知精度の向上や、異常の種類や発生箇所から発生要因をフィードバックすることで異常検知後の作業の優先順位なども指示することが期待できる。
本研究では、画像に対する異常検知結果を LLMへのインプットとすることで説明性を付与する言語駆動型説明可能 AI（Language-Driven XAI）を提案する。
各種画像に対する異常検知結果（２値分類、クラス分類、セグメンテーション、物体検知）に対してキャプション生成を行い、正確性や詳細度、異常のバリエーションに対するキャプションの柔軟性などの評価を行う。



2 関連研究



2.1 画像に対する異常検知

異常検知は、通常データセット内で稀なパターンや事象を識別する技術である。
製品の欠陥や医療画像における病変の早期発見などが含ま、多種多様な分野での重要な課題として認識されており、統計モデルや特徴量エンジニアリングに基づき、特定の指標やルールに従って異常を判断するものが提案されている[1]。
近年では深層学習を用いた手法が、従来の手法が抱える課題を克服するためのアプローチとして注目されている。
特に、Convolutional NeuralNetwork（CNN）を利用した手法は、画像データから自動的に特徴を抽出し、２値分類やクラス分類で高い異常検出精度を達成することが実証されてい

自然言語での異常解釈：LLM を用いた AI 説明モデルの提案

山科 勇輔

1

須賀 圭一

1

白井 祐典

1

市川 佳彦

11

株式会社 Insight Edge



{yusuke.yamashina, keichi.suga, yusuke.shirai, yoshihiko.ichikawa}@insightedge.jp



概要

本研究では、画像異常検モデルと大規模言語モデル（LLM）と組み合わせることで、より解釈しやすくする新しいアプローチを提案する。
異常検知は、製造業や医療分野で不可欠であり、迅速かつ正確な判断が求められるが、その出力が抽象的で理解しづらいことがある。
そこで画像処理アルゴリズムによって検知された異常を、LLM を用いて自然言語で説明する言語駆動型説明可能 AI（Language-DrivenExplainable AI）を提案し、異常検知結果の信頼性と透明性の向上を図るまた、その出力が実業務に有用であるかも検証する。


1 はじめに

近年、深層学習技術の進展に伴い、画像認識における異常検知の精度は飛躍的に向上している。
特に製造業や医療分野において、製品の欠陥検出や病変の早期発見など、様々な応用が期待されている[1, 2]。
しかし、異常は一般的に稀な事象であるため、正常データに比べて異常データの収集に課題がある。
また、異常のパターンは多様で、明確に定義することが難しく、各異常はそれぞれ異なる特徴を持つため、一貫して検出するためのモデル設計も困難なものとなっている。
さらに、ラベリングが複雑で誤りが発生しやすく、アノテーションコストが高いことも課題となっている。
このため、異常検知の精度向上に向けた多方面での研究が引き続き行われている[3]。
また、既存の深層学習モデルはブラックボックスであることが多く、異常と判断した根拠を人間が理解することが困難なケースもあった。
このため、AI の判断に対する信頼性の担保や、さらなる性能向上のために、AI の意思決定プロセスを説明可能なものにする Explainable AI(XAI、説明可能なAI)技術[4, 5, 6]が注目されているが、XAI の手法で生成される説明がデータ分析に長けた専門家でないと解釈が難しい場合や、説明が多すぎて重要な情報が埋もれてしまったり、逆に説明が限定的で詳細に欠けることがあり、適切な情報量のバランスを取ることが難しいといった課題がある。
一方で、近年の LLM の発展は XAI の可能性も大幅にひろがっている。
例えば、画像キャプション生成タスク[7]のように、画像に対する異常検知結果を LLM の入力として説明文を生成することで、画像内の異常の理由を人間が理解しやすく自然な言葉で説明することが可能となる。
さらには、異常検知結果が誤っていた場合にもその間違いを正すことで異常検知精度の向上や、異常の種類や発生箇所から発生要因をフィードバックすることで異常検知後の作業の優先順位なども指示することが期待できる。
本研究では、画像に対する異常検知結果を LLMへのインプットとすることで説明性を付与する言語駆動型説明可能 AI（Language-Driven XAI）を提案する。
各種画像に対する異常検知結果（２値分類、クラス分類、セグメンテーション、物体検知）に対してキャプション生成を行い、正確性や詳細度、異常のバリエーションに対するキャプションの柔軟性などの評価を行う。



2 関連研究



2.1 画像に対する異常検知

異常検知は、通常データセット内で稀なパターンや事象を識別する技術である。
製品の欠陥や医療画像における病変の早期発見などが含ま、多種多様な分野での重要な課題として認識されており、統計モデルや特徴量エンジニアリングに基づき、特定の指標やルールに従って異常を判断するものが提案されている[1]。
近年では深層学習を用いた手法が、従来の手法が抱える課題を克服するためのアプローチとして注目されている。
特に、Convolutional NeuralNetwork（CNN）を利用した手法は、画像データから自動的に特徴を抽出し、２値分類やクラス分類で高い異常検出精度を達成することが実証されている。
また、ImageNet などの大規模な画像データセットで事前学習されたモデルを使用して、特徴を抽出した後、複数の層の特徴を結合してピクセルレベルで異常検知を行う PaDiM[8]や PatchCore[9]なども提案されている。
他にも YOLO[10]などの物体検知を用いた手法も提案されている。

2.2 説明可能な AI

XAI は、AI モデルの決定理由を人間が理解できる形で説明することを目指す技術である。
例えば、医療診断システムでは、XAI が診断の根拠を明示することで、医師がその判断を信用することを助ける。
しかし、生成された説明が専門外の人には難解であったり、説明が冗長で重要な情報が埋もれてしまうといった課題も存在する。
特に画像処理においては、モデルがどの特徴（例えば、ピクセル）に注目しているかを視覚的に示す手法が重要であり、代表的な手法として、特徴マップを用いる Grad-CAM[11]や LPR[12]が提案されている。
また、LIME[4]は、画像の特定の部分やピクセルを抜き出して入力し、それに基づいた予測結果とのペアを作成し、そこからより単純なモデルに学習させることで説明力の高い結果を出力できるようにすることで、重要な特徴量を明確に取得することを可能にしている。



2.3 キャプション生成

画像キャプション生成は、画像のテキスト説明やキャプションを自動的に生成するタスクであり、近年では LLM を活用した芸術作品に対する説明の生成に関する研究もなされている[13]。



3 問題設定

図 1 に提案アプローチの概要図を示す。
異常検知モデルとしては、例えば、多クラス分類やセグメンテーション、物体検知モデルなどを想定している。
本研究では画像に対する異常検知結果に対してLLM で説明性を付与した際のキャプションの正確性、個数や位置、大きさ、形状などの詳細度、異常のバリエーションに対するキャプションの柔軟性、を評価する。
キャプションの生成結果は定量的に評価する手法もあるが、ここでは、設定した 5 段階の評価スケールを用いて人間による定性的な評価とした．「正確性」と「詳細度」は一枚一枚採点し、その平均点を算出する。
「柔軟性」は異常のバリエーションに対する評価となるので各手法での全結果を図 1 提案アプローチ手法：Language-Driven XAI表 1 異常検知モデル2 値分類 CNN多クラス分類 CNNセグメンテーション PatchCore物体検知 Grounding DINO [14]鑑みて採点した。



4 実験設定

データセットとしては、産業用異常検出のベンチマークとしてよくも用いられている MVTec AD[5]で評価する。
MVTec AD は、合計 5354 枚の画像を含む 15 のクラスで構成されており、各クラスは特定の製品に対してさまざまな欠陥タイプを持つ異常データとなっている。
本研究では、テストデータである 1725 枚を対象とした。
異常検知モデルとしては、正常か異常かの 2 値分類、欠けや印刷ミスといった複数の異常の種類を分類する多クラス分類、画像内の異常箇所をピクセルレベルで評価しヒートマップで表すセグメンテーション、画像内の異常箇所をバウンディングボックス（bbox）で示す物体検知、の 4 種類を適用し、これらの手法によるキャプション生成の結果を比較評価する。
本研究で用いた各種法のモデルを表 2 に示す。
なお、各パラメータに関しては、誤検知や検知漏れの結果に対しても評価するため、ある程度ランダムとした。
また、モデル毎に出力される結果も異なるのでモデル毎に指示文を調整している。
表 2 に指示文の例を示す。
また、LLM には gpt-4o（OpenAI）を適用した。

自然言語での異常解釈：LLM を用いた AI 説明モデルの提案

山科 勇輔

1

須賀 圭一

1

白井 祐典

1

市川 佳彦

11

株式会社 Insight Edge



{yusuke.yamashina, keichi.suga, yusuke.shirai, yoshihiko.ichikawa}@insightedge.jp



概要

本研究では、画像異常検モデルと大規模言語モデル（LLM）と組み合わせることで、より解釈しやすくする新しいアプローチを提案する。
異常検知は、製造業や医療分野で不可欠であり、迅速かつ正確な判断が求められるが、その出力が抽象的で理解しづらいことがある。
そこで画像処理アルゴリズムによって検知された異常を、LLM を用いて自然言語で説明する言語駆動型説明可能 AI（Language-DrivenExplainable AI）を提案し、異常検知結果の信頼性と透明性の向上を図るまた、その出力が実業務に有用であるかも検証する。


1 はじめに

近年、深層学習技術の進展に伴い、画像認識における異常検知の精度は飛躍的に向上している。
特に製造業や医療分野において、製品の欠陥検出や病変の早期発見など、様々な応用が期待されている[1, 2]。
しかし、異常は一般的に稀な事象であるため、正常データに比べて異常データの収集に課題がある。
また、異常のパターンは多様で、明確に定義することが難しく、各異常はそれぞれ異なる特徴を持つため、一貫して検出するためのモデル設計も困難なものとなっている。
さらに、ラベリングが複雑で誤りが発生しやすく、アノテーションコストが高いことも課題となっている。
このため、異常検知の精度向上に向けた多方面での研究が引き続き行われている[3]。
また、既存の深層学習モデルはブラックボックスであることが多く、異常と判断した根拠を人間が理解することが困難なケースもあった。
このため、AI の判断に対する信頼性の担保や、さらなる性能向上のために、AI の意思決定プロセスを説明可能なものにする Explainable AI(XAI、説明可能なAI)技術[4, 5, 6]が注目されているが、XAI の手法で生成される説明がデータ分析に長けた専門家でないと解釈が難しい場合や、説明が多すぎて重要な情報が埋もれてしまったり、逆に説明が限定的で詳細に欠けることがあり、適切な情報量のバランスを取ることが難しいといった課題がある。
一方で、近年の LLM の発展は XAI の可能性も大幅にひろがっている。
例えば、画像キャプション生成タスク[7]のように、画像に対する異常検知結果を LLM の入力として説明文を生成することで、画像内の異常の理由を人間が理解しやすく自然な言葉で説明することが可能となる。
さらには、異常検知結果が誤っていた場合にもその間違いを正すことで異常検知精度の向上や、異常の種類や発生箇所から発生要因をフィードバックすることで異常検知後の作業の優先順位なども指示することが期待できる。
本研究では、画像に対する異常検知結果を LLMへのインプットとすることで説明性を付与する言語駆動型説明可能 AI（Language-Driven XAI）を提案する。
各種画像に対する異常検知結果（２値分類、クラス分類、セグメンテーション、物体検知）に対してキャプション生成を行い、正確性や詳細度、異常のバリエーションに対するキャプションの柔軟性などの評価を行う。



2 関連研究



2.1 画像に対する異常検知

異常検知は、通常データセット内で稀なパターンや事象を識別する技術である。
製品の欠陥や医療画像における病変の早期発見などが含ま、多種多様な分野での重要な課題として認識されており、統計モデルや特徴量エンジニアリングに基づき、特定の指標やルールに従って異常を判断するものが提案されている[1]。
近年では深層学習を用いた手法が、従来の手法が抱える課題を克服するためのアプローチとして注目されている。
特に、Convolutional NeuralNetwork（CNN）を利用した手法は、画像データから自動的に特徴を抽出し、２値分類やクラス分類で高い異常検出精度を達成することが実証されている。
また、ImageNet などの大規模な画像データセットで事前学習されたモデルを使用して、特徴を抽出した後、複数の層の特徴を結合してピクセルレベルで異常検知を行う PaDiM[8]や PatchCore[9]なども提案されている。
他にも YOLO[10]などの物体検知を用いた手法も提案されている。

2.2 説明可能な AI

XAI は、AI モデルの決定理由を人間が理解できる形で説明することを目指す技術である。
例えば、医療診断システムでは、XAI が診断の根拠を明示することで、医師がその判断を信用することを助ける。
しかし、生成された説明が専門外の人には難解であったり、説明が冗長で重要な情報が埋もれてしまうといった課題も存在する。
特に画像処理においては、モデルがどの特徴（例えば、ピクセル）に注目しているかを視覚的に示す手法が重要であり、代表的な手法として、特徴マップを用いる Grad-CAM[11]や LPR[12]が提案されている。
また、LIME[4]は、画像の特定の部分やピクセルを抜き出して入力し、それに基づいた予測結果とのペアを作成し、そこからより単純なモデルに学習させることで説明力の高い結果を出力できるようにすることで、重要な特徴量を明確に取得することを可能にしている。



2.3 キャプション生成

画像キャプション生成は、画像のテキスト説明やキャプションを自動的に生成するタスクであり、近年では LLM を活用した芸術作品に対する説明の生成に関する研究もなされている[13]。



3 問題設定

図 1 に提案アプローチの概要図を示す。
異常検知モデルとしては、例えば、多クラス分類やセグメンテーション、物体検知モデルなどを想定している。
本研究では画像に対する異常検知結果に対してLLM で説明性を付与した際のキャプションの正確性、個数や位置、大きさ、形状などの詳細度、異常のバリエーションに対するキャプションの柔軟性、を評価する。
キャプションの生成結果は定量的に評価する手法もあるが、ここでは、設定した 5 段階の評価スケールを用いて人間による定性的な評価とした．「正確性」と「詳細度」は一枚一枚採点し、その平均点を算出する。
「柔軟性」は異常のバリエーションに対する評価となるので各手法での全結果を図 1 提案アプローチ手法：Language-Driven XAI表 1 異常検知モデル2 値分類 CNN多クラス分類 CNNセグメンテーション PatchCore物体検知 Grounding DINO [14]鑑みて採点した。



4 実験設定

データセットとしては、産業用異常検出のベンチマークとしてよくも用いられている MVTec AD[5]で評価する。
MVTec AD は、合計 5354 枚の画像を含む 15 のクラスで構成されており、各クラスは特定の製品に対してさまざまな欠陥タイプを持つ異常データとなっている。
本研究では、テストデータである 1725 枚を対象とした。
異常検知モデルとしては、正常か異常かの 2 値分類、欠けや印刷ミスといった複数の異常の種類を分類する多クラス分類、画像内の異常箇所をピクセルレベルで評価しヒートマップで表すセグメンテーション、画像内の異常箇所をバウンディングボックス（bbox）で示す物体検知、の 4 種類を適用し、これらの手法によるキャプション生成の結果を比較評価する。
本研究で用いた各種法のモデルを表 2 に示す。
なお、各パラメータに関しては、誤検知や検知漏れの結果に対しても評価するため、ある程度ランダムとした。
また、モデル毎に出力される結果も異なるのでモデル毎に指示文を調整している。
表 2 に指示文の例を示す。
また、LLM には gpt-4o（OpenAI）を適用した。
表 2 各モデルへの指示文例（クラス：hazelnut の場合）2 値分類これは hazelnut の画像で、異常と判断されたものです。
この画像がなぜ異常と判断されたか説明してください。
多クラス分類これは hazelnut の画像で、crackと判断されたものです。
この画像がなぜ crack と判断されたか説明してください。
セグメンテーションこれは hazelnut の画像に異常度を表すヒートマップを重ね合わせた画像です。
ヒートマップの色が濃い（赤い）ほど異常度が高いことを示します。
この画像がなぜ異常と判断されたか説明してください物体検知この画像は hazelnut の画像です。
画像内の枠内の箇所は異常と判断された箇所です。
この枠内がなぜ異常と判断されたか説明してください。



5 実験結果

二値分類図 2 に入力画像と検知結果、生成したキャプションの例を示す。
亀裂と割目から異常であることを正確に説明できており、また、保存状態にも言及することができている。
しかし位置や傷の数などについての説明はなく詳細度はやや低い。
多クラス分類図 3 に入力画像と多クラス分類結果、生成したキャプションの例を示す。
異常の種類としては squeeze が正しいが crack と分類してしまったケースだが、右側に凹みがあることを説明しており、誤判定である可能性があることも説明できている。
右側やオレンジ色の部分といっ位置の情報も示されており詳細度が高く、ユーザーの理解が容易であり、検知精度向上へのフィードバックにも活用が期待できる結果となった。
セグメンテーション図 4 に異常検知モデルへの入力画像と検知結果を示す。
赤枠で示す通り、左側に縦のほつれがあるが、セグメンテーションではほつれ付近の異常度が高くなっているものの、左上と左下が特に異常度が高い結果となっている。
LLMへの入力画像と生成したキャプションの例を図 5 に示す。
ヒートマップで基の図が見にくくなっているためか、ほつれだけでなく、色ムラや擦り傷の可能性についても言及できており、正確性の高い結果と言える。
また、異常度が高い箇所以外にも言及できており詳細度は高い。
図 2 二値分類によるキャプション生成結果例図 3 多クラス分類によるキャプション生成結果例物体検知図 6 に物体検知結果と生成したキャプションの例を示す。
異常箇所 2 箇所のうち、1 箇所を検知漏れしているが、キャプションではもう 1箇所についても異常であることが言及されている。
検知できている異常箇所に対しては、テクスチャ、色、形の違いなど、様々な要因から異常の理由を詳述しており、検知漏れの箇所に関しても同様の要因から異常であることを言及できている。
キャプションは異常の理由を多角的に説明できており、正確性と詳細度が高い結果となっている。
表 3 比較検証の採点結果正確性詳細度柔軟性2 値分類 4.17 4.00 5.00多クラス分類 4.83 4.92 5.00セグメンテーション 3.75 4.17 3.00物体検知 4.17 4.75 4.00他のクラスなど全テストデータに対して検証を行った評価結果を表 3 に示す。
二値分類や多クラス

自然言語での異常解釈：LLM を用いた AI 説明モデルの提案

山科 勇輔

1

須賀 圭一

1

白井 祐典

1

市川 佳彦

11

株式会社 Insight Edge



{yusuke.yamashina, keichi.suga, yusuke.shirai, yoshihiko.ichikawa}@insightedge.jp



概要

本研究では、画像異常検モデルと大規模言語モデル（LLM）と組み合わせることで、より解釈しやすくする新しいアプローチを提案する。
異常検知は、製造業や医療分野で不可欠であり、迅速かつ正確な判断が求められるが、その出力が抽象的で理解しづらいことがある。
そこで画像処理アルゴリズムによって検知された異常を、LLM を用いて自然言語で説明する言語駆動型説明可能 AI（Language-DrivenExplainable AI）を提案し、異常検知結果の信頼性と透明性の向上を図るまた、その出力が実業務に有用であるかも検証する。


1 はじめに

近年、深層学習技術の進展に伴い、画像認識における異常検知の精度は飛躍的に向上している。
特に製造業や医療分野において、製品の欠陥検出や病変の早期発見など、様々な応用が期待されている[1, 2]。
しかし、異常は一般的に稀な事象であるため、正常データに比べて異常データの収集に課題がある。
また、異常のパターンは多様で、明確に定義することが難しく、各異常はそれぞれ異なる特徴を持つため、一貫して検出するためのモデル設計も困難なものとなっている。
さらに、ラベリングが複雑で誤りが発生しやすく、アノテーションコストが高いことも課題となっている。
このため、異常検知の精度向上に向けた多方面での研究が引き続き行われている[3]。
また、既存の深層学習モデルはブラックボックスであることが多く、異常と判断した根拠を人間が理解することが困難なケースもあった。
このため、AI の判断に対する信頼性の担保や、さらなる性能向上のために、AI の意思決定プロセスを説明可能なものにする Explainable AI(XAI、説明可能なAI)技術[4, 5, 6]が注目されているが、XAI の手法で生成される説明がデータ分析に長けた専門家でないと解釈が難しい場合や、説明が多すぎて重要な情報が埋もれてしまったり、逆に説明が限定的で詳細に欠けることがあり、適切な情報量のバランスを取ることが難しいといった課題がある。
一方で、近年の LLM の発展は XAI の可能性も大幅にひろがっている。
例えば、画像キャプション生成タスク[7]のように、画像に対する異常検知結果を LLM の入力として説明文を生成することで、画像内の異常の理由を人間が理解しやすく自然な言葉で説明することが可能となる。
さらには、異常検知結果が誤っていた場合にもその間違いを正すことで異常検知精度の向上や、異常の種類や発生箇所から発生要因をフィードバックすることで異常検知後の作業の優先順位なども指示することが期待できる。
本研究では、画像に対する異常検知結果を LLMへのインプットとすることで説明性を付与する言語駆動型説明可能 AI（Language-Driven XAI）を提案する。
各種画像に対する異常検知結果（２値分類、クラス分類、セグメンテーション、物体検知）に対してキャプション生成を行い、正確性や詳細度、異常のバリエーションに対するキャプションの柔軟性などの評価を行う。



2 関連研究



2.1 画像に対する異常検知

異常検知は、通常データセット内で稀なパターンや事象を識別する技術である。
製品の欠陥や医療画像における病変の早期発見などが含ま、多種多様な分野での重要な課題として認識されており、統計モデルや特徴量エンジニアリングに基づき、特定の指標やルールに従って異常を判断するものが提案されている[1]。
近年では深層学習を用いた手法が、従来の手法が抱える課題を克服するためのアプローチとして注目されている。
特に、Convolutional NeuralNetwork（CNN）を利用した手法は、画像データから自動的に特徴を抽出し、２値分類やクラス分類で高い異常検出精度を達成することが実証されている。
また、ImageNet などの大規模な画像データセットで事前学習されたモデルを使用して、特徴を抽出した後、複数の層の特徴を結合してピクセルレベルで異常検知を行う PaDiM[8]や PatchCore[9]なども提案されている。
他にも YOLO[10]などの物体検知を用いた手法も提案されている。

2.2 説明可能な AI

XAI は、AI モデルの決定理由を人間が理解できる形で説明することを目指す技術である。
例えば、医療診断システムでは、XAI が診断の根拠を明示することで、医師がその判断を信用することを助ける。
しかし、生成された説明が専門外の人には難解であったり、説明が冗長で重要な情報が埋もれてしまうといった課題も存在する。
特に画像処理においては、モデルがどの特徴（例えば、ピクセル）に注目しているかを視覚的に示す手法が重要であり、代表的な手法として、特徴マップを用いる Grad-CAM[11]や LPR[12]が提案されている。
また、LIME[4]は、画像の特定の部分やピクセルを抜き出して入力し、それに基づいた予測結果とのペアを作成し、そこからより単純なモデルに学習させることで説明力の高い結果を出力できるようにすることで、重要な特徴量を明確に取得することを可能にしている。



2.3 キャプション生成

画像キャプション生成は、画像のテキスト説明やキャプションを自動的に生成するタスクであり、近年では LLM を活用した芸術作品に対する説明の生成に関する研究もなされている[13]。



3 問題設定

図 1 に提案アプローチの概要図を示す。
異常検知モデルとしては、例えば、多クラス分類やセグメンテーション、物体検知モデルなどを想定している。
本研究では画像に対する異常検知結果に対してLLM で説明性を付与した際のキャプションの正確性、個数や位置、大きさ、形状などの詳細度、異常のバリエーションに対するキャプションの柔軟性、を評価する。
キャプションの生成結果は定量的に評価する手法もあるが、ここでは、設定した 5 段階の評価スケールを用いて人間による定性的な評価とした．「正確性」と「詳細度」は一枚一枚採点し、その平均点を算出する。
「柔軟性」は異常のバリエーションに対する評価となるので各手法での全結果を図 1 提案アプローチ手法：Language-Driven XAI表 1 異常検知モデル2 値分類 CNN多クラス分類 CNNセグメンテーション PatchCore物体検知 Grounding DINO [14]鑑みて採点した。



4 実験設定

データセットとしては、産業用異常検出のベンチマークとしてよくも用いられている MVTec AD[5]で評価する。
MVTec AD は、合計 5354 枚の画像を含む 15 のクラスで構成されており、各クラスは特定の製品に対してさまざまな欠陥タイプを持つ異常データとなっている。
本研究では、テストデータである 1725 枚を対象とした。
異常検知モデルとしては、正常か異常かの 2 値分類、欠けや印刷ミスといった複数の異常の種類を分類する多クラス分類、画像内の異常箇所をピクセルレベルで評価しヒートマップで表すセグメンテーション、画像内の異常箇所をバウンディングボックス（bbox）で示す物体検知、の 4 種類を適用し、これらの手法によるキャプション生成の結果を比較評価する。
本研究で用いた各種法のモデルを表 2 に示す。
なお、各パラメータに関しては、誤検知や検知漏れの結果に対しても評価するため、ある程度ランダムとした。
また、モデル毎に出力される結果も異なるのでモデル毎に指示文を調整している。
表 2 に指示文の例を示す。
また、LLM には gpt-4o（OpenAI）を適用した。
表 2 各モデルへの指示文例（クラス：hazelnut の場合）2 値分類これは hazelnut の画像で、異常と判断されたものです。
この画像がなぜ異常と判断されたか説明してください。
多クラス分類これは hazelnut の画像で、crackと判断されたものです。
この画像がなぜ crack と判断されたか説明してください。
セグメンテーションこれは hazelnut の画像に異常度を表すヒートマップを重ね合わせた画像です。
ヒートマップの色が濃い（赤い）ほど異常度が高いことを示します。
この画像がなぜ異常と判断されたか説明してください物体検知この画像は hazelnut の画像です。
画像内の枠内の箇所は異常と判断された箇所です。
この枠内がなぜ異常と判断されたか説明してください。



5 実験結果

二値分類図 2 に入力画像と検知結果、生成したキャプションの例を示す。
亀裂と割目から異常であることを正確に説明できており、また、保存状態にも言及することができている。
しかし位置や傷の数などについての説明はなく詳細度はやや低い。
多クラス分類図 3 に入力画像と多クラス分類結果、生成したキャプションの例を示す。
異常の種類としては squeeze が正しいが crack と分類してしまったケースだが、右側に凹みがあることを説明しており、誤判定である可能性があることも説明できている。
右側やオレンジ色の部分といっ位置の情報も示されており詳細度が高く、ユーザーの理解が容易であり、検知精度向上へのフィードバックにも活用が期待できる結果となった。
セグメンテーション図 4 に異常検知モデルへの入力画像と検知結果を示す。
赤枠で示す通り、左側に縦のほつれがあるが、セグメンテーションではほつれ付近の異常度が高くなっているものの、左上と左下が特に異常度が高い結果となっている。
LLMへの入力画像と生成したキャプションの例を図 5 に示す。
ヒートマップで基の図が見にくくなっているためか、ほつれだけでなく、色ムラや擦り傷の可能性についても言及できており、正確性の高い結果と言える。
また、異常度が高い箇所以外にも言及できており詳細度は高い。
図 2 二値分類によるキャプション生成結果例図 3 多クラス分類によるキャプション生成結果例物体検知図 6 に物体検知結果と生成したキャプションの例を示す。
異常箇所 2 箇所のうち、1 箇所を検知漏れしているが、キャプションではもう 1箇所についても異常であることが言及されている。
検知できている異常箇所に対しては、テクスチャ、色、形の違いなど、様々な要因から異常の理由を詳述しており、検知漏れの箇所に関しても同様の要因から異常であることを言及できている。
キャプションは異常の理由を多角的に説明できており、正確性と詳細度が高い結果となっている。
表 3 比較検証の採点結果正確性詳細度柔軟性2 値分類 4.17 4.00 5.00多クラス分類 4.83 4.92 5.00セグメンテーション 3.75 4.17 3.00物体検知 4.17 4.75 4.00他のクラスなど全テストデータに対して検証を行った評価結果を表 3 に示す。
二値分類や多クラス図 4 セグメンテーションによる異常検知結果例（クラス：carpet)図 5 セグメンテーションによるキャプション生成結果例分類では異常画像をそのまま入力としているためか、より詳細な説明をしやすく、また、誤検知や誤分類の際に訂正するようなキャプションを生成できるケースが多く見られた。
異常の種類や発生要因についても言及できており、全体的に高い評価結果となった。
セグメンテーションでは、正しく検知できている場合は異常箇所の位置や個数なども詳述できているケースが多く得られた。
しかし、ヒートマップを重ねているためか異常の種類について詳細にキャプションすることが難しく、また、ヒートマップがあることによって検知漏れしている場合に検知漏れ箇所を言及できているケースも少なく、全体的にやや劣る結果であった。
物体検知の場合、異常箇所の位置や個数に関して言及するケースが多く、検知漏れしている場合でも異常箇所を指摘できていたりと、正確性、詳細度、柔軟性とも高いキャプションが生成されやすい結果であった。
しかし、bbox によっては異常箇所に被ってしまい、異常の種類を間違えてしまったり、検知漏れしている場合に、bbox図 6 物体検知によるキャプション生成結果例が無いのにあるような説明をしてしまったりと、プロンプトの改善などが必要なケースもいくつか確認できた。
しかしながら、いずれの異常検知手法においても、正しく検知できている場合には正確性、詳細度が高いキャプションが生成できており、誤検知や検知漏れしている場合にも訂正したり、保存や輸送状態に起因するなどと言った異常の発生した要因についても言及したりと、詳細かつユーザビリティが高いキャプションが生成でき、本アプローチの有効性を確認できた。



6 まとめ

本研究では、画像に対する異常検知結果に説明性を付与するLanguage-Driven XAIを提案し、産業用異常検出のベンチマークとしてよくも用いられている MVTecAD を対象に評価を行った。
異常についての説明だけでなく、発生要因や誤検知時に訂正できることも確認でき、よりユーザビリティの高い検知システムに寄与できることを確認した。
今後は、検知とキャプションを組み合わせた新しい評価手法の開発や、実データを対象とした検証による作業工程へのフィードバックの可否、や複数の異常検知結果を入力とすることでより安定性の高いキャプションの生成可否について検討を行っていく予定。



参考文献


[1] Arindam Banerjee Varun Chandola and Vipin Kumar.Anomaly detection : A survey. ACM Computing Sur-veys, Vol. 41, No. 3, pp. 1–8, 2009.
[2] Thomas Schlegl, Philipp Seeb¨ock, Sebastian M. Waldstein,Ursula Schmidt-Erfur th, and Georg Langs. Unsupervisedanomaly detection with generative adversarial networks toguide marker discovery. In Information Processing inMedical Imaging, 2017.
[3] Lukas Ruﬀ, Robert A. Vandermeulen, Nico G¨ornitz,Alexander Binder, Emmanuel M¨uller, Klaus-RobertM¨uller, and Marius Kloft. Deep semi-supervised anomalydetection. In International Conference on LearningRepresentations, 2020.
[4] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.“why should i trust you”’: Explaining the predictionsof any classiﬁer. In Proceedings of the 22nd ACMSIGKDD International Conference on KnowledgeDiscovery and Data Mining, 2016.
[5] Scott Lundberg and Su-In Lee. A uniﬁed approach tointerpreting model predictions. In Advances in NeuralInformation Processing Systems 30, 2017.
[6] Marco Ancona, Enea Ceolini, Cengiz¨Oztireli, and MarkusGross. Towards better understanding of gradient-basedattribution methods for deep neural networks. InInter-national Conference on Learning Representations,2018.
[7] Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang,Xiaowei Hua, Lei Zhang, Lijuan Wang, Houdong Hu,Li Dong, Furu Wei, Yejin Choi, and Jianfeng Gao. Oscar:Object-semantics aligned pre-training for vision-languagetasks. In European Conference on Computer Vision,2020.
[8] Thomas Defard, Aleksandr Setkov, Angelique Loesch, andRomaric Audigier. Padim: a patch distribution model-ing framework for anomaly detection and localization. InInternational Conference on Pattern Recognition,2021.
[9] Karsten Roth, Latha Pemula, Joaquin Zepeda, BernhardSch¨olkopf, Thomas Brox, and Peter Gehler. Towards to-tal recall in industrial anomaly detection. In ComputerVision and Pattern Recognition Conference, 2022.
[10] Joseph Redmon, Santosh Divvala, Ross Girshicka, and AliFarhadi. You only look once: Uniﬁed, real-time object de-tection. In Computer Vision and Pattern RecognitionConference, 2016.
[11] Ramprasaath R. Selvaraju, Michael Cogswell, AbhishekDas, Ramakrishna Vedantam, Devi Parikh, and Dhruv Ba-tra. Grad-cam: Visual explanations from deep networksvia gradient-based localization. In International Con-ference on Computer Vision, 2017.
[12] Alexander Binder, Gr´egoire Montavon, Sebastian Bach,Klaus-Robert M¨uller, and Wojciech Samek. Layer-wiserelevance propagation for neural networks with local renor-malization layers. In Computer Vision and PatternRecognition Conference, 2017.
[13] Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.Blip-2: Bootstrapping language-image pre-training withfrozen image encoders and large language models. In arXivpreprint arXiv:2301.12597, 2023.
[14] Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Liand HaoZhang, Jie Yang, Qing Jiang, Chunyuan Li, Jianwei Yang,Hang Su, Jun Zhu, and Lei Zhang. Grounding dino: Mar-rying dino with grounded pre-training for open-set objectdetection. In European Conference on Computer Vi-sion, 2024.