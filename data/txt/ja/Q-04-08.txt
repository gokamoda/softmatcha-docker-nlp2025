大規模言語モデルを利用した netlist による回路生成

島田優斗

1

 竹内孔一

21

岡山大学 工学部



 

2

岡山大学大学院 環境生命自然科学研究科



p7hp33jo@s.okayama-u.ac.jp  takeuc-k@okayama-u.ac.jp



概要

回路設計を行う企業では、すでに設計した回路図が存在する一方で、新たな回路設計の際に、それまでの設計知識を活かした設計は人手により任されている。
近年、大規模言語モデル(LLM)は記号列である言語の生成を文脈まで反映した形で実行することが可能になってきている。
そこで、本論文ではLLM を利用した回路生成についての第一段階の研究成果を報告する。
回路生成には素子間の結合と配置の問題があるため、本稿では素子間の結合に焦点をあて、回路を表現する言葉から素子と素子間の結合をあらわすnetlistを生成させるタスクを設定して回路生成の可能性について小規模な実験を実施した。
実験の結果、現段階では生成がむずかしいことを明らかにする。


1 はじめに

回路設計には要求に合わせた素子の選択と素子の接続だけでなく、配置の問題やさらに、軽量化、省電力化などさまざまな要求のもとに作成されており、回路設計を行う企業などで蓄積された回路設計はこれらを考慮した知見が含まれている価値あるデータであると考えられる。
近年、大規模気言語モデル(LLM)は人間の言語のみならず記号やプログラムコードも文脈を考慮して生成することができる。
そこで、本研究ではすでに設計済みの回路設計を LLM に学習させることで、新たな回路を生成するモデルを構築する方法について議論する。
回路の範囲は広く、モーターなどを動かす制御回路からCPU など半導体レベルの回路など用途やスケールにより回路素子、回路の構成要素、回路設計の際の考慮すべき点が異なってくる。
例えば R，L，C および半導体の基盤上の配置と配線の影響によりノイズや性能低下が生じるため、どう配置するかという問題をとりあつかう研究がある[1]。
本研究では回路生成の第一段階として、回路を構成する素子と素子間の結合に焦点をあて、回路を表現する言葉から回路の素子と素子間を記述する netlist 形式1）の回路を生成することを目的とする。
大規模言語モデルにすでに回路の情報が学習されていれば、こうした課題は学習なしでかなり生成できることが期待できるが、予備実験で ChatGPT に回路を書かせようとしたところ，JIS 規格にあるような回路図は生成されず絵に近いものが生成された。
また、Llama など download可能なローカルな言語モデルでは、netlist の生成も難しい。
しかしながら、抵抗 R やコンデンサ C など回路素子に対する情報は持っているようなので、回路の接続に関する情報を学習させると netlist を生成することが期待できる。
そこで、本稿では手法としては download 可能なローカル言語モデルに対して、netlist 形式の回路と回路を説明した文書データを学習させることで、新たな回路を生成できないかを議論する。
小規模な実験結果からは現段階では生成できた回路は 3 割程度であったことを報告する。


2 回路生成システムの全体像

本研究では、生成したい回路の説明テキストからnetlist を生成する言語モデルを構築することで回路生成システムを構築する。
システムの構成はおおきくわけて 3 つからなる。
1 回路図の作成: 回路図の作成と netlist の作成2 回路図から回路に対する説明テキストの生成し回路データを作成3 回路データを言語モデルに学習させて netlist を生成するモデルを構築1） netlist とは回路シュミレータ LTspice で利用できる素子間の接続関係を記述するデータである。

上記[1][2]については次節、[3]については 4 節で説明する。


3 回路データの作成

本研究で用いるデータとして、電源、抵抗、コンデンサ、インダクタの 4 種類の素子の組み合わせによって表される 35 個の回路図を人手で作成した。
作成した回路図を回路シミュレータ LTspice 上で再現し、netlist に変換して保存する。
さらに LTspice 上で表示される回路図を画像として保存する。
回路に対する説明テキストは 2 種類の方法で作成する。
1 つは gpt-4o-mini に上記で作成した回路画像を入力して説明テキストを生成させる。
他の方法としては人手により一つ一つの回路に対して、素子や回路の様態を説明したテキストを作成した。



4 netlist 生成モデル

上記で作成した回路データから netlist を生成する．netlist は上記に示したように素子と素子間を表すデータで記述形式が決まっているため言語に近い。
よってモデルの構成としては大規模言語モデルのみで、入力が説明テキスト(および指示文)、出力が netlist となる。
本稿では llama-3.1-8B および gpt-4o-mini と LoRAで学習した llama-3.1-8B を利用する。
前者の 2 つのモデルは ﬁne-tuning なしでプロンプトのみで説明テキストから netlist を生成させる。
一方で、LoRA モデルは llama-3.1-8B に対して、上記で作成した回路データを言語生成と同様の枠組みで学習させる。



5 評価実験

本実験では、作成した回路データを用いて学習を行い、その有効性について検証する。
LoRA モデルの場合、学習データで言語モデルを学習し、すべてのモデルはテストデータで評価する。

5.1 実験準備

本実験では、生成された netlist が LTspice を用いて生成された netlist と一致しているかどうかを示す正答率を用いて評価を行う。
また、比較実験としてチューニングを行わない場合と gpt-4o-mini を用いた場合についても検証する。
表 1 各モデルの正答率GPT 人手モデルllama-3.1-8B(LoRA) 0.286 0.286llama-3.1-8B 0 0gpt-4o-mini 0 0

5.2 実験結果

GPT を用いて作成した概要を用いた際の正答率及び、人手で作成した概要を用いた際の正答率を表 1に示す。
表 1 より、LoRA を適用することで適用していない場合や GPT を用いた場合よりも正答率が向上している。
正答率は 0.286 となっており、まだまだ改善の余地があることがわかる。
しかしながら学習がない場合では一つも netlist を正しく出すことができなかった。
これにより、基本的には学習が必要であることがわかる。
本実験において、GPT を用いて作成された説明文を用いた場合と人手で作成した説明文を用いた場合の正答率に差が見られなかった。



6 まとめ

本論文では LLM を利用した回路生成について議論した。
回路生成には素子間の結合と配置の問題があるため、本稿では素子間の結合に焦点をあて、回路を表現する言葉から素子と素子間の結合をあらわす netlist を生成させるタスクを設定して回路生成の可能性について小規模な実験を実施した。
実験の結果，LoRA を適用することで 3 割程度 netlist を生成することができたが学習がない場合には生成できないことから現段階では難しいこと、また、言語モデルには回路生成に関する情報が不足していることが明らかになった。


参考文献

[1]山梶佑介、 庄野逸、 福島邦彦。
回路定数最適化のための回路とグラフニューラルネットワークの融合。
Vol.124, No. 211, pp. 1–6, 2024.