How Domain Adaptation of BERT ImprovesSyntactic Parsing of Math Text

Runa Yoshida

1

Takuya Matsuzaki

21

Department of Applied Mathematics, Graduate School of Science, Tokyo University of Science

2

The Faculty of Science Division I, Tokyo University of Science



1423532@ed.tus.ac.jp matuzaki@rs.tus.ac.jp



掲載号の情報

31 巻 4 号 pp. 1691-1716.doi: https://doi.org/10.5715/jnlp.31.1691

概要

This study clariﬁes how the domain adaptation ofbidirectional encoder representations from transformers(BERT) contributes to the syntactic analysis of mathe-matical texts and their limitations. Experimental resultsshow that the domain adaptation of BERT is highly eﬀec-tive, even with a relatively small amount of raw in-domaindata. This improves the accuracy of the syntactic depen-dency analysis by up to four points without any annotatedin-domain data. By analyzing the improvement, we foundthat numerous errors
involving the mathematical expres-sions have been corrected. Errors related to structuresthat are not frequent in the out-domain ﬁne-tuning datawere diﬃcult to improve by only the domain adaptation ofBERT. This study also revealed that the eﬀectiveness ofBERT depends on the representation of the mathematicalexpressions in the input. Among several diﬀerent repre-sentations of mathematical expressions, the highest depen-dency accuracy was achieved using a simple method wherean entire mathematical expression is replaced with a dedi-cated special token.1）1） This paper is a revised version of [1], which has been submittedfor Proceedings of the 29th Annual Conference of the Associationfor Natural Language Processing, 2023.

参考文献

[1] Runa Yoshida and Takuya Matsuzaki. Ber t の教師なし分野適応による数学問題テキスト構文解析の精度向上要因の分析。
In Proceedings of the 29th An-nual Meeting of the Association for Natural LanguageProcessing, pp. 64–69, 2023. (in Japanese).