議論形式のマルチエージェント自動評価の詳細分析

内藤 悠

1

佐藤 魁

1

佐々木 翔大

2,1∗

鈴木 潤

1,3,41

東北大学

2

SB Intuitions 株式会社

3

理化学研究所

4

国立情報学研究所



naito.yu.q3@dc.tohoku.ac.jp



概要

本研究では、大規模言語モデル（LLM）による自動評価手法として、議論形式のマルチエージェントの有効性を検証し、評価性能の向上を試みた。
2 つの LLM を協調的に動作させるマルチエージェントシステムを導入し、モデル間で議論を行わせることによって、評価精度を高めることを目指した。
結果として、単体モデルによる評価に比べて評価精度が低下することが確認されたが、議論形式を導入することで評価精度を向上させられる可能性が示唆された。


1 はじめに

大規模言語モデル（Large Language Model: LLM）によって生成された文章の品質評価は、自然言語処理分野の研究課題としても、実用システム開発の観点でも最重要課題の一つといえる。
LLM が生成する文章の品質評価については、回答が一意に決まらないこともあり、従来は人手により評価してきた[1]。
しかし、人手評価の欠点として多くの時間と労力が必要となったり、評価者の違いや評価時のインストラクションの不整合などの理由で再現性が低いなどの課題が指摘されている[2, 3]。
このため、評価プロセスの自動化は、効率化とコスト削減、および、再現性の向上を実現するための重要な研究テーマとなっている。
近年、LLM の性能向上に伴い、LLM 自体を LLMが生成した文章の品質評価に用いる自動評価法(通称 LLM-as-a-judge [4, 5])が提案されている。
以降、本稿では LLM による自動評価と表記する。
このアプローチにより、従来の人手評価と比べ、評価速度の向上、評価コストの低下、再現性などの観点はいずれも向上した。
しかし、現状の LLM による自動評価法が人手評価に変わる完璧な代替法には至っておらず、人手評価への更なる適合が求められて∗東北大学の学術研究員としての成果図 1 評価手法の概要図いる。
本研究では、LLM による自動評価における判断の処理過程を、複数の人間が議論して最終的な判断をする手続きで模倣させることによって、LLM による文章の品質評価能力が向上するかを検証する。
この手法では、2 つの LLM を協調的に動作させ、モデル間で議論を行わせることで、最適な評価を導き出すことを目指す。
これにより、LLM が単独で行う評価よりも精度が向上することを期待する。
また、人手評価が付与されている評価データを用いて、LLM による自動評価が人間の評価とどの程度一致するかで性能を評価する。
LLM の生成文の品質を評価する課題の上では、複数の LLM を用いて品質評価をする方法は、従来のように単一の LLMにて評価をする方法に比べ顕著に性能が向上するといった結果は得られなかったが、実験の過程で発見した課題や問題点に対する対応を試みることで得られた様々な有益な知見を共有する。


2 関連研究



2.1 LLM による自動評価

近年、多くの研究[6, 7, 8]でLLMによる自動評価が採用されている。
Zheng らの研究[5]では、特定の設定において、LLM の評価が人間による評価と高い一致率を達成することが定量的に示された。
同時に、位置バイアス、冗長バイアス、自己強化バイアスなどの問題点も指摘されている[5, 9]。
LLMによる自動評価は有望視される一方で、その評価性能には改善の余地も多く、評価基準の設計や評価フレームワークの改善が求められている。


2.2 議論形式のマルチエージェント評価

LLM の対話性能向上に伴い、複数の LLM をマルチエージェントとして議論させ、複雑なタスクに対しての精度を上げる手法が注目されており[10, 11, 12]、LLM による自動評価においても同様にマルチエージェトを活用する試みがなされている。
Chan らの研究[13]や Wu らの研究[14]では、複数の LLM がそれぞれ異なる役割を担い、互いの意見を基に議論を行うことで、単一モデルによる評価と比較して、より人手評価に近い結果が得られることが報告されている。


3 評価手法

本研究では、採点者エージェントの評価結果に対して、フィードバックエージェントが改善点を指摘するフィードバック方式の評価手法を検証する。
これは、LLM が LLM 自身にフィードバックを行うことで出力を改善する従来手法[15, 12]に着想を得ており、LLM による自動評価においても段階的に評価性能が改善していくことが期待される。
手法の概要を図 1 に示す。
具体的には以下の手順でマルチエージェント評価を実施する。
はじめに、採点者エージェントに対して採点を行うようにプロンプトで指示を行う。
このプロンプトには採点者として振る舞う指示の他に、タスクの問題文、正解例、個々の問題に対する採点基準、評価対象のモデルの回答文が含まれる。
次に、フィードバックエージェントに対して、採点者エージェントの採点に修正が必要かどうかを根拠を示しながらフィードバックするように指示を行う。
最後に、採点者エージェントに対して、フィードバックエージェントが生成したフィードバックを与え、改めて採点を行うように指示する。
このようにして、フィードバックを受けて採点するサイクルを𝑁 回繰り返す。
𝑁 回目の採点をラウンド 𝑁、フィードバックを受ける前のはじめの採点をラウンド 0 とする。


4 実験設定



4.1 データ

日本語 instruction モデルの評価を目的としたデータセット「ELYZA-tasks-100[16]」を使用した。
この表 1 実験結果。
単体ラウンド 0 ラウンド 1Accuracy 0.53 0.50 0.46平均絶対誤差 0.57 0.61 0.75ピアソンの相関係数 0.78 0.77 0.67データセットは、日本語による 100 問の指示と、それに対するモデルの回答および人手による 5 段階評価を含む内容で構成されている。
要約修正や算数問題、高度な推論を要するタスクなど多様で複雑な指示が含まれており、AI アシスタントとしての有用性を評価するのに適している。
また、全ての問題に評価観点が人手で付与されており、評価の方針が明確化されている。



4.2 モデル

評価モデルとして、本実験で使用する全てのエージェントには「gpt-4o-mini-2024-07-18」を採用した。
また、評価対象のモデルとして、「elyza/ELYZA-japanese-Llama-2-70b」を使用した。



4.3 評価法

評価は、データセット内の回答に対して採点基準を基に自動評価を行い、5 段階評価スコアを付与する方法を採用した。
自動評価は単体モデルおよびマルチエージェントモデルそれぞれで実施し、その結果を人手評価との比較によって分析した。
比較には、Accuracy、平均絶対誤差（MAE）、およびピアソンの相関係数を指標として使用した。
また、Accuracy は、人手評価の平均スコアとの誤差が 0.5以下の場合を正解と定義した。
自動評価に使用するプロンプトについては、データセットを作成したELYZA 社が公開しているプロンプト[17]をベースとして調整を加えた。



5 実験結果および考察



5.1 実験結果

表 1 に実験結果を示す。
単体モデルとマルチエージェントモデルの結果を比較したところ、Accuracy、平均絶対誤差、ピアソンの相関係数の全ての指標において、マルチエージェントモデルは単体モデルに劣る結果となった。
この結果から、マルチエージェントモデルの評価能力にいくつかの問題が存在する可能性が示唆された。
実際に出力された文章を観察したところ、重大な表 2 プロンプト変更後の実験結果。
単体ラウンド0 1 2 3Accuracy 0.53 0.50 0.55 0.48 0.49平均絶対誤差 0.57 0.61 0.74 0.78 0.78ピアソンの相関係数 0.78 0.77 0.61 0.62 0.63問題として、フィードバックエージェントがすでに減点が適用されている項目に重複して減点を促す事例が複数見受けられた。
この重複減点は評価を不当に低くし、最終的な採点に悪影響を及ぼした。
また、2 度目の採点を行う際に、フィードバックに基づいた点数に関する指摘の受け渡しに問題が生じ、エージェント間でのコミュニケーションが適切に行われない事例が確認された。
このコミュニケーションの問題は、評価の品質を低下させ、マルチエージェントモデルのパフォーマンスに悪影響を与える要因となった。
一方で、フィードバックエージェントが採点基準に基づいた正しいフィードバックを提供した場合、採点が改善する事例も複数確認された。
このようなフィードバックによって、マルチエージェントモデルの評価性能が向上する可能性が示唆され、フィードバックの有効性が示された。



5.2 人手フィードバックを実施

実験結果を受けて、明らかになった問題点を解決するためにはフィードバックの改善が必要であると考察した。
そこで、人手でのフィードバックを用いて採点の改善が見込めるかを追加で検証した。
マルチエージェントモデルによって採点が悪化した 10問程度に対してフィードバックを手動で付与し、採点の改善が見られるかを観察した。
その結果、全ての問題において、人手でのフィードバックを用いることにより採点が改善されることが実証された。
また、人手でのフィードバック作成において、フィードバックがどの程度明確な内容を指摘していれば採点が変化するのかを観察するために、一部に抽象性を持たせたフィードバックも作成した。
これらのフィードバックでは、重複減点や点数の指摘の受け渡しが正しく行われない問題を抑止できずに採点を改善できない事例も見られた。
表 3 に、自動生成されたフィードバックと人手で作成したフィードバックの例を示した。
この例では、ラウンド 0 での採点時点で、キャッチーさが欠けていることが指摘されている。
これにより 1 点の減点が行われ、最終的に 4 点が付けられたことが読み取れる。
しかし、自動生成されたフィードバックでは、キャッチーさに再度減点を加える内容が書かれており、採点の不当な低下をもたらしている。
そのため、人手でのフィードバックでは、キャッチーさに関する減点が既に行われていることを明示的に伝えた。
これを用いて、ラウンド 1 での採点を行ったところ、自動生成されたフィードバックでは 3 点と評価されたのに対し、人手によるフィードバックでは 4 点が維持され、人間の評価に近づく結果となった。



5.3 プロンプトを変更

人手でのフィードバックの結果を受けて、効果的なフィードバックを自動生成するため、フィードバックエージェントに与えるプロンプトを変更した。
人手でのフィードバックの特徴を反映させつつ各エージェントの出力を明確化・形式化することを目的に、追加や緩和が必要な減点部分を強調するためのプロンプトへの変更を行った。
変更後のプロンプトを用いて再度実験を実施し、効果を検証した。
ここで使用したプロンプトは付録 A に掲載した。
その結果、表 2 に示すように、プロンプト変更前と比較して、ラウンド 1 の Accuracy が向上し、単体モデルを上回った。
一方で、ラウンド 1 の平均絶対誤差、およびピアソンの相関係数に関しては、依然として単体モデルを下回る結果が得られた。
表 3 には、プロンプト変更後に自動生成されたフィードバックの例も示した。
この例では、減点への指摘が正確になり、重複減点を抑止するフィードバックが生成されるようになった。
この他にも、プロンプトの変更によってフィードバックの指摘の正確性が向上し、採点が改善された事例がいくつか見られた。
さらに、ラウンド数を増やしてラウンド 2 およびラウンド 3 についても実験を行ったが、ラウンドが進むにつれて Accuracy、平均絶対誤差、ピアソンの相関係数のいずれの指標も大きく悪化する傾向が確認された。
ラウンド数を増加させた場合の出力を観察し、定性評価を行った結果、1 回目のフィードバックによって採点が改善されず、2 回目のフィードバックで改善された事例は 100 問中 1 問に過ぎなかった。
また、2 度目以降のフィードバックにおいて、エージェント間で点数に関する指摘の受け渡しが正しく表 3 自動生成されたフィードバックと人手で作成したフィードバックの例。
ラウンド 0 時点での採点4内容は概ね正確で、GPS トラッカーの機能（位置確認と音声通話）がしっかりと説明されています。
ただし、キャッチーさに欠けるため、もう少し親しみやすい表現や感情に訴える要素があれば、より良い広告になったと思います。
自動生成されたフィードバック人手で作成したフィードバック採点者の評価は概ね正確ですが、いくつかのポイントを指摘したいと思います。
... 3. **減点項目**: キャッチーではないスタイルに対する減点が適用されるべきです。
この点を考慮すると、4 点ではなく 3 点が適切かもしれません。
したがって、最終的な評価は 3 点とし。
..採点者の評価は正確ですが、補足と修正を提案します。
あらためて採点してください。
GPS トラッカーの機能（位置確認と音声通話）がしっかりと説明されている点は評価できます。
この部分は採点基準に従っており、正当な評価です。
また、キャッチーさに欠けるという指摘は妥当であり、適切な減点ができています。
ラウンド 1 時点での採点3内容は正確で、GPS トラッカーの機能がしっかりと説明されていますが、キャッチーさに欠けるため、広告としての魅力が不足しています。
感情に訴える要素や親しみやすい表現があれば、より効果的な広告になったでしょう。
具体的なフレーズの提案を取り入れることで、改善の余地があります。
4内容は概ね正確で、GPS トラッカーの機能（位置確認と音声通話）がしっかりと説明されています。
この点は評価できます。
ただし、キャッチーさに欠けるため、もう少し親しみやすい表現や感情に訴える要素があれば、より良い広告になったと思います。
全体的には良い内容ですが、もう一歩工夫が必要です。
プロンプト変更後に自動生成されたフィードバック採点者の評価は概ね正確であり、内容の正確性やターゲットへの配慮がしっかりと反映されています。
... ただし、キャッチーさに欠けるという指摘は妥当です。
... したがって、4 点の評価は適切であり、キャッチーさを向上させることで 5 点に近づく可能性があることを伝えるのが良いでしょう。
...行われないというコミュニケーションの問題が発生し、採点に悪影響を及ぼしている事例がいくつか見られた。
さらに、1 度目と 2 度目のフィードバック内容が類似している事例が多く見受けられ、単純なフィードバックの繰り返しだけでは効果的な性能の向上が見込めないことが明らかになった。
そのため、議論を重ねることで採点の正確さを深く追求するためには異なるアプローチが必要である可能性がある。



5.4 考察

本研究では、マルチエージェントモデルが必ずしも単体モデルよりも優れた精度を示すわけではないことが確認された。
また、マルチエージェントモデルにおいていくつかの問題点が明らかになった。
特に、重複減点の問題が特徴的であり、この問題は最終的な採点の正当性を損なう原因となった。
さらに、点数に関する指摘の受け渡しにおけるコミュニケーションの問題も明らかになった。
ただし、正確なフィードバックを生成することができれば、評価精度を改善させられる可能性も示唆された。
これらの問題点を解決し効果的なフィードバックを生成するには、各エージェントの出力を明確化・形式化することが一つの対策として考えられる。
しかし、実験の過程で、エージェント間のコミュニケーションを改善する目的でプロンプトを冗長化した場合、逆に評価精度が低下する傾向が確認された。
このことから、プロンプト設計だけで問題を解決するには限界がある可能性を考慮する必要がある。
さらに、フィードバックを繰り返すだけでは、議論が深まらずモデルの評価精度の向上に繋がらない可能性が高いことも明らかとなった。
この課題を克服するためには、フィードバックに依存しないエージェントの設計や、システム全体の新たなフレームワークの導入が求められると考えられる。


6 おわりに

本研究では、LLM による自動評価において議論形式のマルチエージェントモデルを適用し、評価の改善を試みた。
結果としては、単体モデルと比較して評価能力が低下することが確認されたが、モデル間での議論を通じることで最適な評価を導き出せる可能性を示唆する結果を得た。
また、マルチエージェントモデルにはいくつかの固有の問題が存在することも明らかになった。
今後の研究では、その問題に対応し評価精度をさらに改善するため、プロンプト設計の最適化や、新たなアプローチの導入が必要になると考えられる。



謝辞

本研究は、JST ムーンショット型研究開発事業JPMJMS2011-35 (fundamental research)、および、文部科学省の補助事業「生成 AI モデルの透明性・信頼性の確保に向けた研究開発拠点形成」の支援を受けたものです。

参考文献


[1] Tom B. Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D. Kaplan, Prafulla Dhariwal, Arvind Nee-lakantan, Pranav Shyam, Girish Sastry, Amanda Askell,Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger,Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M.Ziegler, Jeﬀrey Wu, Clemens Winter, Christopher Hesse,Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Ben-jamin Chess, Jack Clark, Christopher Berner, Sam McCan-dlish, Alec Radford, Ilya Sutskever, and Dario Amodei.Language models are few-shot learners, 2020.
[2] Emiel van Miltenburg Sander Wubben Chr is van der Lee,Albert Gatt and Emiel Krahmer. Best practices for thehuman evaluation of automatically generated text, 2019.
[3] Anya Belz, Craig Thomson, Ehud Reiter, and Simon Mille.Non-repeatable experiments and non-reproducible results:The reproducibility crisis in human evaluation in NLP.In Findings of the Association for ComputationalLinguistics: ACL 2023, 2023.
[4] Haitao Liu, Yujie Zhang, Yujie Li, Yujie Zhang, and YujieLi. A survey on llm-as-a-judge, 2024.
[5] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, SiyuanZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, ZhuohanLi, Dacheng Li, Eric Xing, Hao Zhang, Joseph E Gonza-lez, and Ion Stoica. Judging llm-as-a-judge with mt-benchand chatbot arena. In Advances in Neural InformationProcessing Systems, pp. 46595–46623, 2023.
[6] Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer,Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu,LILI YU, Susan Zhang, Gargi Ghosh, Mike Lewis, LukeZettlemoyer, and Omer Levy. Lima: Less is more for align-ment. In A. Oh, T. Naumann, A. Globerson, K. Saenko,M. Hardt, and S. Levine, editors, Advances in NeuralInformation Processing Systems, Vol. 36, pp. 55006–55021. Curran Associates, Inc., 2023.
[7] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan,John A. Gehrke, Eric Horvitz, Ece Kamar, Peter Lee,Yin Tat Lee, Yuan-Fang Li, Scott M. Lundberg, HarshaNori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang.Sparks of artiﬁcial general intelligence: Early experimentswith gpt-4. ArXiv, Vol. abs/2303.12712, , 2023.
[8] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and LukeZettlemoyer. Qlora: eﬃcient ﬁnetuning of quantized llms.NIPS ’23, Red Hook, NY, USA, 2024. Curran AssociatesInc.
[9] Guiming Hardy Chen, Shunian Chen, Ziche Liu, FengJiang, and Benyou Wang. Humans or LLMs as the judge?a study on judgement bias. In Proceedings of the 2024Conference on Empirical Methods in Natural Lan-guage Processing, 2024.
[10] Minghao Wu, Yulin Yuan, Gholamreza Haﬀari, andLongyue Wang. (perhaps) beyond human translation: Har-nessing multi-agent collaboration for translating ultra-longliterary texts, 2024.
[11] Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenen-baum, and Igor Mordatch. Improving factuality and rea-soning in language models through multiagent debate,2023.
[12] Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, YanWang, Rui Wang, Yujiu Yang, Shuming Shi, and ZhaopengTu. Encouraging divergent thinking in large language mod-els through multi-agent debate. In Yaser Al-Onaizan, Mo-hit Bansal, and Yun-Nung Chen, editors, Proceedings ofthe 2024 Conference on Empirical Methods in Nat-ural Language Processing, pp. 17889–17904, Miami,Florida, USA, November 2024. Association for Computa-tional Linguistics.
[13] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu,Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu.Chateval: Towards better llm-based evaluators throughmulti-agent debate, 2023.
[14] Ning Wu, Ming Gong, Linjun Shou, Shining Liang, andDaxin Jiang. Large language models are diverse role-players for summarization evaluation, 2023.
[15] Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hal-linan, Luyu Gao, Sarah Wiegreﬀe, Uri Alon, Nouha Dziri,Shrimai Prabhumoye, Yiming Yang, Shashank Gupta,Bodhisattwa Prasad Majumder, Katherine Hermann, SeanWelleck, Amir Yazdanbakhsh, and Peter Clark. Self-reﬁne:iterative reﬁnement with self-feedback. In Proceedingsof the 37th International Conference on Neural In-formation Processing Systems, NIPS ’23, Red Hook,NY, USA, 2024. Curran Associates Inc.
[16] Akira Sasaki, Masato Hirakawa, Shintaro Horie, and To-moaki Nakamura. Elyza-tasks-100: 日本語 instruction モデル評価データセット, 2023.
[17] ELYZA. Elyza が公開した日本語 llm「elyza-japanese-llama-2-7b」に つ い て の 解 説 : (2) 評 価 編, 2023.Accessed: 2025-01-09.




A 使用したプロンプト



A.1 採点者エージェントに与えたシステ



ムプロンプト

あなたは採点者です。
問題、 正解例、 採点基準、 出力形式、 回答が与えられます。
採点基準と正解例を参考にして、回答を 1,2,3,4,5 の5 段階で採点し、数字と採点理由を出力してください。
また、フィードバックが与えられた場合、フィードバックをもとに自身の採点を見直し、あらためて数字と採点理由を出力してください。
# 問題{input_text}# 正解例{output_text}# 採点基準基本的な採点基準- 1 点: 誤っている、指示に従えていない- 2 点: 誤っているが、方向性は合っている- 3 点: 部分的に誤っている、部分的に合っている- 4 点: 合っている- 5 点: 役に立つ基本的な減点項目- 不自然な日本語: -1 点- 部分的に事実と異なる内容を述べている: -1 点-「倫理的に答えられません」のように過度に安全性を気にしてしまっている: 2 点にする問題固有の採点基準{eval_aspect}# 出力形式1 行目: 数字のみ2 行以降: 採点理由

A.2 フィードバックエージェントに与え



たシステムプロンプト

あなたは採点者の採点を確認し、フィードバックを与える専門家です。
採点基準に従って、減点を追加または緩和するべき部分があれば、正確なフィードバックを提供してください。
適切な採点は正当に認め、正しく採点できていることを伝えてください。
ただし、採点者は、問題、 正解例、 採点基準、 回答を与えられ、採点基準と正解例を参考にして、回答を1,2,3,4,5 の 5 段階で採点し、数字と採点理由を出力しています。
# 問題{input_text}# 正解例{output_text}# 採点基準基本的な採点基準- 1 点: 誤っている、指示に従えていない- 2 点: 誤っているが、方向性は合っている- 3 点: 部分的に誤っている、部分的に合っている- 4 点: 合っている- 5 点: 役に立つ基本的な減点項目- 不自然な日本語: -1 点- 部分的に事実と異なる内容を述べている: -1 点- 「倫理的に答えられません」のように過度に安全性を気にしてしまっている: 2 点にする問題固有の採点基準{eval_aspect}# 回答{pred}