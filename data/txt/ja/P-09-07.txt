SNS 投稿によるユーザの意見変化の予測と要因分析

増川哲太

1

 狩野芳伸

11

静岡大学

1

{tmasukawa,kano}@kanolab.net



概要

ソーシャルメディアの普及により、個人が意見を発信し、他者の意見を取り入れることが容易になった。
本研究では、対象ユーザの投稿文履歴、リポストした投稿文履歴、これら履歴のいいね数やリポスト数から、 直後に意見が変化するかの予測を試みた。
結果、 80%前後の予測性能を達成し、 リポスト投稿文が顕著に予測に貢献すること、 要因として投稿文内容からの直接の予測よりもユーザ属性からの間接的な予測が大きいと思われることが分かった。


1 はじめに

現代社会に広く普及したソーシャルメディアネットワーク（SNS）では、人々はさまざまな情報を発信し、他のユーザとコミュニケーションを行っており、 SNS 上の投稿やアクティビティによってオンライン世論が形成されている[1]。
多くの SNS では、ユーザのアクティビティに基づいて最適化された情報が表示される[2]。
その結果、似たような意見ばかりに触れ、異なる意見を取り入れにくくなる現象、いわゆるエコーチェンバーが発生する可能性が指摘されている[2]。
一方で、ユーザ数の拡大に伴い、自身の発信した意見のみならず、普段触れる機会の少ない他者の意見に触れることも増加する。
これにより、意見の変化がもたらされる可能性もある。
これまでにも、SNS 上のユーザ意見に関する研究が数多く行われてきた[3][4]。
しかし、これらの研究では主に言語情報を使用していないため、ユーザの思考や意見を完全に把握しているとはいえない。
言語情報を用いた研究も単語統計に基づくものが多く[5], 全体的な動向はわかっても個別ユーザの振る舞いが捉えられない、 後からの分析はできても将来の予測ができない、 といった課題がある。
また、SNS上のコミュニケーションネットワークを通じてエコーチェンバーのような意見変遷の動向を捉えている一方で、ユーザ個人がどのような発信を行うかについての分析が不足している。
そこで、本研究では、代表的な SNS の一つであるX（旧 Twitter）1）におけるユーザの投稿文履歴、リポスト履歴、およびこれらの履歴に基づく合計いいね数やリポスト数を用いて、 意見変化の予測を試みる。
これにより、直近の投稿内容が意見変化にどのように影響を与えるかを分析し、個別ユーザの意見変化の可能性を予測することで、 将来的にはユーザ集団の意見変化過程の予測につながると期待できる。


2 関連研究



2.1 JTweetRoBERTa

JTweetRoBERTa モデル[6]は、X より取得した日本語の SNS 投稿テキスト約 6,000 万件を用いて事前学習した RoBERTa[7]ベースのモデルである。
このモデルの事前学習時には、入力となる投稿文を時系列順に繋ぎトークン数が 250 を超えない範囲で分割することで、投稿文を途中で分割することなく可能な限り長い文脈情報を保持する工夫がなされている。
一般的な書き言葉ベースのモデルよりも、SNS投稿特有の表現を高精度で捉えることができる。

2.2 JCSE

SimCSE[8]は対照学習を用いて文埋め込みを学習するフレームワークである。
その教師ありアプローチでは、自然言語推論データセットである SNLI[9]と MNLI[10]を用い、「含意」ペアを正例，「矛盾」ペアをハード負例（hard negative）として対照学習に組み込んだ。
この SimCSE をもとにした JCSE（Contrastive Learning of Japanese SentenceEmbeddings)[11]は、生成文と実際の文を組み合わせたデータを用いて対照学習を行い、 日本語モデルをターゲットドメインに適応させた。
1） https://x.com/図 1 提案手法の概念図

3 提案手法

対象ユーザの直前までの投稿文履歴、 対象ユーザがリポストした他ユーザの投稿文履歴、 合計いいね数および合計リポスト数から、 直後のターゲット投稿を伏せてそれが「意見変化投稿」「それ以外の投稿」のいずれであるかを予測する二値分類タスクをLightGBM[12]で学習する。
投稿文履歴は文埋め込みをしたベクトルとして入力する。
提案手法の概念図を図 1 に、 投稿種別の定義を表 1 に示す。
文埋め込みモデルの入力長制限に対応するため、直前の投稿文履歴から入力長制限に達するまで時系列でさかのぼって投稿文を取得し用いる。
その際、 意見変化・非変化表現が含まれない投稿文のみで構成される履歴を用いた。
また、投稿文を与える順序の影響を観察するため、 ランダムと時系列の二つの方法で投稿文を並べ替えて与え比較する。

4 実験



4.1 投稿データ収集と前処理

Twitter API v2 の Academic Research2）を用いて、2023 年 4 月 30 日以前の日付範囲から、 意見変化・非変化表現を含む投稿を取得した。
取得した投稿群に対し、OpenAI 社の GPT-4o-mini3）を利用して、意見変化・非変化表現の主語が投稿したユーザ自身であるかを判別するフィルタリングをし、ユーザ自身が出あった場合のみを残した。
フィルタリングに使用したプロンプトは付録 A.2 に示す。
フィルタリングの結果、意見変化投稿 18012） https://developer.x.com/ja/docs/x-api3） https://openai.com/ja-JP/index/gpt-4o-miniadvancing-cost-efficient-intelligence/表 1 4 つの投稿種別意見変化投稿「意見を変えた」「もう支持しない」「考え方変わった」など、それまでの意見を変更したことを示す表現（意見変化表現）（一覧は付録を参照）を含む投稿．意見非変化投稿「意見を変えない」「これからも支持する」「これからも考えは変わらない」など、同じ意見をこれからも継続する意思を示す表現（意見非変化表現）（一覧は付録を参照）を含む投稿。
中立投稿（意見変化ユーザ）意見変化投稿があったユーザの、 意見変化投稿が前後に含まれない投稿群に属する投稿。
中立投稿それ以外。
件、意見非変化投稿は 1646 件となった。
加えて、意見変化・非変化投稿の直前 500 件のユーザ本人のリポストを含む投稿文、および各投稿へのいいね数やリポスト数を取得した。
さらに、人手による追加フィルタリングを行い、確実に意見変化・非変化を表明していると判断できた 140 件を評価データとして選定した。
これとは別に、 中立投稿としてランダムにユーザを選定し、 時系列順に投稿を取得した。
ただし、 意見変化・非変化投稿が含まれないようにした。
取得した中立投稿は 2912 件である。
なお、 取得したすべての投稿文に対して、URL，ハッシュタグ、メンション、絵文字の削除を行った。



4.2 学習データセットの構築

各ユーザの投稿文およびリポスト履歴から、各モデルの最大入力トークン数に収まるまで、それぞれの履歴から投稿文を時系列でさかのぼって選択し、ランダム・日付降順のそれぞれの並べ替え方法で並べ替えてから SEP トークンで連結した。
文埋め込みは、日本語 BERT𝑏𝑎𝑠𝑒モデル4），JTweet-RoBERTa, および教師あり JCSE の BERT𝑏𝑎𝑠𝑒ベースモデル5）の三つを比較した。
CLS トークンに対応する 768 次元のベクトルを文埋め込みとして用いた。
なお、 JTweetRoBERTa の最大入力長は 250 トークンで、 ほかの 2 モデルは 512 トークンである。
学習特徴量として、文埋め込みベクトルに加え、投稿文履歴およびリポスト履歴ごとに各投稿のいいね数やリポスト数をそれぞれ合計して利用した。



4.3 要因分析のための分類タスク設計

本研究の目的は、 意見変化が起こるタイミングを個別ユーザ投稿レベルで推測することにあるが、 現4） https://huggingface.co/tohoku-nlp/bert-base-japanese-v35） MU-Kindai/Japanese-SimCSE-BERT-base-sup実の投稿はさまざまなトピックが交錯するうえ、 投稿には表れない間接的な要因も考えらえる。
そこで、投稿履歴から「その直後の投稿で意見変化が起こるか」ではなく「直後から一定の投稿数範囲内で意見変化が起こるか」を推測する。
実験ではこの一定数を 20 投稿以内とした。
意見変化の要因を考えると、 意見を変えた対象のトピックに直接関係する投稿で推測できる場合と、ユーザの傾向として意見を変えやすいかどうかといったユーザ属性で間接的に推測しうる場合がある。
これらの要因分析を行えるように、 実験では 5 パターンの分類タスクを実施した(表 2).

4.4 学習と評価

前節で構築した学習データセットから評価データを除いた件を訓練 8: 検証 2 に分割し、5 パターンの学習・検証・評価データセットを構成した(表 2)。
表 2 実験した 5 つの分類タスクとデータセット統計(変化：意見変化投稿、非変化：意見非変化投稿、中立：中立投稿、中立[変化]：意見変化ユーザの中立投稿)データ変化非変化中立中立[変化]合計意見変化 vs. 意見非変化+中立訓練 1385 692 692 - 2770検証 346 173 173 - 692評価 70 35 35 - 140意見変化 vs. 意見非変化訓練 1260 1260 - - 2520検証 316 316 - - 632評価 70 70 - - 140意見変化 vs. 中立訓練 1385 - 1385 - 2770検証 346 - 346 - 692評価 70 - 70 - 140意見変化 vs. 意見非変化+中立+中立[変化]訓練 1385 461 461 461 2770検証 346 115 115 115 692評価 70 24 23 23 140意見変化 vs. 中立[変化]訓練 1385 - - 1385 2770検証 346 - - 346 692評価 70 - - 70 140LightGBM で意見変化予測を学習した。
学習時に5 分割交差検証を実施し、得られた 5 つのモデルの予測確信度の平均を推測結果とし、 性能を評価した。
パラメータの詳細は付録 A.3 に記載した。
評価指標は Accuracy，F1 スコア、Precision，Recallを用い、埋め込みモデルと投稿文選択手法の組み合わせごとに性能を比較した。


5 結果

意見変化予測に関する各モデルおよび投稿文選択手法の組み合わせの評価結果を、表 3 に示す。
5 分割交差検証では、 Accuracy や F1 にはおおむね± 3-5ポイント程度の幅が見られた。
これをある種の誤差範囲と考えると、モデル間では有意な差がなく 5 パターンのタスクの傾向は一致しているといえる。
並べ方の違いについても、差がある場合もみられるものの一貫した優劣の傾向はみられなかった。
評価データに中立や中立[変化]などを混合した場合の、 投稿種別内訳での評価結果を表 4 に示す。
表 3と同一の結果を種別ごとに 1:1 になるよう加重して2 値分類とみなし再計算したものである。
表 3 とあわせると,意見非変化の推測性能は8割程度と高く,学習データに中立を追加することでさらに 9 割程度に性能向上している。
中立の推測性能は 8 割程度だが、 ほかの種別を学習データに追加することで性能低下している。
これらはユーザの全体的な投稿傾向から間接的に予測できた可能性がある。
中立[変化]の推測性能は 6 割弱で、ほかの種別を学習データに追加することで 65%程度に性能向上した。
ある程度は投稿内容から直接予測できたといえる。



6 分析と考察



6.1 重要特徴量の分析と考察

評価結果が全体的に高かった、 日付降順に履歴を並べ埋め込みモデルに BERT を用いた手法で、意見変化予測に貢献する特徴量の分析を行った。
特徴量の重要度は、該当する特徴量を使用した分岐で損失関数がどの程度改善されたかを示すLightGBM の情報利得（Information Gain）を用いた。
その結果、 5 パターンいずれも、 上位 5 位は投稿履歴およびリポスト履歴の埋め込みで占められ、 下位とは利得の値も大きく開きがあった。
さらに、評価データで予測を行った場合でAblation Study を実施した。
その結果(表 5)から、各投稿文履歴を除いた場合の性能低下が最も大きく、数値を除いた場合はほとんど性能低下がなかった。
特にリポスト文の貢献が大きいことがわかる。
これらの結果は、リポスト文とその内容により意見を変化させる傾向があることを示唆している。
表 3 5 つの分類タスクの評価結果（最大長: 最大入力トークン数、 Acc: Accuracy, P: Precision, R: Recall)モデル並べ方 Acc F1 P R意見変化 vs. 意見非変化+中立BERTランダム 0.871 0.882 0.817 0.957日付降順 0.907 0.914 0.852 0.986JTweet-RoBERTaランダム 0.893 0.902 0.831 0.986日付降順 0.900 0.908 0.841 0.986JCSEランダム 0.871 0.882 0.817 0.957日付降順 0.857 0.872 0.791 0.971意見変化 vs. 意見非変化BERTランダム 0.778 0.777 0.783 0.771日付降順 0.792 0.803 0.766 0.843JTweet-RoBERTaランダム 0.800 0.808 0.776 0.843日付降順 0.792 0.800 0.773 0.828JCSEランダム 0.786 0.792 0.770 0.814日付降順 0.786 0.792 0.770 0.814意見変化 vs. 中立BERTランダム 0.843 0.857 0.785 0.943日付降順
0.836 0.854 0.770 0.957JTweet-RoBERTaランダム 0.800 0.825 0.733 0.943日付降順 0.800 0.733 0.943 0.825JCSEランダム 0.800 0.827 0.728 0.957日付降順 0.771 0.702 0.943 0.805意見変化 vs. 意見非変化+中立+中立[変化]BERTランダム 0.757 0.785 0.705 0.886日付降順 0.764 0.790 0.713 0.886JTweet-RoBERTaランダム 0.736 0.770 0.681 0.886日付降順 0.743 0.780 0.681 0.914JCSEランダム 0.729 0.882 0.674 0.886日付降順 0.743 0.780 0.681 0.914意見変化 vs. 中立[変化]BERTランダム 0.514 0.534 0.513 0.557日付降順 0.428 0.394 0.419 0.371JTweet-RoBERTaランダム 0.507 0.473 0.508 0.443日付降順 0.579 0.569 0.582 0.557JCSEランダム 0.507 0.537 0.506 0.571日付降順 0.507 0.496 0.507 0.486

6.2 投稿文の分析と考察

埋め込み表現とコサイン類似度により、 文章全体に最も類似したサブフレーズを特定するKeyBERT[13]を用い、各履歴のキーフレーズを抽出した。
付録の表 12、表 13 に各ターゲット投稿の直前の投稿文履歴、リポスト履歴の例を示す。
「意見変化」および「意見変化ユーザの中立投稿を行う前の投稿文」履歴では、トピックは分散しているものの何らかの意見を示す投稿が多く、リポスト履歴には政治関連の投稿が多かった。
その一方で、意見非変化投稿を行う前の投稿履歴では、投稿文とリポストに共通して政治的な内容の意見を表明する投稿が多く含まれていた。
中立投稿前の各履歴表 4 分類タスクの評価投稿種別内訳（最大長: 最大入力トークン数、 Acc: Accuracy, P: Precision, R: Recall)モデル並べ方 Acc F1 P R中立の内訳：意見変化 vs. 意見非変化+中立BERTランダム 0.686 0.708 0.557 0.957日付降順 0.676 0.694 0.544 0.986JTweet-RoBERTaランダム 0.693 0.826 0.711 0.986日付降順 0.693 0.836 0.726 0.986JCSEランダム 0.663 0.795 0.688 0.957日付降順 0.682 0.782 0.654 0.971中立の内訳：意見変化 vs. 意見非変化+中立+中立[変化]BERTランダム 0.623 0.810 0.747 0.886日付降順 0.624 0.844 0.805 0.886JTweet-RoBERTaランダム 0.623 0.795 0.721 0.886日付降順 0.643 0.780 0.681 0.914JCSEランダム 0.623 0.795 0.721 0.886日付降順 0.643 0.780 0.681 0.914中立[変化]の内訳：同上BERTランダム 0.621 0.656 0.521 0.886日付降順 0.621 0.656 0.508 0.886JTweet-RoBERTaランダム 0.620 0.636 0.496 0.886日付降順 0.641 0.660 0.516 0.914JCSEランダム 0.620 0.626 0.484 0.886日付降順 0.641 0.660 0.516 0.914表 5 Ablation Study の結果（Acc: Accuracy, P: Precision, R:Recall）投稿リポスト数値 Acc. F1 P R- ○ ○ 0.864 0.877 0.800 0.971○ - ○ 0.814 0.809 0.833 0.786○ ○ - 0.900 0.908 0.841 0.986- - ○ 0.714 0.686 0.727 0.706では日常の出来事や挨拶などが多かった。
この結果から、普段の投稿であまり政治にかかわるような投稿をしていないユーザは、政治など議論の多いトピックの投稿を見ることによって、それまで持っていた意見が変化する可能性が高いと考えられる。
一方で、普段から政治など議論の多いトピックについて投稿を行うユーザは、同様のトピックに関する他者の投稿を日常的に目にしているため、自身の意見を変えにくいと推測される。



7 おわりに

SNS 投稿とリポスト履歴の埋め込み文、合計いいね数とリポスト数を用いて、投稿直後に意見変化を表す投稿があるかの予測を行った。
実験では 80%前後の予測性能を達成し、 リポスト投稿文が顕著に予測に貢献すること、 要因として投稿文内容からの直接の予測よりもユーザ属性からの間接的な予測が大きいと思われることが分かった。
今後はユーザ間の関係性を考慮した意見変化予測に取り組みたい。



謝辞

本研究は JSPS 科研費（JP22H00804）, JST さきがけ（JPMJPR2461）, JST AIP 加速課題（JPMJCR22U4）,およびセコム科学技術財団特定領域研究助成の支援をうけた。

参考文献


[1] 遠藤薫. 「ネット世論」という曖昧 : ＜世論＞，＜小公共圏＞，＜間メディア性＞（＜特集＞世論と世論調査）. マス・コミュニケーション研究, Vol. 77,No. 0, pp. 105–126, 2010.
[2] Matteo Cinelli, Gianmarco De Francisci Morales, Alessan-dro Galeazzi, Walter Quattrociocchi, and Michele Starnini.The echo chamber eﬀect on social media. Proceedingsof the National Academy of Sciences of the UnitedStates of America, Vol. 118, , 2021.
[3] Chen W. Peng H. et al. Sasahara, K. Social inﬂuence andunfollowing accelerate the emergence of echo chambers.Journal of Computational Social Science, Vol. 4, p.381–402, 2021.
[4] Takuya Nagura and Eizo Akiyama. The eﬀect of increasingnumber of topics to polarization and echo chambers on sns.Transactions of the Japanese Society for ArtiﬁcialIntelligence, Vol. 38, pp. B–N11 1, 2023.
[5] Chiara Monti, Luca Maria Aiello, Gianmarco De Fran-cisci Morales, et al. The language of opinion change onsocial media under the lens of communicative action. Sci-entiﬁc Reports, Vol. 12, p. 17920, 2022.
[6] 高須遼, 狩野芳伸. JTweetRoBERTa: 大規模 sns 投稿テキストによる事前学習と 各種タスクによる性能検証. 言語処理学会第 30 回年次大会発表論文集, 2024.
[7] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, LukeZettlemoyer, and Veselin Stoyanov. RoBERTa: A ro-bustly optimized bert pretraining approach. ArXiv, Vol.abs/1907.11692, , 2019.
[8] Tianyu Gao, Xingcheng Yao, and Danqi Chen. SimCSE:Simple contrastive learning of sentence embeddings. InMarie-Francine Moens, Xuanjing Huang, Lucia Specia,and Scott Wen-tau Yih, editors, Proceedings of the2021 Conference on Empirical Methods in Natu-ral Language Processing, pp. 6894–6910, Online andPunta Cana, Dominican Republic, November 2021. Asso-ciation for Computational Linguistics.
[9] Samuel R. Bowman, Gabor Angeli, Christopher Potts, andChristopher D. Manning. A large annotated corpus forlearning natural language inference, 2015.
[10] Adina Williams, Nikita Nangia, and Samuel R. Bowman.A broad-coverage challenge corpus for sentence under-standing through inference, 2018.
[11] Zihao Chen, Hisashi Handa, and Kimiaki Shira-hama. JCSE: Contrastive learning of japanese sen-tence embeddings and its applications. arXiv e-prints10.48550/arXiv.2301.08193, 2023.
[12] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, WeiChen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. Light-gbm: A highly eﬃcient gradient boosting decision tree. InNeural Information Processing Systems, 2017.
[13] Maarten Grootendorst. Keybert: Minimal keyword extrac-tion with bert., 2020.




A 付録



A.1 表現一覧

表 6 意見変化表現の一覧意見を変えた、考えを変えた、支持を変えた、立場を変えた、見方を変えた、見解を変えた、意見を変えました、考えを変えました、支持を変えました、立場を変えました、見方を変えました、見解を変えました、考えを改めた、考えを改めました、もう支持しない、もう賛成しない、もう賛同しない、もう同意しない、もう支持できない、もう賛成できない、もう賛同できない、もう同意できない、もう支持したくない、もう賛成したくない、もう賛同したくない、もう同意したくない、もう支持しません、もう賛成しません、もう賛同しません、もう同意しません、もう支持できません、もう賛成できません、もう賛同できません、もう同意できません、もう支持したくありません、もう賛成したくありません、もう賛同したくありません、もう同意したくありません、支持やめた、支持やめました表 7 意見非変化表現の一覧これからも支持する、これからも支持します、これからも賛同する、これからも賛同します、これからも意見変えない、これからも意見変えません、これからも考え変えない、これからも考え変えません、これからも支持変えない、これからも支持変えません、これからも立場変えない、これからも立場変えません、これからも見方変えない、これからも見方変えません、これからも見解変えない、これからも見解変えません、考え改めない、考え改めません、考えを変えない、考えを変えません、考えを改めない、考えを改めません、支持続ける、支持続けます、ずっと支持する、ずっと支持します、ずっと賛同する、ずっと賛同します、これからも意見一緒、これからも意見同じ、これからも考え一緒、これからも考え方一緒、これからも考え同じ、これからも立場一緒、これからも立場同じ、これからも見方一緒、これからも見方同じ、これからも見解一緒、これからも見解同じ

A.2 フィルタリングプロンプト

表 8 意見変化表現のフィルタリングプロンプトこれから与える投稿文において以下の条件を全て満たす場合は True，それ以外の場合は False をそれぞれ考察の過程と共に出力してください。
# 条件・投稿文中で意見、立場、支持などのスタンスを明示的に変えた人が、この投稿文の筆者(著者)の場合・投稿文中で意見、立場、支持などのスタンスを明示的に変えた人が、この投稿をした時点で意見が変わった場合# 投稿文※ここに投稿文を挿入する

A.3 学習時の各種パラメータ設定

LightGBM の学習時パラメータ設定を表 10 に示す。

A.4 GPT-4o との性能比較

以下のプロンプトを GPT-4o に渡し、評価データで意見変化予測を行った。
 これからとある SNS ユーザの本人投稿文履歴、リポスト投稿文履歴、それぞれの履歴のいいね数、リポスト数を与えます。
これらの特徴量からこのユーザがこの次の投稿において意見を変えそうな場合は True, そうでない場合は False を出力してください。
※ここに本人投稿文履歴、リポスト履歴、合計いいね数および合計リポスト数を挿入 実際のプロンプトではこの後に、本人投稿文履歴、リポスト履歴、合計いいね数および合計リポスト数を挿入している。
評価結果は表 11 に示す。


A.5 投稿文の例

表 9 意見非変化表現のフィルタリングプロンプトこれから与える投稿文において以下の条件を全て満たす場合は True，それ以外の場合は False をそれぞれ考察の過程と共に出力してください。
# 条件・投稿文中で意見、立場、支持などのスタンスを変えないと宣言している人が、この投稿文の筆者(著者)の場合・投稿時点でのスタンスを今後も継続すると推測できる場合# 投稿文※ここに投稿文を挿入する表 10 LightGBM の各種パラメータパラメータ名値objective binaryboosting gbdtlearning rate 0.1num leaves 31max depth -1表 11 GPT-4o での意見変化予測性能評価(Acc: Accuracy,P: Precision, R: Recall)Acc F1 P R0.512 0.586 0.085 0.148表 12 投稿文例。
各投稿文は匿名加工済み意見変化投稿この人好きだったから結構ショックだなこれがこの業界に参入した当初から考えていたことだ勝手にやったことなんだから被害者ヅラするな意見非変化投稿日本第一党に交代した方がいいと思うこの発言は総理総裁らしくないこの党のお陰で救われた人も結構いる中立投稿今日はヨガ二つやってきました今週も娘の買い物に付き合わされたいつもの古本屋で美術集見つけた意見変化ユーザの中立投稿失うものは何もないと思いこむことにしたそれらしい偏見で文章を生成しているだけだだからこそ、そこに評価が偏るところはあると思う表 13 リポスト文例。
各投稿文は匿名加工済み意見変化投稿これを言い続けるなら与党全体で堕ちていって欲しいあの候補者に嫌味っぽく言われたから投票行って変わるならマシ意見非変化投稿この税金の意味って何？憲法改正に躍起になってるこのニュース、情報源がどこか大事だよね中立投稿おはよう！今日もいい一日でありますように今年は本当に大変な 1 年でしたねあの人の友達のイケメンも好きやった意見変化ユーザの中立投稿これ県庁に報告しないとダメだわ本当の勝負は一発で不合格になるこの試験からこの党の本当の意味での敗北はこれからだな