系列ラベリングを用いた日本語の比喩表現抽出

Ganbat Naranbuuvei

1

 尾崎太亮

1

 古宮嘉那子

1

 浅原正幸

21

東京農工大学大学院 生物システム応用科学府 

2

国立国語研究所/総合研究大学院大学



{s248894r, hiroaki-ozaki}@st.go.tuat.ac.jp  kkomiya@go.tuat.ac.jp



 masayu-a@ninjal.ac.jp



概要

本研究では、系列ラベリングの手法を用いて日本語の比喩表現をスパンレベルで抽出した。
モデルには BERT を使用し、コーパスには BCCWJ-Metaphorコーパスを用いた。
比喩表現一般を抽出するモデルと比喩表現の 4 つの種類である結合比喩、文脈比喩、換喩、提喩それぞれを抽出するモデルの 2 種類を作成した。
さらに、各モデルの性能を評価し、エラー分析を行った。
これにより、日本語の比喩表現の自動抽出とその課題を明らかにする。


1 はじめに

比喩表現とはある物事を別の物事に喩えることである。
例えば、「ほとんど環境を傷つけることもなく発展を遂げた。
」
という
文中の単語「傷つける」は本来の意味である「物理的な傷を与える」ではなく、「悪影響を与える」という意味で使用されている比喩表現である。
比喩は日常生活で幅広く使われており、Lakoﬀ と Johnson ら[1]が提案した概念メタファー理論(Conceptual metaphor theory)では、比喩表現は人間の思考や認知に重要な役割を果たしていると述べられている。
そのため、比喩表現を理解することは言語学、心理学、自然言語処理などの分野にとって重要である。
比喩を自動的に検出する研究を行うためには、比喩表現を同定する必要がある。
比喩表現を同定する手法は、(1)個別の構成語の基本義と派生義の変化に重きを置いて説明をする方式と、(2)複合化した格フレームの選択制限違反に重きを置いて説明する方式の二種類が主流である。
英語コーパスについては上記二通りの手法に基づいたコーパスが公開されている。
これに対し、日本語の比喩のコーパスは少ない。
加藤ら[2]は MIP VU[3]という手法を援用し、「現代日本語書き言葉均衡コーパス」(BCCWJ)に比喩表現情報を付与した BCCWJ-Metaphor コーパスを構築した。
これにより日本語の比喩表現の様々な実証的な研究を可能にした。
MIP (MetaphorIdentiﬁcation Procedure)は Pragglejaz ら[4]が提案した上記の(1)の手法の一種であり、MIP VU は MIPの拡張として Metaphor Related Word を決める手法である。
暗喩だけではなく、直喩や比喩の境界事例も対象としている。
BCCWJ-Metaphor コーパスは多くの英語の比喩コーパスとは異なりトークンレベルのアノテーションではなく、スパンレベルの比喩のアノテーションがなされている点に特徴がある。
本研究では、BCCWJ-Metaphor コーパスを用いて、日本語の比喩表現をスパンレベルで抽出した。
スパン抽出は、日本語 BERT1）を系列ラベリングとして定式化した上で、ﬁne-tuning を実施した。
MIP によるトークンレベルの比喩の同定を行うには、単語が文字通りの意味、または基本的な語義の意味で使われているかどうかを意味ベクトルの比較を用いて行うものが多い[5, 6, 7, 8]。
しかし、スパンレベルの比喩検出のためには、スパンレベルの意味ベクトルを使用する必要があり、比較対象の字義通りの意味ベクトルの生成が困難である。
そのため、本研究は、そのような情報を利用することなく、BCCWJ-Metaphor コーパス上の情報だけを利用し、比喩表現のスパンレベルの自動抽出を試みた。



2 関連研究

英語の比喩表現判定の研究には BERT を基盤にしたものが多い。
BERT や RoBERTa などの事前学習済みモデルは文脈に即した単語の埋め込み表現を生成できることから、比喩表現判定において高い性能を示す。
MelBERT[5]は BERT モデルにMIP と SPV(Selectional Preference Violation)[9]を取り組むことで比喩表現を判定した。
MrBERT[10]は特に英語の動詞比喩に焦点を当てた。
FrameBERT[6]は FrameNET の外部知識と RoBERTa を用いた。
1） tohoku-nlp/bert-base-japanese-v3

BasicBERT[7]は他の研究と異なり、RoBERTa に MIPと SPV などを合わせて適用した。
このように、比喩表現を判定、抽出するタスクに事前学習済みモデルを使用することの有効性が示されている。
また、青野ら[11]は大規模コーパスに含まれる日常的なテキストに対して、メタファーとして使われやすい単語の言語学仮説を検証した。
日本語の比喩表現に関連する研究は英語と比べて少ない。
宮脇ら[12]は小説テキストから「〜ような」表現を使う直喩を抽出した。
加藤ら[13, 14]は「比喩表現の理論と分類」を電子化し、BCCWJ に自然さ・わかりやすさ・古さ・新しさ・比喩性の評定値を付与した。
また、BCCWJ-Metaphor から MIP の考え方に基づいて比喩を検出した Zhu ら[8]の研究がある。



3 コーパス

本研究では、加藤ら[2]が公開した BCCWJ-Metaphor コーパスを用いた。
本コーパスは BCCWJの人手で分類語彙表番号が付与されている新聞(PN)・書籍(PB)・雑誌(PM)の 34 万語を対象とし、比喩表現情報が付与されているコーパスである。
比喩表現情報を付与する基準として MIP および MIP VUを採用している。
コーパスには、結合や種別の情報のほか、一般的な読み手による印象評定情報も含まれている。
加藤ら[15]の研究で、BCCWJ-Metaphorコーパスにおける比喩表現の認定手法と情報付与について報告している。
図 1 に、BCCWJ-Metaphorコーパスの一部を示す。
図 1 BCCWJ-Metaphor の一部本研究で使用したのは短単位書字形とそれに対する比喩 BIO、結合比喩 BIO、換喩 BIO、提喩 BIO、文脈 BIO の列である。
コーパスに付与された各種の BIO タグは、固有表現抽出などに使われる一般的な系列ラベリングと同様に、比喩表現の始まり(Beginning, B)、中(Inside, I)、外(Outside, O)を表している。
例えば、「論議が進む」という比喩表現の場合、比喩表現一般を表す比喩 BIO 列と比喩種別(この例では結合比喩)の列に BI ラベルが付与されている。
BI のかたまりが一つの比喩表現のスパンになる。
コーパスのサイズは 1 文を「。」で区切って 11,905 文である。
比喩には以下のような種類がある。
それぞれの定義と例を示す。
• 結合比喩：構成要素に意味的な逸脱を持つ比喩例として「だから、ここ一番誠意を示すには水羊羹しかない。」という文中の「誠意を示す」がある。
誠意という人の気持ちを表す抽象的な概念が水羊羹という具体的なものに喩えられている具象化の例である。
• 換喩：隣接性に基づく質的転換「埼玉県の草加市立八幡小学校は昨年、家庭訪問をやめ、代わりに「地域訪問」に切り替えた。」という文の「小学校」は換喩である。
実際に家庭訪問の中止を決定するのは小学校ではなく小学校の教師などの関係者であり、小学校とその関係者という隣接性を用いている。
• 提喩：類と種という類的転換提喩の例として「お花見」がある。
お花見は実際に全ての花ではなく「桜の花」を見る際に使われる。
「花」という類で「桜」という種を表している。
• 文脈比喩：前後の文脈で比喩と理解される比喩「その頃には熱の冷めた投資家が高い免許料を懸念したために、携帯電話関連株の相場は急速に冷え込んでいった。」という
文の「熱が冷める」は文脈比喩である。
「熱が冷める」は温度が下がることを意味するが、前後の文脈から投資家の関心の低下を表していることが分かる。
表 1 に比喩表現種別の単位書字形数と比喩表現の割合を示す。
表 1 比喩表現種別の数と比喩表現の割合B I O 全割合比喩全体 11,240 23,121 312,734 347,095 9.9%結合比喩 5,066 13,276 328,753 347,095 5.28%換喩 2,519 5,504 339,072 347,095 2.31%提喩 413 512 346,170 347,095 0.27%文脈比喩 1,416 1,916 343,718 347,095 0.97%表 1 から比喩表現種別の中で結合比喩が最も多く、次に、換喩、文脈比喩、提喩の順になっていることが分かる。




4 スパンレベルの日本語の比喩表現



抽出システム

本研究では、日本語 BERT を系列ラベリングとして ﬁne-tuning することで、日本語の比喩表現抽出システムを作成した。
モデルは 2 種類作成した。
1 つ目は、比喩表現一般を抽出するモデルである。
具体的には、図 1 の「比喩 BIO」列の比喩一般を表すタグを用いて、BIO タグを推定する 3 値分類モデルを学習した。
2 つ目は、比喩表現種別ごとに学習したモデルである。
結合比喩、換喩、提喩、文脈比喩それぞれを抽出するモデルを別々に学習した。
以上により本研究では、合わせて 5 つの 3 値分類系列ラベリングモデルを作成した。



5 実験設定

BCCWJ-Metaphor コーパスの新聞・書籍・雑誌のデータをまとめ、無作為にシャッフルし、比喩表現の割合が同じになるように 5 分割後、3:1:1 の割合で学習データ、検証データ、テストデータとし、5分割交差検定を行った。
データセットの短単位書字形を tohoku-nlp/bert-base-japanese-v3 でトークナイズし、510 トークンを超える文がある場合、最初の 510トークンを入力とした。
学習時の最適化関数に AdamW、損失関数に重み付き交差エントロピー損失を用いた。
重み付き交差エントロピー損失を用いたのはコーパス中の比喩表現の割合が小さく、検出率を高めるためである。
BIO クラスそれぞれの重みは、全トークン数をクラスに属するトークン数に割って、さらに、全ての重みの合計が 1 になるように正規化を行うことで求めた。
評価指標はスパンレベルの F1 スコアである。
ハイパーパラメータは表 2 に示す値のグリッドサーチを行い、検証データに対して F1 スコアが最も高いモデルを採用した。
表 2 ハイパーパラメータ設定学習率(比喩一般) 2e-6, 5e-6, 2e-5, 5e-5, 2e-4, 2e-3学習率(4 種別) 1e-5, 2e-5, 3e-5, 5e-5バッチサイズ 4, 8, 16エポック数 10

6 実験結果

表 3 に比喩表現一般と種別ごとのモデルの再現率、適合率、F1 スコアをそれぞれ示す。
表 3 スパンレベルの比喩表現抽出の実験結果再現率適合率 F1比喩一般 44.75% 33.59% 38.38%結合比喩 41.77% 24.25% 30.69%換喩 39.18% 23.75% 29.57%提喩 16.88% 15.29% 16.05%文脈比喩 26.90% 17.41% 21.14%表 3 より、スパンレベルで比喩表現一般をある程度抽出できることが分かる。
F1 スコアが最も高いのは比喩表現一般の抽出で、次に、結合比喩、換喩、文脈比喩、提喩の順であった。
さらに、実験結果と表 1 より F1 スコアがデータ中の比喩表現の割合と正の相関関係にある。
各モデルに共通しているのは、適合率より再現率が高いことである。
これは学習時に、重み付き交差エントロピー損失を用いたことにより、比喩表現の重みが過大であったことが原因だと考えられる。


7 考察

今回の実験結果では、比喩表現一般の抽出が比喩の個々の種別の抽出より高い結果を示した。
ここでは、結合比喩、換喩、提喩、文脈比喩それぞれのスパン抽出ができた例とできなかった例を挙げる。
図2 に結合比喩の例を示す。
図中の緑色は正しく抽出された比喩表現のスパン、赤色は未抽出の表現を表す。
図 2 結合比喩の出力例結合比喩は意味的な逸脱によって成立する比喩であり、モデルが抽出できた例を見ると、日常的に使われるようなフレーズであることが分かる。
そのため、モデルの事前学習のデータや BCCWJ-Metaphorコーパスに多く出現し、予測が比較的に容易であったと考えられる。
比喩表現のスパンを抽出できなかった例を見ると、モデルがスパン全体を予測して

いない場合と一部だけを予測している場合がある。
図 3 換喩の出力例図 3 に換喩の例を示す。
換喩は隣接性に基づく比喩であり、1 文の文脈で隣接性を捉えられるかが重要になる。
例えば、図中の正しく抽出できなかった例の「ブラウスを手に」という表現は示されている文脈では「ブラウスを持っている」という動作と解釈される可能性から判断が難しくなる。
換喩では、隣接性が曖昧、抽象的な場合抽出が難しいと思われる。
図 4 提喩の出力例図 4 に提喩の例を示す。
提喩は比喩種別の中で最も抽出が難しかった。
提喩の正しく抽出できた例を見ると、「選挙戦終盤」という表現で「選挙戦全体」の動きや状況を、「スタンド」という部分で「充電スタンド場所」という全体を、「オス」で「オス鳥」を表していることが容易に分かる。
一方、未抽出の例「リビングまで上がる」は「リビングまで入る」という文字通りの意味で捉えられる可能性があり、比喩とは判断されなかったと考えられる。
コーパスの11,905 文中の提喩スパン数が 413 件であり、提喩のパターンを学習するには十分ではなかったとも考えられる。
図5 に文脈比喩の例を示す。
文脈比喩は前後の文図 5 文脈比喩の出力例脈で分かる比喩である。
抽出が成功した例に「電話を切る」、「頭にくる」、「手がかかる」などの日常的によく使われる慣用表現があり、比喩表現であることがすぐに理解できるものが多い。
抽出できなかった例には文字通りの意味でも捉えられるような比喩と非比喩の境界が曖昧な例が多くみられる。
そのため、広範囲の文脈をみるなど種別それぞれの特徴を考慮した方法が必要である。


8 おわりに

本研究では、系列ラベリングの手法を用いて日本語の比喩表現をスパンレベルで抽出した。
比喩表現一般を抽出するモデルと比喩表現の種別それぞれを抽出するモデルの 2 種類を作成し、評価した。
実験結果で、BERT を系列ラベリングとして ﬁne-tuningする方法は日本語の比喩表現抽出のベースラインとして使えるが、さらなる性能向上が必要であることが分かった。
今後の計画として、コーパスアノテーターなどの専門家の意見をもとに、スパンを抽出するための文脈の範囲を大きくする、意味ベクトルを用いる、SPV を用いた手法を提案する、データ拡張をするなどの実験を行う予定である。
さらに、BCCWJ コーパスの比喩表現情報が付与されていないデータに比喩表現情報の付与を行う。



謝辞

本研究は JSPS 科研費 JP22K12145、国立国語研究所共同研究プロジェクト「アノテーションデータを用いた実証的計算心理言語学」、及びに栢森情報科学振興財団 研究助成金「自然言語処理を用いた概念メタファーの抽出」の助成を受けたものです。

参考文献


[1] George Lakoﬀ and Mark Johnson. Metaphors We LiveBy. University of Chicago Press, Chicago, 1980.
[2] 加藤祥, 菊地礼, 浅原正幸. 『現代日本語書き言葉均衡コーパス』に対する mip に基づく比喩表現情報の付与. 言語処理学会第 28 回年次大会発表論文集,2022.
[3] Gerard J. Steen, Aletta G. Dorst, J. Berenike Herrmann,Anna Kaal, Tina Krennmayr, and Trijntje Pasma. AMethod for Linguistic Metaphor Identiﬁcation. JohnBenjamins Publishing, 2010.
[4] Pragglejaz Group. Mip: A method for identifyingmetaphorically used words in discourse. Metaphor andSymbol, Vol. 22, No. 1, pp. 1–39, 2007.
[5] Minjin Choi, Sunkyung Lee, Eunseong Choi, HeesooPark, Junhyuk Lee, Dongwon Lee, and Jongwuk Lee.MelBERT: Metaphor detection via contextualized late in-teraction using metaphorical identiﬁcation theories. InKristina Toutanova, Anna Rumshisky, Luke Zettlemoyer,Dilek Hakkani-Tur, Iz Beltagy, Steven Bethard, Ryan Cot-terell, Tanmoy Chakraborty, and Yichao Zhou, editors,Proceedings of the 2021 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pp. 1763–1773, Online, June 2021. Association for Com-putational Linguistics.
[6] Yucheng Li, Shun Wang, Chenghua Lin, Frank Guerin,and Loic Barrault. FrameBERT: Conceptual metaphor de-tection with frame embedding learning. In Andreas Vla-chos and Isabelle Augenstein, editors, Proceedings ofthe 17th Conference of the European Chapter ofthe Association for Computational Linguistics, pp.1558–1563, Dubrovnik, Croatia, May 2023. Associationfor Computational Linguistics.
[7] Yucheng Li, Shun Wang, Chenghua Lin, and FrankGuerin. Metaphor detection via explicit basic meaningsmodelling. In Anna Rogers, Jordan Boyd-Graber, andNaoaki Okazaki, editors, Proceedings of the 61st An-nual Meeting of the Association for ComputationalLinguistics (Volume 2: Short Papers), pp. 91–100,Toronto, Canada, July 2023. Association for Computa-tional Linguistics.
[8] Zhu Hang, 古宮嘉那子, 浅原正幸. 分類語彙表の基本義を利用した日本語メタファー検出. 言語処理学会第 31 回年次大会 (NLP2025) 予稿集, 2025.
[9] Yorick Wilks. A preferential, pattern-seeking, semanticsfor natural language inference. Artiﬁcial Intelligence,Vol. 6, No. 1, pp. 53–74, 1975.
[10] Wei Song, Shuhui Zhou, Ruiji Fu, Ting Liu, and LizhenLiu. Verb metaphor detection via contextual relationlearning. In Chengqing Zong, Fei Xia, Wenjie Li, andRoberto Navigli, editors, Pro ceedings of the 59th An-nual Meeting of the Association for ComputationalLinguistics and the 11th International Joint Con-ference on Natural Language Processing (Volume1: Long Papers), pp. 4240–4251, Online, August 2021.Association for Computational Linguistics.
[11] 広太 郎 青野, 遼 平笹 野, 浩 一 武 田. 大 規 模 なメ タファー自動推定結果に基づくメタファーに関する仮説の検証. Technical Report 22, 名古屋大学, 名古屋大学, 名古屋大学, nov 2023.
[12] 宮脇星名, 安藤一秋. 小説テキストからのような表現に基づく直喩文抽出手法の検討. 情報処理学会第 86 回全国大会, 2024.
[13] 加藤祥, 浅原正幸. 『比喩表現の理論と分類』データの電子化および情報付与. 国立国語研究所論集,Vol. 25, pp. 1–19, 2023.
[14] Sachi Kato and Masayuki Asahara. Assigning impressionrating information to the ‘balanced corpus of contemporarywritten japanese. Proceedings of PACLIC 38, 12 2024.
[15] 加藤祥, 菊地礼, 浅原正幸. Bccwj-metaphor における比喩表現認定と情報付与作業手順. 言語処理学会第31 回年次大会 (NLP2025) 予稿集, 2025.