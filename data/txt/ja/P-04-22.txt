分類語彙表の基本義を利用した日本語メタファー検出

ZHU HANG

1

 古宮嘉那子

1

 浅原正幸

21

東京農工大学 

2

国立国語研究所・総合研究大学院大学



 s215943u@st.go.tuat.ac.jp  kkomiya@go.tuat.ac.jp



 masayu-a@ninjal.ac.jp



概要

本研究では、分類語彙表の基本義を活用した日本語メタファー検出手法を提案する。
メタファーは言語の認知的およびコミュニケーション機能において重要な役割を果たしているが、その自動検出には文脈内での表現の意味理解が必要となる。
既存のメタファー検出モデルは主に英語を対象としており、日本語に特化したモデルは限られている。
提案手法では、日本語 BERT をベースに分類語彙表から得られる基本義情報とその用例文を活用し、対象単語の文脈的な意味と基本義の文脈的な意味を比較することでメタファーを検出する。
基本義には、山崎らが作った基本義を利用する。
また、手法には BasicBERT を基本として利用し、基本義の用例はBCCWJ から取得する。
本研究では、分類語彙表の基本義を活用した既存手法の日本語への効果的な適用により、日本語の比喩抽出を行った。
評価はBCCWJ-Metaphor コーパスを用いた 5 分割交差検証により行い、高精度な日本語メタファー検出の実現を目指す。


1 はじめに

メタファーは日常的なコミュニケーションにおいて広く使われる比喩表現であり、概念メタファー理論によれば、抽象的な領域を具体的な領域に基づいて表現する比喩手法である[1]。
例えば、「新しい道を切り開く」という表現は、「新しい挑戦や革新」という抽象的な概念を、「道を切り開くこと」という具体的な行為で表現している。
このように、メタファーは抽象的概念や複雑な感情を具体的事物に置き換えることで、コミュニケーションの円滑化と理解の深化に寄与する重要な言語現象である。
しかしながら、メタファーの計算機による自動検出には、多義性やニュアンスの存在により、文脈内での表現が何を意味しているかを理解する必要があるため困難である。
そこで、Pragglejaz[2]は語彙の基本的な意味と文脈での意味を比較してメタファーを識別する Metaphor Identiﬁcation Procedure（MIP）を提案した。
この手法では、目標語彙について文脈での意味と基本的な意味を比較し、文脈での意味が基本的な意味から逸脱している場合にメタファーと判定する。
近年、この基本概念に基づいて、BERT[3]を活用した英語向けのモデルMelBERT[4]，FrameBERT[5]，BasicBERT[6]が開発された。
一方で、既存のモデルは主に英語を対象としており、日本語に特化したメタファー検出モデルは限られている。
そこで本研究では、多義語分類の分類語彙表の基本義[7][8]を活用し、日本語版のBasicBERT による比喩検出を試みる。
MIP の考え方に基づき、分類語彙表から得られる基本義とその用例文を活用し、BERT[3]モデルにより対象単語の文脈的な意味と基本義の文脈的な意味を比較することで、メタファーの検出を実現する。


2 関連研究

メタファー検出手法は大きく 3 つのアプローチに分類できる[9]。
1 つ目は、辞書とルールベースの手法であり、明確な定義に基づいて検出を行うが、手作業が多く、稀な用例の検出が困難である[10]。
2つ目は、コーパスベースの統計的手法であり、大規模データから自動的にパターンを抽出できるが、同様に稀な用例への対応が課題となる[11]。
3 つ目は、深層学習を用いた手法であり、文脈を考慮した検出が可能である[12]。
近年、Transformer 系の言語モデルを活用したメタファー検出の研究が進んでいる。
その中で基本的な意味と文脈的な意味の比較に焦点を当てた研究として、MelBERT[4]，FrameBERT[5]，BasicBERT[6]が提案されている。
これらのモデルはいずれも、Pragglejaz らが提案した MIP[2]の考え方に基づいている。
MelBERT[4]は、RoBERTa[13]をベースとしたモデルで、目標単語の埋め込みと文脈埋め込みを比較する手法を採用している。
FrameBERT[5]は、RoBERTa を FrameNet[14]データセットでファインチューニングすることで、語の意味フレームの情報を取り入れている。
BasicBERT[6]は、目標単語の基本的な意味を、訓練データから収集した字義的な用例の埋め込みを平均化することで表現している。
一方で、日本語のメタファー検出に関する研究は、その資源の少なさから英語ほど進んでいないのが現実である。
日本語のメタファーコーパスとしては加藤ら[15]がある。
加藤らは、MIP およびMIP VU の手順に基づいて比喩表現情報を現代日本語書き言葉均衡コーパス（BCCWJ）に付与し、BCCWJ-Metaphor[15]を作成した。
BCCWJ-Metaphorにおける印象評定情報の付与については、加藤ら[16]の IPAL 用言例文での印象評定手法を踏襲している。
具体的には、「自然さ」「わかりやすさ」「古さ」「新しさ」「比喩性」の 5 つの観点について、クラウドソーシングを用いて 0〜5 の 6 段階評価を収集している。
加藤ら[17]の研究では、BCCWJ に対して「自然さ」「理解しやすさ」「古さ」「革新性」「比喩性」といった印象評価情報を付与し、特に語の基本的な意味と文脈的な意味の比較において、これらの評価情報が有用であることを示している。
また、メタファーと感情の相互作用に着目した研究も進められている。
青野ら[18]は、Common Crawlコーパスを用いた分析から、感情や主観性がメタファーを生み出す要因の一つであるという可能性を示唆している。


3 手法

本研究では、MIP に基づいて語の基本義と文脈的な意味を比較することでメタファーを検出する。
具体的には以下の 3 つのステップで処理を行う。



3.1 基本義の特定

BCCWJ-Metaphor コーパス[15]の特定品詞1）に対して、分類語彙表[7][8]から適切な基本義を特定する。
基本義の特定には BCCWJ-Metaphor から取得した短単位語彙素と短単位分類語彙表番号を利用する。
具体的な処理手順は以下の通りである。
1） 対象とした品詞の詳細は付録 A を参照1. 分類語彙表での基本義候補の探索短単位語彙素を見出し語として、分類語彙表から基本義候補を探索する。
この際、各候補の確信度を以下のように数値化する。•「●」: 4 点(最も確信度が高い)•「○」: 3 点•「△」: 2 点•「×」: -1 点•「？」: 1 点• その他: 0 点2. 基本義の特定最大確信度を持つ候補を以下の手順で特定する。
• 最大確信度の候補が複数ある場合。
– 入力の短単位分類語彙表番号と一致する候補があればそれを選択– 一致する候補がない場合はランダムに 1つ選択• 候補が見つからない場合は入力の短単位分類語彙表番号をそのまま使用この手法により、単なる頻度や辞書順序ではなく、語義の体系的な分析に基づいて基本義を決定する。
また、確信度による重み付けにより、代表性の高い語義を優先的に選択する。


3.2 用例の検索手法

基本義を持つ用例を分類語彙表番号付与したBCCWJ[19]から効率的に収集するため、以下のような索引づけと検索の手法を用いる。
1. 用例データベースの構築• 語彙素と分類番号による索引を作成する。
2. 用例検索• 用例検索の入力には BCCWJ-Metaphor から取得した以下の二種類を用いる。
– target lemma: 対象語の語彙素– target bunnrui: 基本義の分類番号• 検索は以下の手順により行う。
– 索引から(target lemma, target bunnrui)に対応する用例を取得– 該当する用例からランダムに 1 件を選択– 該当する用例ない場合に対象語の語彙素を用例として使用対象語の語彙素と基本義の分類番号が共に等しい用例の中から、ランダムに用例を選択することで、文脈の多様性を確保する狙いがある。



3.3 BERT を用いたメタファーの検出モ



デル

本研究では、BasicBERT[6]の手法を基に、日本語BERT を用いたメタファー検出を行う。
まず、日本語で学習された BERT モデルをベースモデルとして用い、対象文 𝑉𝑠と基本義用例 𝑉𝑟の両方をエンコードする。
次に、対象語の文脈表現𝑉𝑠,𝑡と基本義の文脈表現 𝑉𝑟 ,𝑡を、それぞれ BERT 出力から対象語のマスク位置の平均を計算することで取得する。
そして、得られた 2 つの文脈表現を結合し[𝑉𝑠,𝑡; 𝑉𝑟]、線形層を通して最終的な 2 値分類（メタファー／非メタファー）を行う。
出力層にはlog-softmax を適用する。


4 データ

本研究では主要な言語資源として、分類語彙表番号悉皆付与データと BCCWJ-Metaphor を用いる。
分類語彙表は、語を意味によって分類・整理した日本語のシソーラスであり、特に山崎ら[7][8]が多義語に対して基本義情報を付与している。
基本義は、認知意味論におけるプロトタイプ的意味に相当し、典型的な語義であること、派生的な意味よりも原義に近いこと、使用頻度が高いことなどの性質を持つ[8]。
また、文脈ごとに意味を判定するのではなく、あらかじめ定められた基本義を使用することで、大規模なデータに対する効率的な意味処理を可能にする。
現代日本語書き言葉均衡コーパス（BCCWJ）は書き言葉の代表的なコーパスであり、本研究では加藤ら[20]が作ったメータファー注釈が付与されたデータ（BCCWJ-Metaphor）を利用する。
このBCCWJ-Metaphor[20]は、BCCWJ の中でも分類語彙表番号が付与された新聞（PN）・雑誌（PM）・書籍（PB）サンプル（347,094 語）を対象とし、MIP に基づき MRW を用いて比喩種別の分類を付与したものである。
比喩表現の認定に際しては、中村[21]の手法を取り入れ、選択制限の違反による結合関係の抽出や、擬人化・具象化などの類似性による転換、換喩・提喩といった比喩の種別情報が付与されている[20]。
各語の文脈的意味が分類語彙表番号により明示されたため、MIP に基づく基本的意味と文脈的意味の比較による比喩性判定が可能となっている。
メタファー検出の対象として、内容語（名詞、動詞、形容詞、副詞など）を中心に 166,989 の短単位書字形を使用する2）。
検出対象となる品詞とその統計情報を表 4 に示し、内容語（名詞、動詞、形容詞、副詞など）を中心に 166,989 の短単位書字形を使用した。
品詞別の分析から、動詞一般（23.08%）、形状詞-助動詞語幹（23.31%）、形容詞一般（20.25%）において、相対的に高いメタファー表現の出現率が確認された。
一方で、名詞-数詞（2.55%）や固有名詞の人名（1.64-4.52%）では、メタファー表現の出現は限定的であった。
表 5 には、検出対象外とした機能語（助詞、助動詞など）や記号類の統計情報を示している。
これらの品詞は主に機能語（助詞、助動詞など）や記号類であり、文の意味構築において内容語と比べて独立した意味を持たず、比喩表現の主要な担い手とはなりにくいと考えられる。
さらに、浅田ら[19]が構築した分類語彙表番号悉皆付与データは、BCCWJ を対象に分類語彙表番号を網羅的に付与したものである。
本研究ではこの研究で付与された分類語彙表番号を用いている。



5 実験

東北大学の bert-base-japanese-v33）をベースモデルとして用い、5 分割交差検証により行う。
再現性を確保するために、乱数の種を 42 に設定した。
評価指標の算出には、BCCWJ-Metaphor[20]に付与された BIO 形式のアノテーションを二値分類（B,I→1，O→0）に変換して使用する。
また、メタファー事例の少なさに対応するため、損失関数にはメタファー事例の重みを 3 倍に設定した重み付きクロスエントロピー損失を採用する。
過学習を防ぐため、dropout 率を 0.4 に設定した。
学習するときに、学習のバッチサイズを 16 に、検証のバッチサイズを 8 に用いた。
エポック数は最大 60 に設定し、評価損失が最小値から 20回連続で上昇した場合に早期停止を行う。
また、学習初期の不安定性を回避して学習率を徐 々に減少させることで安定した学習を促進するため，get linear schedule with warmup を利用し、総学習ステップ数の 10%をウォームアップステップとして設定した。
最適化手法として AdamW を用い、最初の学習率を 2e-05 に設定した。
更に、Gradient Accumulation という勾配累積技術を使用した。
累積ステップを 8 に設定し、実効的なバッチサイズを 8 倍に拡大することができ、GPU メモリ使用2） 対象とした品詞の詳細は付録 A を参照3） https://huggingface.co/tohoku-nlp/bert-base-japanese-v3量を抑えながらより大きなバッチサイズでの学習が可能となった。



6 評価



6.1 メタファー全体

5 分割交差検証による評価実験の結果を表 1 に示す。
全フォールドの平均値と標準偏差を算出したところ、F1 値は 0.766 (± 0.005)、適合率は 0.770 (±0.008)、再現率は 0.762 (± 0.012)であった。
また、損失関数の平均値は 0.685 (± 0.061)であった。
表 1 提案手法の評価結果（平均±標準偏差）評価指標評価値F1 値 0.766 ± 0.005適合率 0.770 ± 0.008再現率 0.762 ± 0.012損失 0.685 ± 0.061この結果から、日本語のメタファー検出において安定した性能を示していることが確認された。
特に、適合率と再現率がともに 0.76 を超え、バランスの取れた検出が実現できた。
また、各指標の標準偏差が比較的小さいので、異なるデータ分割に対しても安定した性能を維持できたと考えられる。



6.2 メタファー種別

表 2 メタファー種別ごとの検出精度（平均±標準偏差）種別全体精度(%) B-タグ精度(%) I-タグ精度(%)結合比喩 81.32 ± 1.75 74.30 ± 2.34 86.11 ± 1.51換喩 77.23 ± 2.89 69.90 ± 3.64 83.74 ± 3.23提喩 62.01 ± 4.71 47.79 ± 6.83 81.11 ± 4.84文脈比喩 71.67 ± 1.11 63.46 ± 1.16 82.56 ± 1.715 分割交差検証による各種メタファー表現の検出結果は表 2，3 に示している。
結合比喩の検出において、5 分割交差検証の平均精度は 81.32%を達成した。
特に、結合の内部要素（I-結合）の検出精度は 86.11%と高く、安定した性能を示している。
一方、結合の開始位置（B-結合）の検出精度は 74.30%とやや低下する傾向が見られた。
これは結合比喩の境界同定がより困難な課題であることを示唆している。
換喩の検出では、平均精度 77.23%を達成した。
内部要素（I-換喩）の検出精度は 83.74%と比較的高いものの、開始位置（B-換喩）の検出は 69.90%にとどまった。
結合比喩と同様に、換喩の境界同定に課題表 3 比喩種別ごとの出現数種別全事例数 B-タグ I-タグ結合比喩 2379 ± 21 964 ± 28 1416 ± 31換喩 1006 ± 17 473 ± 26 533 ± 21提喩 128 ± 15 73 ± 12 55 ± 7文脈比喩 481 ± 17 274 ± 11 208 ± 15が残されていると考えられる。
提喩の検出は最も課題の残る領域であり、平均精度は 62.01%であった。
特に開始位置（B-提喩）の検出精度は 47.79%と低く、内部要素（I-提喩）の検出精度 81.11%との間に大きな差が見られた。
これは提喩の事例数が少ないことに加え、上位概念と下位概念の関係性の判定が困難であると考えられる。
文脈比喩の検出では平均精度 71.67%を達成した。
内部要素（I-文脈）の検出精度は 82.56%である一方、開始位置（B-文脈）の検出精度は 63.46%にとどまった。
開始位置（B-文脈）の検出精度が低い原因として、文脈比喩の特性に起因する問題が考えられる。
すなわち、文脈比喩は前後の文脈情報と密接に関連しており、比喩が成立するための広範な文脈的特徴を把握する必要があるためである。
現行モデルは一文のみを対象としているという制約があり、このことは比喩表現が依存する広い文脈情報を十分に活用できていない可能性を示唆している。


7 考察

本研究では、分類語彙表の分類番号を用いて基本義を持つ例文を探し、利用するため、分類番号が分類語彙表にないもの、BCCWJ 上に基本義の用例が見つからないものについては、本来の機能を発揮できない。
しかし、そのような例はあまり見られなかった。
一方、本研究によるメタファー検出の結果を見てみたところ、基本義を持つ用例が、BCCWJ-Metaphor上で比喩としてラベル付けされている例が散見された。
これらを調べたところ、基本義のスコープが大きなもの（「良い」など）が確認された。
また、BCCWJ-Metaphor の作成者の方に結果を見ていただいたところ、誤っているところは、データ作成時にも迷いそうなところが多いというコメントをいただいた。
今後は、作成者の方と共に結果の詳細なエラー分析を行い、システムを改良する予定である。



謝辞

本研究は JSPS 科研費 JP22K12145、国立国語研究所共同研究プロジェクト「アノテーションデータを用いた実証的計算心理言語学」、および栢森情報科学振興財団・研究助成金「自然言語処理を用いた概念メタファーの抽出」の助成を受けたものです。また、山崎誠先生と柏野和佳子先生には分類語彙表の基本義のデータをご提供いただきました。BCCWJ-Metaphor の作成者である加藤祥先生には、システム結果についてコメントいただきました。御礼申し上げます。

参考文献


[1] George Lakoﬀ and Mark Johnson. Metaphors we liveby. University of Chicago Press, 1980.
[2] Group Pragglejaz. Mip: A method for identifyingmetaphorically used words in discourse. Metaphor andSymbol, Vol. 22, No. 1, pp. 1–39, 2007.
[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and KristinaToutanova. Bert: Pre-training of deep bidirectional trans-formers for language understanding. Proceedings of the2019 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies, Vol. 1, pp. 4171–4186,2019.
[4] Minjin Choi, Sunkyung Lee, Eunseong Choi, Heesoo Park,Junhyuk Lee, Dongwon Lee, and Jongwuk Lee. Melbert:Metaphor detection via contextualized late interaction us-ing metaphorical identiﬁcation theories. Proceedings ofthe 2021 Conference of the North American Chap-ter of the Association for Computational Linguis-tics: Human Language Technologies, pp. 1763–1773,2021.
[5] Yucheng Li, Shun Wang, Chenghua Lin, Frank Guerin,, and Loic Barrault. Framebert: Conceptual metaphordetection with frame embedding learning. Proceedingsof the 17th Conference of the European Chapterof the Association for Computational Linguistics,pp. 1558–1563, 2023.
[6] Yucheng Li, Shun Wang, Chenghua Lin, and Frank Guerin.Metaphor detection via explicit basic meanings modelling.Proceedings of the 61st Annual Meeting of the As-sociation for Computational Linguistics, Vol. 2, pp.91–100, 2023.
[7] 山崎誠, 柏野和佳子. 『分類語彙表』の多義語に対する代表義情報のアノテーション. 言語処理学会 第 23回年次大会 発表論文集, 2017.
[8] 山崎誠, 柏野和佳子, 内山清子, 砂岡和子, 田島毓堂,山元啓史, 韓有錫, 薛根洙. 『分類語彙表増補改訂版』へのアノテーション―基本義の決定―. 計量国語学会第 58 回大会, 2015.
[9] Xiaoyu Tong, Ekaterina Shutova, and Martha Lewis. Re-cent advances in neural metaphor processing: A linguis-tic, cognitive and social perspective. Proceedings of the2021 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies, pp. 4673–4686, 2021.
[10] Ellen Dodge, Jisup Hong, and Elise Stickles. Metanet:Deep semantic automatic metaphor analysis. Proceed-ings of the Third Workshop on Metaphor in NLP,pp. 40–49, 2015.
[11] Beata Beigman Klebanov, Ben Leong, Michael Heilman,and Michael Flor. Diﬀerent texts, same metaphors: Uni-grams and beyond. Proceedings of the Second Work-shop on Metaphor in NLP, pp. 11–17, 2014.
[12] Rui Mao, Chenghua Lin, and Frank Guerin. End-to-endsequential metaphor identiﬁcation inspired by linguistictheories. Proceedings of the 57th Annual Meetingof the Association for Computational Linguistics,pp. 3888–3898, 2019.
[13] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, LukeZettlemoyer, and Veselin Stoyanov. Roberta: A robustlyoptimized bert pretraining approach. arXiv:1907.11692,2019.
[14] Collin F. Baker, Charles J. Fillmore, and John B. Lowe.The berkeley framenet project. 36th Annual Meeting ofthe Association for Computational Linguistics and17th International Conference on ComputationalLinguistics, Vol. 1, pp. 86–90, 1998.
[15] 加藤祥, 菊地礼, 浅原正幸. 『現代日本語書き言葉均衡コーパス』に対する mip に基づく比喩表現情報の付与. 言語処理学会 第 28 回年次大会 発表論文集,pp. 1427–1431, 2022.
[16] 加藤祥, 浅原正幸. Ipal 用言例文への印象評定情報付与と代表義・典型用例の抽出. 計量国語学, Vol. 33,No. 3, pp. 178–193, 2021.
[17] Sachi Kato and Masayuki Asahara. Assigning impressionrating information to the balanced corpus of contem-porary written japanese. Proceedings of PACLIC,Vol. 38, , 2024.
[18] 青 野広 太 郎, 笹 野遼 平, 武 田 浩一. 大 規模 な メタファー自動推定結果に基づくメタファーに関する仮説の検証. 情報処理学会研究報告, Vol. 2023-NL-258,No. 22, pp. 1–5, 2023.
[19] 浅田宗磨, 古宮嘉那子, 浅原正幸. 『現代日本語書き言葉均衡コーパス』に対する分類語彙表番号悉皆付与. 言語処理学会第 30 回年次大会発表論文集, pp.2767–2772, 2024.
[20] 加藤祥, 菊地礼, 浅原正幸. Bccwj-metaphor における比喩表現認定と情報付与作業手順. 言語処理学会 第31 回年次大会 発表論文集, 2025.
[21] 中村明. 比喩表現の理論と分類. 秀英出版, 1977.




A 品詞情報の詳細

表 4 メタファー検出対象の品詞と出現数品詞出現数隠喩の割合(%)名詞-数詞 13,676 2.55名詞-助動詞語幹 35 0.00名詞-普通名詞-一般 51,726 17.93名詞-普通名詞-サ変可能 19,558 18.83名詞-普通名詞-サ変形状詞可能 352 15.06名詞-普通名詞-形状詞可能 2,250 13.29名詞-普通名詞-副詞可能 7,308 4.72名詞-普通名詞-助数詞可能 5,570 10.04名詞-固有名詞-一般1,02217.32名詞-固有名詞-地名-一般 2,714 7.11名詞-固有名詞-地名-国 1,393 19.74名詞-固有名詞-人名-一般 1,327 4.52名詞-固有名詞-人名-名 2,321 1.64名詞-固有名詞-人名-姓 2,240 2.19動詞-一般 19,134 23.08動詞-非自立可能 19,201 7.85形容詞-一般 2,637 20.25形容詞-非自立可能 1,675 4.18副詞 4,597 4.44形状詞-一般 2,417 11.42形状詞-助動詞語幹 961 23.31形状詞-タリ 61 11.48連体詞 2,433 2.75代名詞 3,638 3.38英単語 41 0.00漢文 2 0.00合計 166,989 13.54表5メタファー検出対象外の品詞と出現数品詞出現数隠喩の割合(%)助詞-格助詞 53,970
12.43助詞-係助詞 13,372 7.96助詞-接続助詞 12,581 2.56助詞-副助詞 4,493 5.16助詞-準体助詞 2,808 0.68助詞-終助詞 1,793 0.56助動詞 26,839 4.08補助記号-読点 16,709 1.00補助記号-句点 12,856 0.14補助記号-括弧閉 5,234 4.57補助記号-括弧開 5,220 3.14補助記号-一般 2,838 2.15接頭辞 2,052 9.99接続詞 942 0.64接尾辞-名詞的-一般 7,741 11.65接尾辞-名詞的-助数詞 747 5.62接尾辞-名詞的-副詞可能 461 7.59接尾辞-名詞的-サ変可能 196 25.51接尾辞-形状詞的 666 20.72接尾辞-形容詞的 187 12.30接尾辞-動詞的 44 13.64記号-一般 57 22.81記号-文字 429 7.46感動詞-一般 296 4.39感動詞-フィラー 1 0.00空白 6,215 0.16URL 55 1.82言いよどみ 3 0.00合計 178805 6.48