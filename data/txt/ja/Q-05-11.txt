Multi-modularizing CodeChain ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¿ã‚¹ã‚¯ã®ç´°åˆ†åŒ–ãŒç²¾åº¦ã«ä¸ãˆã‚‹å½±éŸ¿

äº•ä¸Šè²´ä¹‹

1

â€ƒé¶´å²¡æ…¶é›…

21

æ±äº¬å¤§å­¦å·¥å­¦éƒ¨é›»å­æƒ…å ±å·¥å­¦ç§‘â€ƒ

2

æ±äº¬å¤§å­¦å¤§å­¦é™¢æƒ…å ±ç†å·¥å­¦ç³»ç ”ç©¶ç§‘é›»å­æƒ…å ±å­¦å°‚æ”»â€ƒ



{inoue, tsuruoka}@logos.t.u-tokyo.ac.jp



æ¦‚è¦

å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ã‚ˆã†ãªå…¥åŠ›ã«å¯¾ã—å‡ºåŠ›ãŒä¸€æ„ã«å®šã¾ã‚‹ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã«ãŠã„ã¦ã¯ã€ã‚¿ã‚¹ã‚¯ã‚’å°ã‚¿ã‚¹ã‚¯ã®é€£ç¶šã«åˆ†å‰²ã—ã€ãã‚Œãã‚Œã‚’è§£æ±ºã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå–ã‚‰ã‚Œã¦ã„ã‚‹ã€‚
æœ¬ç ”ç©¶ã§ã¯ã‚³ãƒ¼ãƒ‰å†…å®šç¾©é–¢æ•°ã‚’åˆ©ç”¨ã—ã‚¿ã‚¹ã‚¯ã®ç´°åˆ†åŒ–ã‚’è¡Œã†CodeChain ã¨å‘¼ã°ã‚Œã‚‹æ©Ÿæ§‹ã«ã¤ã„ã¦ã€é«˜é›£æ˜“åº¦ã®å•é¡Œã«ãŠã‘ã‚‹ç²¾åº¦å‘ä¸Šã«å‘ã‘ã€é–¢æ•°å†…é–¢æ•°ã‚’åˆ©ç”¨ã—ã•ã‚‰ãªã‚‹ç´°åˆ†åŒ–ã‚’è¡Œã†ã‚ˆã†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ”¹ä¿®ãŠã‚ˆã³é–¢æ•°å†…é–¢æ•°ã®æŠ½å‡ºã€è©•ä¾¡ã‚’è¿½åŠ ã—ãŸã€‚
çµæœã€ä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã€ãƒ¢ãƒ‡ãƒ«ã§ã¯ç²¾åº¦ã®å‘ä¸ŠãŒç¢ºèªã§ããŸã€‚


1 ã¯ã˜ã‚ã«

å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(Large Language Model, LLM)ã¯å¤§é‡ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ§‹æˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‘ã‚¹ã‚’å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å­¦ç¿’ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ã€‚
2017 å¹´ã«ãŠã‘ã‚‹ Attention æ©Ÿæ§‹ã‚’å°å…¥ã—ãŸTransformer ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æå”±[1]ã€ãã®ç¿Œå¹´ã®Transformer ã‚’å°å…¥ã—ãŸå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ GPT [2]ã€BERT [3]ã®é–‹ç™ºã‚’ç«¯ç·’ã¨ã—ã¦ LLM ã®é–‹ç™ºãŒé€²ã¿ã€ã‚ˆã‚Šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤§ããã€é«˜ç²¾åº¦ãªãƒ¢ãƒ‡ãƒ«ãŒç™»å ´ã—ãŸ[4, 5, 6]ã€‚
LLM ã¯æ±ç”¨æ€§ãŒé«˜ãã€æ–‡ç« ã®è£œå®Œã‚„ç”Ÿæˆã«ã¨ã©ã¾ã‚‰ãšã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆã‚„è«–ç†çš„æ¨è«–ã€çŸ¥è­˜å•é¡Œã¸ã®å¿œç­”ãŒå¯èƒ½ã¨ãªã£ã¦ã„ã‚‹ã€‚
ã¾ãŸã€è»¢ç§»å­¦ç¿’ã‚„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®åˆ©ç”¨ã«ã‚ˆã‚Š StarCoder [7]ã‚„WizardCoder [8]ãªã©ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã«ç‰¹åŒ–ã—ãŸ LLM ãƒ¢ãƒ‡ãƒ«ã‚‚å‡ºç¾ã—ãŸã€‚
ã—ã‹ã—ã€LLM ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã«ã¯ä¾ç„¶ã¨ã—ã¦èª²é¡ŒãŒå¤šãã€HumanEval [9]ã‚„ MBPP [10]ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãªã©ã¨ã„ã£ãŸè©•ä¾¡æŒ‡æ¨™ã®å•é¡Œç¾¤ã¯åˆæ­©çš„ãªå†…å®¹ã«ç•™ã¾ã£ã¦ã„ã‚‹ã€‚
ã‚ˆã‚Šè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’ã‚¯ãƒªã‚¢ã§ãã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ç”Ÿæˆã«ãŠã„ã¦ã¯ã€ã‚¿ã‚¹ã‚¯é”æˆã¾ã§ã‚’ã‚ˆã‚Šå°ã•ãªã‚¿ã‚¹ã‚¯ã®é€£ç¶šã¸åˆ†å‰²ã—ã€ãã®é”æˆæ–¹æ³•ã‚’ãã‚Œãã‚Œã«ä¸ãˆã‚‹è¨ˆç”»ã®ç«‹æ¡ˆåŠ›ã‚„å‡ºåŠ›ã‚’ä¿®æ­£ã™ã‚‹èƒ½åŠ›ãŒå¿…è¦ã«ãªã‚‹ã€‚
ä¸Šè¨˜ã®èª²é¡Œã«å¯¾ã—ã€CodeChain [11]ã¯ã€é–¢æ•°å®šç¾©ã‚’ç”¨ã„ã¦ã‚¿ã‚¹ã‚¯ã®ç´°åˆ†åŒ–ã‚’è¡Œã„ã€å‡ºåŠ›ã‹ã‚‰é¸åˆ¥ã•ã‚ŒãŸé–¢æ•°ã‚’åˆ©ç”¨ã—ã¦å†ç”Ÿæˆã™ã‚‹ã“ã¨ã§å‡ºåŠ›ã‚’ä¿®æ­£ã—ã¦ã„ã‚‹ã€‚
ã—ã‹ã—ã€ãã®ç²¾åº¦ã¯ APPS ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯[12]ã«ãŠã„ã¦æœ€é«˜ã§ã‚‚ GPT-3.5 [13]ã¨ä½µç”¨ã—ãŸå ´åˆã®30.24%ã§ã‚ã‚‹ã€‚
ç‰¹ã«æœ€é«˜é›£æ˜“åº¦ã® â€œcompetitionâ€œã®å•é¡Œç¾¤ã«ãŠã„ã¦ã¯ç²¾åº¦ã¯ 12.38 %ã«ã¨ã©ã¾ã‚‹ã€‚
ãã“ã§ã€æœ¬ç ”ç©¶ã§ã¯ç´°åˆ†åŒ–ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’ãã‚Œãã‚Œç´°åˆ†åŒ–ã™ã‚‹æ‰‹æ³•[14, 15]ã‚’ç”¨ã„ã¦ã‚¿ã‚¹ã‚¯ä¸€ã¤ä¸€ã¤ã®ç²’åº¦ã‚’é«˜ã‚ã€ç²¾åº¦ã®å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚


2 CodeChain

æœ¬ç¯€ã§ã¯æœ¬ç ”ç©¶ã®åœŸå°ã¨ãªã‚‹ CodeChain ã«ã¤ã„ã¦èª¬æ˜ã™ã‚‹ã€‚
æœ¬ç ”ç©¶ã§æ‰±ã†å•é¡Œç¾¤ã¯ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚’æƒ³å®šã—ãŸã€å…¥åŠ›ã«å¯¾ã—å‡ºåŠ›ãŒä¸€æ„ã«å®šã¾ã‚‹å•é¡Œã§ã‚ã‚‹ã€‚
å•é¡Œã¯èª¬æ˜æ–‡ã€å…¥åŠ›å¤‰æ•°ã®å‹ãŠã‚ˆã³åˆ¶ç´„ã€å‡ºåŠ›å¤‰æ•°ã®å‹ãŠã‚ˆã³åˆ¶ç´„ã€å…¥å‡ºåŠ›ã®ä¸€ä¾‹ãŒä¸ãˆã‚‰ã‚Œã‚‹ã€‚
ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«ã¯ã€ã‚³ãƒ¼ãƒ‰æå‡ºå‰ã«å‚ç…§ã§ãã‚‹å…¥å‡ºåŠ›å¯¾ãŒå­˜åœ¨ã™ã‚‹ã€‚
ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¿ã‚¹ã‚¯ã§ã¯ã“ã‚Œã«æº–ãˆã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®éç¨‹ä¸Šã§å‚ç…§ã§ãã‚‹å…¥å‡ºåŠ›å¯¾ã®Public test ãƒ‡ãƒ¼ã‚¿ã¨æœ€çµ‚å‡ºåŠ›ã‚’è©•ä¾¡ã™ã‚‹å…¥å‡ºåŠ›å¯¾ã§ã‚ã‚‹ Private test ãƒ‡ãƒ¼ã‚¿ãŒä¸ãˆã‚‰ã‚Œã¦ã„ã‚‹ã€‚
ç¶šã„ã¦å…¨ä½“ã®æ¦‚è¦ã‚’å›³ 1 ã«ç¤ºã™ã€‚
ã¯ã˜ã‚ã«ã€ä»¥ä¸‹ã®ï¼”ã¤ã®æ‰‹é †ã‚’ï¼‘ã‚µã‚¤ã‚¯ãƒ«ã¨ã—ã¦å®šç¾©ã™ã‚‹: (1)Chain of Thought [16]ã‚’ç”¨ã„ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹é–¢æ•°ã‚’ç”¨ã„ãŸã‚¿ã‚¹ã‚¯ã®ç´°åˆ†åŒ–(2) Public Test ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹å‡ºåŠ›ã‚³ãƒ¼ãƒ‰ã®è©•ä¾¡(3)ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’é€šéã—ãŸå‡ºåŠ›ã®é–¢æ•°éƒ¨åˆ†ã®æŠ½å‡º(4) K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ä»£è¡¨é–¢æ•°ã®æŠ½å‡ºãŠã‚ˆã³(1)ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¸ã®ä»£è¡¨é–¢æ•°ã®è¿½è¨˜ã“ã®ä¸€é€£ã®æ‰‹é †ã‚’ 1 ã‚µã‚¤ã‚¯ãƒ«ã¨ã—ã¦æ‰€å®šã®å›æ•°è¡Œã£ãŸã®ã¡ã€å†åº¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä»£è¡¨é–¢æ•°ã‚’åŠ ãˆç”Ÿæˆã‚’è¡Œã£ãŸã‚‚ã®ã‚’æœ€çµ‚å‡ºåŠ›ã¨ã—ã¦æ‰±ã†ã€‚
ä»¥ä¸‹ã€(1)ã‹ã‚‰è©³ç´°ã‚’èª¬æ˜ã™ã‚‹ã€‚
å›³ 1: CodeChainCodeChain ã¯èª²é¡Œã¨ãªã‚‹å•é¡ŒãŠã‚ˆã³å‡ºåŠ›ã¨ã—ã¦ä¸ãˆã‚‰ã‚Œã‚‹ã‚³ãƒ¼ãƒ‰ã®å¯¾ã‚’ One-shot [17]ã§ä¸ãˆã‚‹ã€‚
å‡ºåŠ›ã‚³ãƒ¼ãƒ‰ã¯ã‚³ãƒ¼ãƒ‰ 1ã€2 ã®ã‚ˆã†ã«äºŒæ®µéšã«åˆ†ã‹ã‚Œã¦ãŠã‚Šã€STEP 1 ã§ã¯å‡ºåŠ›ã‚³ãƒ¼ãƒ‰ã«ä½¿ç”¨ã™ã‚‹é–¢æ•°ã«ã¤ã„ã¦é–¢æ•°åã€æ©Ÿèƒ½ã€å…¥å‡ºåŠ›ã®å‹ã®ã¿å®šç¾©ã™ã‚‹ã€‚
STEP 2 ã§ã¯ STEP 1 ã§è¨˜è¼‰ã—ãŸé–¢æ•°ã®è©³ç´°ã‚’å®Ÿè£…ã—ã€ã“ã‚Œã‚’ç”¨ã„ã¦å•é¡Œã‚’è§£ãã‚³ãƒ¼ãƒ‰ã‚’æ§‹æˆã™ã‚‹ã€‚
ã“ã‚Œã«ã‚ˆã‚Šè§£æ±ºã™ã¹ãã‚¿ã‚¹ã‚¯ãŒé–¢æ•°ã®å€‹ã€…ã®æ©Ÿèƒ½å®Ÿè£…ã¨çµ±åˆã«åˆ†å‰²ã•ã‚Œã‚‹ã€‚
CodeChain ã«ãŠã„ã¦ã¯ Public test ã‚’ç”¨ã„ã¦å„ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã‘ã‚‹å‡ºåŠ›ã‚’è©•ä¾¡ã—ã€ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’é€šéã—ãŸå‡ºåŠ›ã®ã¿ã‚’é¸åˆ¥ã™ã‚‹ã€‚
ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ 1: STEP 1 ã®ä¾‹STEP 1: G E NE RA T E SUB - MO DUL ES :` ` ` mo d uledef co u n t _s ta rt _e n d _ ch ar s (w o rds ):"""De s cr ip ti on : Th i s fu n ct ion cou n ts the nu mbe r ofword s that st a rt and en d wi th each c har ac te r .Inpu t :word s (li s t ): A li s t of bin ary w ords .Out p ut :st a rt _c ou nt ( d ef au l td ic t ): A di ct io nar y c on ta i ni ngthe c ount of w ords t hat sta rt with ea c hch a ra ct e r .en d _c ou n t ( def a u l td ic t ): A di ct io n ar y c on t ai ni ngthe c ount of w ords t hat end w ith eachch a ra ct e r ."""` ` `...ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ 2: STEP 2 ã®ä¾‹STEP 2: G E NE RA T E PY THO N CODE` ` ` py t honimp
o rt c ol le ct io n sfrom ut ils im por t *def co u n t _s ta rt _e n d _ ch ar s (w o rds ):st a rt _c ou nt = co ll ec ti o ns . d e f a ul td ic t ( int )en d _c ou n t = co ll e ct io ns . de fa ul t di ct ( in t )for w ord in wor d s :st a rt _c ou nt [ w ord [0 ]] += 1end _c ou n t [wo r d [ -1 ]] += 1ret u rn s t art _cou nt , en d_ cou nt...t = int ( in p ut ())for _ in ran ge ( t ):n = int ( in p ut ())word s = []for _ in ran ge ( n ):word s . app end ( inpu t ())tot al_ rev ers ed , r ev er se d_ wo rd s = s ol ve _t a sk ( wor d s )prin t ( to t a l _ r e v e rs ed )if t ot al _r ev er se d !
= 0:prin t (* re ve rs ed _w or ds )` ` `ä¸Šè¨˜ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’é€šéã—ãŸã‚³ãƒ¼ãƒ‰ã‹ã‚‰é–¢æ•°å®Ÿè£…éƒ¨åˆ†ã®ã¿ã‚’åˆ‡ã‚Šå‡ºã™ã€‚
å–ã‚Šå‡ºã•ã‚ŒãŸé–¢æ•°ã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’æœ‰ã™ã‚‹äº‹å‰å­¦ç¿’æ¸ˆã¿ LLM ã‚’ç”¨ã„ã¦å®Ÿæ•°å€¤ãƒ™ã‚¯ãƒˆãƒ«ã¸å¤‰æ›ã‚’è¡Œã†ã€‚
ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ã—ã¦ç”¨ã„ã‚‰ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ CodeBERT [ 18]ã€CodeT5+ [19]ã€StarCoder[7]ã® 3 ç¨®é¡ã‹ã‚‰é¸ã°ã‚Œã‚‹ã€‚
æœ¬å®Ÿé¨“ã§ã¯ StarCoder ã«çµ±ä¸€ã™ã‚‹ã€‚
ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã¸å¤‰æ›ã•ã‚ŒãŸé–¢æ•°ç¾¤ã¯ K-means æ³•ã«ã‚ˆã‚Šã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã€é¡ä¼¼ã—ã¦ã„ã‚‹é–¢æ•°ã®ã†ã¡ä»£è¡¨ã¨ãªã‚‹ã‚‚ã®ã®ã¿ã‚’æŠ½å‡ºã™ã‚‹ã€‚
ã‚¯ãƒ©ã‚¹ã‚¿ ğ‘˜ ã«ãŠã‘ã‚‹ä»£è¡¨å€¤ ğ¶ğ‘˜ã¯ã€ã‚¯ãƒ©ã‚¹ã‚¿å†… ğ‘– ç•ªç›®ã®è¦ç´ ã‚’ ğ‘†ğ‘˜ğ‘–ã€ã‚¯ãƒ©ã‚¹ã‚¿å†…è¦ç´ ã®å¹³å‡ã‚’ ğœ‡ğ‘˜ã¨ã—ã¦ä»¥ä¸‹ã®å¼ 1 ã®é€šã‚Šæ±ºå®šã•ã‚Œã‚‹ã€‚
æŠ½å‡ºã•ã‚ŒãŸé–¢æ•°ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½è¨˜ã•ã‚Œã‚‹ã€‚
ã“ã‚Œã‚’ç”¨ã„ã¦å†åº¦ç”Ÿæˆã€è©•ä¾¡ã€é–¢æ•°æŠ½å‡ºã‚’ç¹°ã‚Šè¿”ã™ã€‚
ğ¶ğ‘˜=argminğ‘†ğ‘˜||ğ‘†ğ‘˜ğ‘–âˆ’ ğœ‡ğ‘˜||(1)

3 ææ¡ˆæ‰‹æ³•



3.1 é–¢æ•°ã®å¤šé‡åˆ†è§£

ç¶šã„ã¦æœ¬ç ”ç©¶ã§æ§‹æˆã™ã‚‹ Multi-modularizingCodeChain ã®ä¸»è»¸ã§ã‚ã‚‹é–¢æ•°ã®å¤šé‡åˆ†è§£ã®æ‰‹æ³•ã«ã¤ã„ã¦èª¬æ˜ã™ã‚‹ã€‚
CodeChain ã§ã¯ã€ã‚³ãƒ¼ãƒ‰å…¨ä½“ã§é”æˆã™ã¹ãã‚¿ã‚¹ã‚¯ã‚’ç‰¹å®šã®æ©Ÿèƒ½ã‚’æœãŸã™é–¢æ•°ã‚’è¤‡æ•°å®šç¾©ã™ã‚‹ã“ã¨ã§å€‹ã€…ã®é–¢æ•°ã®å®Ÿè£…ã«ã‚¿ã‚¹ã‚¯ã‚’åˆ†å‰²ã™ã‚‹ã€‚
ã“ã®é–¢æ•°å®Ÿè£…ã‚’ã•ã‚‰ã«è¤‡æ•°ã®é–¢æ•°å†…é–¢æ•°ã«ã‚ˆã£ã¦ç´°åˆ†åŒ–ã™ã‚‹ã“ã¨ã§è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã®é›†åˆã¨ã—ã¦æ‰ãˆã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚
æœ¬ç ”ç©¶ã§ã¯ã€é–¢æ•°å†…é–¢æ•°ã®åˆ©ç”¨ã«ã‚ˆã‚Šä¸€åº¦ã®ç”Ÿæˆã§ã‚¿ã‚¹ã‚¯ã®å¤šæ®µéšåˆ†è§£ã‚’è¡Œã†ã€‚
ã‚³ãƒ¼ãƒ‰3 ã«ç¤ºã™ã‚ˆã†ã«ã‚ã‚‹é–¢æ•°ã®å®šç¾©è¨˜è¿°å†…éƒ¨ã§å†åº¦é–¢æ•°ã‚’å®šç¾©ã™ã‚‹æ–‡æ§‹é€ ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å°å…¥ã™ã‚‹ã€‚
ã“ã‚Œã«ã‚ˆã‚Šç”Ÿæˆæ™‚ã«å¿…è¦ã«å¿œã˜ã¦é–¢æ•°å†…é–¢æ•°ã®å®šç¾©ã«ãŠã„ã¦ã‚‚å‡ºåŠ›ä¾‹ã‚’åˆ©ç”¨ã—ã¦é–¢æ•°å†…é–¢æ•°ãŒç”Ÿæˆã•ã‚Œã‚‹ãŸã‚ã€å¿…è¦ã«å¿œã˜é–¢æ•°ã®æœãŸã™ã¹ãã‚¿ã‚¹ã‚¯ã‚’ç´°åˆ†åŒ–ã§ãã‚‹ã€‚
ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ 3: é–¢æ•°å†…é–¢æ•°ã‚’å«ã‚€å®šç¾©ã®ä¾‹def so lv e _t as k ( wo r ds ):def is _r e ve rs ed (s ):ret u rn s == s [:: -1]def co un t _ r ev er se d_ w o r ds ( word s ):coun t = 0...

3.2 Multi-modularizing CodeChain

å›³ 2 ã«å…¨ä½“å›³ã‚’ç¤ºã™ã€‚
ã‚³ãƒ¼ãƒ‰ 4 ã«å¤‰æ›´ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¤ºã™ã€‚
èµ¤å­—éƒ¨åˆ†ãŒ CodeChain ã‹ã‚‰ã®å¤‰æ›´ç‚¹ã§ã‚ã‚‹ã€‚
æ–°ãŸã«é–¢æ•°å†…é–¢æ•°ã«ã¤ã„ã¦ã‚‚æ©Ÿèƒ½ã®è¨˜è¿°ã‚’è¡Œã† STEP ã‚’è¿½åŠ ã—ã€å…¨ 3 S TEP ã®æ§‹æˆã¨ãªã£ã¦ã„ã‚‹ã€‚
å‡ºåŠ›ä¾‹ã«ã¯é–¢æ•°å†…é–¢æ•°ã‚’å«ã‚€é–¢æ•°ã¨å«ã¾ãªã„é–¢æ•°ã®ä¸¡æ–¹ã‚’ä¸ãˆã€é–¢æ•°å†…é–¢æ•°ã‚’å¿…ãšã—ã‚‚å«ã¾ãªã„ã‚ˆã†ã«ã™ã‚‹ã€‚
å…¥åŠ›ä¾‹ã¯ CodeChain ã¨å…±é€šã§ APPS train ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œç•ªå· 0 ã®å•é¡Œã‚’ç”¨ã„ã‚‹ã€‚
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä¸ãˆã‚‹å‡ºåŠ›ä¾‹ã¯ã‚³ãƒ¼ãƒ‰ 5 ã«è¨˜è¼‰ã™ã‚‹ã€‚
ãã—ã¦å‰ç¯€ã§èª¬æ˜ã—ãŸé€šã‚Šã€ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’é€šéã—ãŸã‚³ãƒ¼ãƒ‰ã‹ã‚‰é–¢æ•°ã€é–¢æ•°å†…é–¢æ•°ã‚’å€‹åˆ¥ã«æŠ½å‡ºã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†ã€‚
ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã¯å„ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã„ã¦ãã‚Œãã‚Œ 5ã€4ã€3ã€2ã€1 ã¨ã™ã‚‹ã€‚
ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ 4: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é››å½¢Belo w is a c om p et it iv e p ro g ra mm in g qu es t io n . R e adthe que st ion ca r ef ul l y .* I ns tr uc t io n *Dev elo p a well - st ru ct ure d P y tho n so lu t io n f o r thepro vi d ed pro ble m that ob eys the c o ns tr ai nt s an dpas s es the ex amp le te s t case s . E nsu r e m odu la ri tyand co ns i de ri ng po t en ti a l edg e c ases and f ai l ur es .Star t by ou tli ni ng the r e qu ire d code mod u les ,inc lu di n g f unc ti o n h ead ers and s ig na t ur es .Sub s equ ent ly , pr oce ed to i mp l em en t each mo dul e tocre a te the fin al code .In s i mp l er terms , c rea t e a cl ean and o r ga ni z ed Pyt h onsol ut i on for the giv en pr obl em . Br eak it dow n i n tosma lle r par ts ( mo d ul e s ) w ith cle ar f u nc tio n na m esand i nput / out put sp ec i f i
c a t i o n s . Onc e thestr uc tu r e is read y , writ e the a ctu a l code for eachmod u le to c om p le te the s o lu tio n .The o utp ut cod e n eeds to r ead from and wri te tosta nd a rd IO . P l eas e wrap you r c o de an s wer u sin g` ` ` .### Exa mpl e 1### T ASK :<< E x am ple _pr ob l em > >### REL EV ANT FU N CT IO N S :<< module s > >### REL EV ANT SUB - F UN CT I ON S :<< sub - modules >>### RES PO NSE :STEP 1: G E NE RA T E M O DU L ES :<< e x am p le gen er a te d modules >>STEP 2: G E NE RA T E SUB - MO DUL ES :<< e x am p le gen er a te d sub - modules >>STEP 3: G E NE RA T E PY THO N CODE<< e x am p le gen er a te d code > >-- -- - -- -- - - - -- - - -### Exa mpl e 2### T ASK :<< new p roblem >>### REL EV ANT FU N CT IO N S :<< module s > >### REL EV ANT SUB - F UN CT I ON S :<< sub - modules >>### RES PO NSE :å›³ 2: Multi-modularizing CodeChain

4 å®Ÿé¨“



4.1 å®Ÿé¨“è¨­å®š

å‰ç¯€ã§èª¬æ˜ã—ãŸ Multi-modularizing CodeChain ã‚’ç”¨ã„ã¦å‡ºåŠ›ã®ç²¾åº¦æ¤œè¨¼ã‚’è¡Œã†ã€‚
ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ GPT-3.5-turbo-16k [13]ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ WizardCoder-15B-V1.0 ã‚’ç”¨ã„ã‚‹ã€‚
WizardCoder ã¯ VLLM ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯[20]ã‚’ä½¿ç”¨ã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã™ã‚‹ã€‚
Temperature (ã©ã®ç¨‹åº¦ãƒ©ãƒ³ãƒ€ãƒ ã«å¿œç­”ã™ã‚‹ã‹ã‚’å®šã‚ã‚‹ 0ã€œ1 ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)ã¯å…ˆè¡Œç ”ç©¶[11]ã«å€£ã„ 0.6 ã¨ã™ã‚‹ã€‚
æœ€å¤§å‡ºåŠ›é•·ã¯ 8192 ã¨ã™ã‚‹ã€‚
å‡ºåŠ›ã‚³ãƒ¼ãƒ‰ã«ã¤ã„ã¦ã¯ 5 å¿œç­”/å…¥åŠ›Ã— 4 å…¥åŠ›ã®å½¢å¼ã§åé›†ã—ã€Pass@ğ‘˜ ã‚’ç®—å‡ºã—ã¦æ¯”è¼ƒã™ã‚‹ã€‚
Pass@ ğ‘˜ ã¯ä¸€èˆ¬ã«ä»¥ä¸‹ã®å¼ 2 ã§ç®—å‡ºã•ã‚Œã‚‹ã€‚
Pass@ğ‘˜ = ğ”¼[1 âˆ’ğ‘›âˆ’ğ‘ğ¶ğ‘˜ğ‘›ğ¶ğ‘˜](2)(ğ‘› : å‡ºåŠ›ã‚³ãƒ¼ãƒ‰æ•°ã€ ğ‘ : æ­£è§£ã—ãŸå‡ºåŠ›ã‚³ãƒ¼ãƒ‰æ•°)ä½¿ç”¨ã™ã‚‹å•é¡Œãƒ‡ãƒ¼ã‚¿ã¯ APPS ãŠã‚ˆã³ CodeContests[21]ã® test ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã€APPS ã«ã¤ã„ã¦ã¯é›£æ˜“åº¦ã”ã¨ã«ç²¾åº¦ã‚’ã€å„ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ 3 å›ã®å‡ºåŠ›ã®å¹³å‡ã‚’ã¨ã£ã¦æ¯”è¼ƒã™ã‚‹ã€‚
APPS ã® test ãƒ‡ãƒ¼ã‚¿ã¯5000 å•ã‚ã‚Šã€å‡ºåŠ›ç”Ÿæˆã«é•·æ™‚é–“ã‚’è¦ã—ãŸã€‚
ã—ãŸãŒã£ã¦ 1 å›åˆ†ã®å–å¾—ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã€åŒãƒ‡ãƒ¼ã‚¿å†…ã‹ã‚‰ã‚ˆã‚Šå°ã•ã„ã‚µã‚¤ã‚ºã®å•é¡Œç¾¤ã‚’å–ã‚Šå‡ºã—ã€ãã®èª¤å·®ã‚’æ¨å®šã™ã‚‹ã€‚
çµ¶å¯¾èª¤å·®ã¯å–ã‚Šå‡ºã—ãŸå•é¡Œã«å¿œã˜ã¦å¤‰å‹•ã™ã‚‹ãŸã‚ã€åŒä¸€ãƒ¢ãƒ‡ãƒ«ã®ã«ãŠã‘ã‚‹ç›¸å¯¾èª¤å·®ã«ã¤ã„ã¦åŒä¸€ãƒ‡ãƒ¼ã‚¿å†…ã§ã‚ã‚Œã°ã©ã®éƒ¨åˆ†ã‚’å–ã‚Šå‡ºã—ã¦ã‚‚ä¸€å®šã§ã‚ã‚‹ã¨ä»®å®šã—ã€test ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é›£æ˜“åº¦ã”ã¨ã« 50 å•ãšã¤ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã³ã€ãã®å‡ºåŠ›çµæœã®ç›¸å¯¾èª¤å·®ã‚’ç®—å‡ºã™ã‚‹æ“ä½œã‚’ 3 å›è¡Œã„ã€ãã®ã†ã¡æœ€å¤§å€¤ã‚’å‡ºåŠ›ã®ç›¸å¯¾èª¤å·®ã¨ã—ã¦è¨ˆç®—ã—ãŸã€‚


4.2 å®Ÿé¨“çµæœ


å®Ÿé¨“çµæœã‚’è¡¨ 1ã€2 ã«ç¤ºã™ã€‚
CodeChain ãŠã‚ˆã³å„ãƒ¢ãƒ‡ãƒ«ã®æ©Ÿæ§‹ã‚’ä»‹ã•ãªã„ç”Ÿæˆã®çµæœã¯å…ˆè¡Œç ”ç©¶[11]ã‹ã‚‰å¼•ç”¨ã—ãŸã€‚
APPS ã«ã¤ã„ã¦ã¯å…¨ã¦ã®é›£æ˜“åº¦ã§æœ‰æ„ãªç²¾åº¦ä½ä¸‹ãŒç¢ºèªã•ã‚Œã€CodeContests ã§ã¯ã€WizardCoder ã‚’ç”¨ã„ãŸå ´åˆã¯ Validation data ã«ãŠã‘ã‚‹ pass@1 ã‚’é™¤ãæœ‰æ„ãªç²¾åº¦ã®å‘ä¸ŠãŒç¢ºèªã•ã‚Œã€GPT-3.5-turbo-16k ã«ãŠã„ã¦ã¯æœ‰æ„ãªç²¾åº¦ä½ä¸‹ãŒç¢ºèªã•ã‚ŒãŸã€‚
è¡¨ 1: APPS test ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹ç²¾åº¦æ¯”è¼ƒModel Introductory Interview Competition AllWizardCoder-15B 26.04 4.21 0.81 7.90+ CodeChain 26.29 7.49 3.75 10.50+ Multi-modularizing CodeChain 16.29 Â± 1.47 4.81 Â± 0.43 1.4 Â± 0.35 6.44 Â± 0.78è¡¨ 2: CodeContests ã«ãŠã‘ã‚‹ç²¾åº¦æ¯”è¼ƒModelValid TestPass@1 Pass@5 Pass@1 Pass@5WizardCoder-15B 1.11 3.18 1.98 3.27+ CodeChain 2.35 3.29 2.48 3.30+ Multi-modularizing CodeChain 2.26 Â± 0.30 3.90 Â± 0.33 3.23 Â± 0.34 5.67 Â± 0.34GPT-3.5-turbo-16k 6.81 16.23 5.82 11.16+ CodeChain 12.86 16.91 10.27 14.11+ Multi-modularizing CodeChain 8.51 Â± 0.15 13.90 Â± 0.33 6.81 Â± 0.65 11.55 Â± 0.65

4.3 è€ƒå¯Ÿ

APPSã€CodeContests ã®ä¸¡æ–¹ã§ CodeChain ã‚ˆã‚Šã‚‚ç²¾åº¦ãŒä½ä¸‹ã—ãŸè¦å› ã«ã¤ã„ã¦ã¯ã€Multi-modulariingCodeChain ã«ãŠã„ã¦ã€é€”ä¸­ã¾ã§ã¯ç²¾åº¦ãŒå‘ä¸Šã—ãŸãŒæœ€çµ‚ã‚µã‚¤ã‚¯ãƒ«ã§ç²¾åº¦ãŒä¸‹é™ã—ãŸã“ã¨ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã€‚
å›³ 3 ã¯ CodeContests ã«ãŠã‘ã‚‹ Multi-modularizingCodeChain (æŠ˜ã‚Œç·š)ã¨ CodeChain ã®æœ€çµ‚å‡ºåŠ›å€¤(ç›´ç·š)ã®æ¯”è¼ƒã§ã‚ã‚‹ã€‚
å®Ÿéš›ã®å‡ºåŠ›ã‚³ãƒ¼ãƒ‰ã«ãŠã„ã¦STEP1ã€STEP 2 ã«ãŠã„ã¦å®£è¨€ã•ã‚ŒãŸé–¢æ•°ã€é–¢æ•°å†…é–¢æ•°ã¨STEP 3 ã§å®Ÿè£…ã•ã‚ŒãŸé–¢æ•°ãŒä¸€è‡´ã—ã¦ã„ãªã„ã‚‚ã®ãŒè¦‹ã‚‰ã‚ŒãŸã€‚
STEP 1ã€STEP 2 ã®æ§‹é€ ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ãŸã‚ä¸¡è€…ã®æ··åœ¨ãŒç”Ÿã˜ã¦ãŠã‚Šã€ã“ã‚ŒãŒã‚µã‚¤ã‚¯ãƒ«ã‚’é€šã—ã¦ç²¾åº¦ãŒå®‰å®šåŒ–ã—ãªã„ç†ç”±ã§ã‚ã‚‹ã¨è€ƒãˆã‚‹ã€‚
å›³ 4 ã¯ APPS ã«ãŠã‘ã‚‹æœ€çµ‚å‡ºåŠ›ã«ãŠã„ã¦ã€Privatetest ã‚’é€šéã—ãŸã‚³ãƒ¼ãƒ‰ã«ãŠã‘ã‚‹é–¢æ•°å†…é–¢æ•°ã®æ•°ã‚’é›†è¨ˆçµæœã§ã‚ã‚‹ã€‚
ãã®å¹³å‡ã¯ 1.35 å€‹ã§ã‚ã‚Šã€é–¢æ•°å†…é–¢æ•°ã‚’æœ‰ã—ã¦ã„ãŸã‚³ãƒ¼ãƒ‰ã®å‰²åˆã¯ 28.59%ã§ã‚ã£ãŸã€‚
Multi-Modularizing CodeChain ã¯ã‚³ãƒ¼ãƒ‰å…¨ä½“ã®ç”Ÿæˆã‚’1 åº¦ã«å®Ÿè¡Œã•ã›ã‚‹ãŸã‚é–¢æ•°å†…é–¢æ•°ã®ç”Ÿæˆå¯å¦ã‚’æ˜ç¤ºçš„ã«æŒ‡ç¤ºã—ã¦ã„ãªã„ãŸã‚ã€ä¸€éƒ¨ã‚³ãƒ¼ãƒ‰ã§ã¯å¤šæ®µéšãªã‚¿ã‚¹ã‚¯åˆ†è§£ãŒæˆåŠŸã—ã¦ã„ã‚‹ã‚‚ã®ã®ãã®åˆ©ç”¨ç‡ã¯ä½ãã€ç¢ºèªã•ã‚ŒãŸç²¾åº¦å‘ä¸Šã‚‚åƒ…ã‹ã§ã‚ã£ãŸã¨è€ƒãˆã‚‹ã€‚
å›³ 3: ç²¾åº¦æ¨ç§»æ¯”è¼ƒ(ãƒ¢ãƒ‡ãƒ«: GPT-3.5)å›³ 4: ã‚³ãƒ¼ãƒ‰ã”ã¨ã®é–¢æ•°å†…é–¢æ•°ã®æ•°ã¾ãŸã€Multi-modularizing CodeChain ã¯ 1 å›ç›®ã®ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã„ã¦ Public test ã‚’é€šéã™ã‚‹ã‚±ãƒ¼ã‚¹ãŒãªã„å•é¡Œã«ã¯å†ç”Ÿæˆã«ã‚ˆã‚‹æ”¹å–„ã‚’è¡Œã†ã“ã¨ãŒã§ããšç²¾åº¦ã¯å‘ä¸Šã›ãšã€åŠ¹æœã‚’ç™ºæ®ã§ãã‚‹å•é¡ŒãŒé™å®šçš„ã§ã‚ã‚‹ã€‚
GPT-3.5 ã‚’ç”¨ã„ãŸéš›ã§ã‚ã£ã¦ã‚‚åŠåˆ†ç¨‹åº¦ã®å•é¡Œã«å¯¾ã—ã¦ã¯ Public test ã‚’ä¸€åˆ‡é€šéã§ããšã€ä»¥é™ã®ã‚µã‚¤ã‚¯ãƒ«ãŒæ©Ÿèƒ½ã—ã¦ã„ãªã„ã€‚
ã‚ˆã‚Šæ ¹æœ¬çš„ãªç²¾åº¦å‘ä¸Šã«ã¯ Public test ã‚’é€šéã—ãªã„å‡ºåŠ›ã¸ä½œç”¨ã™ã‚‹ LLM ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®ãƒ‡ãƒãƒƒã‚°ä¿®æ­£æ©Ÿæ§‹ãŒå¿…è¦ã«ãªã‚‹ã€‚



5 ãŠã‚ã‚Šã«

æœ¬ç ”ç©¶ã§ã¯ LLM ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’é–¢æ•°ã‚’ç”¨ã„ã¦ç´°åˆ†åŒ–ã™ã‚‹ CodeChain ã«ãŠã„ã¦ã€ç´°åˆ†åŒ–ã‚’å¤šæ®µåŒ–ã™ã‚‹ãŸã‚é–¢æ•°å†…é–¢æ•°ã‚’ç”¨ã„ãŸæ§‹é€ ã¸æ‹¡å¼µã—ãŸã€‚
çµæœã€ç²¾åº¦å‘ä¸ŠãŒä¸€éƒ¨ã‚¿ã‚¹ã‚¯ã§ã¯ç¢ºèªã§ããŸã‚‚ã®ã®ç²¾åº¦ä½ä¸‹ã‚‚å¤šãç¢ºèªã•ã‚ŒãŸã€‚
ã¾ãŸã€å¤šæ®µéšã«ã‚¿ã‚¹ã‚¯ã‚’åˆ†å‰²ã§ããŸå•é¡Œã¯ä¸€éƒ¨ã«é™ã‚‰ã‚Œã‚‹ã€‚
ã‚µã‚¤ã‚¯ãƒ«ã‚’é€šã—ã¦ã®ç²¾åº¦ã®å®‰å®šåŒ–ã€é–¢æ•°å†…é–¢æ•°ã®ã‚ˆã‚ŠåŠ¹ç‡çš„ãªåˆ©ç”¨æ–¹æ³•ã®æ¨¡ç´¢ãŒä»Šå¾Œã®èª²é¡Œã§ã‚ã‚‹ã€‚



å‚è€ƒæ–‡çŒ®


[1] Ashish Vaswani, Noam M. Shazeer, and et al. Attention isall you need. In Neural Information Processing Sys-tems, 2017.
[2] Alec Radford, Karthik Narasimhan, Tim Salimans, andIlya Sutskever. Improving language understanding by gen-erative pre-training, 2018.
[3] Jacob Devlin Ming-Wei Chang Kenton and Lee KristinaToutanova. Bert: Pre-training of deep bidirectional trans-formers for language understanding. In Proceedings ofnaacL-HLT, Vol. 1, p. 2. Minneapolis, Minnesota, 2019.
[4] Hugo Touvron, Thibaut Lavril, and et al. LLaMA: Openand Eï¬ƒcient Foundation Language Models. arXiv e-prints, p. arXiv:2302.13971, February 2023.
[5] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,Maarten Bosma, Gaurav Mishra, Adam Roberts, ..., andNoah Fiedel. PaLM: Scaling Language Modeling withPathways. Journal of Machine Learning Research,Vol. 24, No. 240, pp. 1â€“113, 2023.
[6] Colin Raï¬€el, Noam Shazeer, and et al. Exploring the limitsof transfer learning with a uniï¬ed text-to-text transformer.Journal of Machine Learning Research, Vol. 21, No.140, pp. 1â€“67, 2020.
[7] Raymond Li, Loubna Ben allal, and et al. StarCoder: maythe source be with you!Transactions on MachineLearning Research, 2023. Reproducibility Certiï¬cation.
[8] Ziyang Luo, Can Xu, and et al. Wizardcoder: Empow-ering code large language models with evol-instruct. InThe Twelfth International Conference on LearningRepresentations, 2024.
[9] Mark Chen, Jerry Tworek, and et al. Jun. Evaluating LargeLanguage Models Trained on Code. arXiv e-prints, p.arXiv:2107.03374, July 2021.
[10] Jacob Austin, Augustus Odena, and et al. Program Syn-thesis with Large Language Models. arXiv e-prints, p.arXiv:2108.07732, August 2021.
[11] Hung Le, Hailin Chen, Amrita Saha, Akash Gokul, DoyenSahoo, and Shaï¬q Joty. Codechain: Towards modularcode generation through chain of self-revisions with rep-resentative sub-modules. In The Twelfth InternationalConference on Learning Representations, 2024.
[12] Dan Hendrycks, Steven Basart, and et al. Measuring cod-ing challenge competence with APPS. In Thirty-ï¬fthConference on Neural Information Processing Sys-tems Datasets and Benchmarks Track (Round 2),2021.
[13] Junjie Ye, Xuanting Chen, and et al. A ComprehensiveCapability Analysis of GPT-3 and GPT-3.5 Series Models,2023.
[14] Jingchang Chen, Hongxuan Tang, Zheng Chu, QianglongChen, Zekun Wang, Ming Liu, and Bing Qin. Divide-and-conquer meets consensus: Unleashing the power offunctions in code generation. In The Thirty-eighth An-nual Conference on Neural Information ProcessingSystems, 2024.
[15] Jierui Li, Hung Le, Yingbo Zhou, Caiming Xiong, SilvioSavarese, and Doyen Sahoo. CodeTree: Agent-guidedTree Search for Code Generation with Large LanguageModels, 2024.
[16] Mirac Suzgun, Nathan Scales, and et al. Challenging big-bench tasks and whether chain-of-thought can solve them.In ACL (Findings), pp. 13003â€“13051, 2023.
[17] Tom Brown, Benjamin Mann, and et al. Language modelsare few-shot learners. Advances in neural informationprocessing systems, Vol. 33, pp. 1877â€“1901, 2020.
[18] Zhangyin Feng, Daya Guo, and et al. CodeBERT: A Pre-Trained Model for Programming and Natural Languages.In Trevor Cohn, Yulan He, and Yang Liu, editors, Findingsof the Asso ciation for Computational Linguistics:EMNLP 2020, pp. 1536â€“1547, Online, November 2020.Association for Computational Linguistics.
[19] Yue Wang, Hung Le, Akhilesh Gotmare, Nghi Bui, JunnanLi, and Steven Hoi. CodeT5+: Open code large languagemodels for code understanding and generation. In HoudaBouamor, Juan Pino, and Kalika Bali, editors, Proceed-ings of the 2023 Conference on Empirical Methodsin Natural Language Processing, pp. 1069â€“1088, Sin-gapore, December 2023. Association for ComputationalLinguistics.
[20] Woosuk Kwon, Zhuohan Li, and et al. Eï¬ƒcient memorymanagement for large language model serving with page-dattention. In Proceedings of the 29th Symposiumon Operating Systems Principles, pp. 611â€“626, 2023.
[21] Yujia Li, David Choi, and et al. Competition-level codegeneration with AlphaCode. Science, Vol. 378, No. 6624,pp. 1092â€“1097, December 2022.




A å®Ÿé¨“ã«ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿ã®è©³ç´°

ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ 5: One-shot ã§ä¸ãˆã‚‹å‡ºåŠ›ä¾‹STEP 1: G E NE RA T E M O DU L ES :` ` ` mo d uledef co u n t _s ta rt _e n d _ ch ar s (w o rds ):"""De s cr ip ti on : Th i s fu n ct ion cou n ts the nu mbe r ofword s t hat sta rt and en d wi t h e ach c h ar ac ter .Inpu t :word s ( li s t ): A lis t of bin a ry w o rds .Out p ut :st a rt _c ou nt ( def au lt di c t ): A d ic t io na ry c on ta in i ngthe c ount of w ords t hat sta rt with ea c hch a ra ct e r .en d _c ou n t ( def a u l td ic t ): A di ct io n ar y c on t ai ni ngthe c ount of w ords t hat end w ith eachch a ra ct e r ."""` ` `` ` ` mo d uledef re ve rs e_ wo rd s ( wor ds , re ve rs ed _i n d i c e s ):"""De s cr ip ti on : Th i s fu n ct ion re v er ses the s pe ci f ie dword s in the g i ven li s t .Inpu t :word s ( li s t ): A lis t of bin a ry w o rds .re ve rs ed _i nd ic es ( li s t ): A li s t of ind ice sin d ic at in g
th e w ords to be r ev ers ed .Out p ut :re ve rs ed _w or d s ( lis t ): A new list of w o rds wi t h th espe ci fi e d wo rds r eve rs ed ."""` ` `` ` ` mo d uledef so lv e _t as k ( wo r ds ):"""De s cr ip ti on : Th i s fu n ct ion cou n ts the tot alrev er s ed w ords and th eir i nde xes .Inpu t :word s ( li s t ): A lis t of bin a ry w o rds .Out p ut :to ta l_ re ve rs e d (int ): A in te g er of the nu mbe r ofrev er s ed w ords .re ve rs ed _w or d s (l ist ): A list of i n de x es of r ev e rs dword s ."""` ` `STEP 2: G E NE RA T E SUB - MO DUL ES :` ` ` su bm odu ledef re ve rs e_ w or d (w o rd ):"""De s cr ip ti on : Th i s fu n ct ion re v er ses the g i venword .Inpu t :word ( s t r ): A b i nar y word .Out p ut :str : The re ve r se d word ."""` ` `` ` ` su bm odu ledef is _r e ve rs ed (s ):"""De s cr ip ti on : Th i s fu n ct ion che c ks if the giv enstr i ng is a re v er sed str i ng .Inpu t :s
( str ): A st rin g of bin ary d igi ts .Out p ut :bool : True if the giv e n str ing is a re ver se dstring , F alse oth er wis e ."""` ` `` ` ` su bm odu ledef co u n t _ r ev er se d_ w o r ds ( word s ):"""De s cr ip ti on : Th i s fu n ct ion cou n ts the tot alrev er s ed w ords and th eir i nde xes .Inpu t :word s ( li s t ): A lis t of bin a ry w o rds .Out p ut :int : The nu m ber of rev er sed word s .list : A list of i nd e xe s of re v er sd wo r ds ."""` ` `STEP 3: G E NE RA T E PY THO N CODE` ` ` py t hondef co u n t _s ta rt _e n d _ ch ar s (w o rds ):st a rt _c ha rs = {}end _c ha r s = {}for w ord in wor d s :if word [0] not in s ta rt _c ha r s :st a rt _c ha rs [ w ord [0 ]] = 0st a rt _c ha rs [ w ord [0 ]] += 1if word [ -1] not in en d_ ch a rs :en d _c ha r s [wo r d [ -1 ]] = 0en d _c ha r s [wo r d [ -1 ]] += 1ret u rn s t art _cha rs , en d_ cha rsdef re ve rs e_ wo rd s ( wor ds ,
re ve rs ed _i n d i c e s ):def re ve rs e_ w or d (w o rd ):ret u rn wo r d [:: -1]new _w or d s = w ords . c opy ()for i ndex in re ve rs ed _i nd i c e s :ne w _w or d s [i n dex ] = re ve rs e _w or d (w ords [ i nde x ])ret u rn n ew _w o rd sdef so lv e _t as k ( wo r ds ):def is _r e ve rs ed (s ):ret u rn s == s [:: -1]def co un t _ r ev er se d_ w o r ds ( word s ):coun t = 0ind exe s = []for i in ran ge ( len ( wor d s )):if i s_ re v er se d ( wo rds [i ]):coun t += 1ind exe s . ap pen d (i )ret u rn count , i nde xescount , ind exe s = c o u n t _ re ve rs ed _ w o rd s ( wo rds )prin t ( cou n t )prin t ( in dex es )t = int ( in p ut ())for _ in ran ge ( t ):n = int ( in p ut ())word s = []for _ in ran ge ( n ):word s . app end ( inpu t ())tot al_ rev ers ed , r ev er se d_ wo rd s = s ol ve _t a sk ( wor d s )prin t ( to t a l _ r e v e rs ed )if t ot al _r ev er se d !
= 0:prin t (* re ve rs ed _w or ds )` ` `