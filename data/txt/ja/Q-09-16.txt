比喩検出における大規模言語モデルを用いた前後補助文脈の活用

林拓哉

1

 佐々木稔

11

茨城大学大学大学院



 {24nm752s, minoru.sasaki.01}@vc.ibaraki.ac.jp



概要

比喩検出は、文字通りには解釈できない比喩表現を検出するタスクであり、文脈情報が重要である。
過去の研究では、ChatGPT を用いて生成した補助文をターゲット文の前に追加する手法が提案され、精度向上が示されたものの、十分ではなかった。
本論文では、ターゲット文の前後に補助文を追加する手法を提案し、比喩検出の精度向上を図った。
複数のデータセットを用いた実験では、補助文の追加により精度、適合率、F1 スコアが過去の研究より向上したことが確認された。
本研究は補助文生成の有効性を示しており、今後はより多様な文脈構成や最新の生成モデルを活用する可能性を探る必要がある。


1 はじめに



1.1 研究背景

比喩検出とは、文章中の比喩表現を検出することであり、本研究では英文の隠喩を対象とする。
比喩表現は文字通りには解釈できず、その意味を推測する必要がある。
近年、事前学習済み言語モデルを活用した Transformer を用いる手法が精度向上に寄与している[1][2]。
特に MisNet モデル[3]は、1 文に基づいて比喩の有無を判断するが、文脈が不足する文では依然として困難が残る。


1.2 補助文脈の活用

過去の我々の研究[4]では、ChatGPT を用いて補助文を生成・追加することで文脈情報を増強し、比喩検出の精度を向上させる手法を提案した。
実験では補助文を追加したデータセットが元のデータセットよりも精度が高いことが確認されたが、文脈量の増加や追加位置の影響についても課題が示唆された。


1.3 研究目的

本論文では、補助文の追加位置を前後に変更し、文脈量を増加させた手法の有効性を検証する。


2 補助文を用いた比喩検出手法

本研究では、ある文（ターゲット文）およびその中の特定の単語（ターゲット単語）が比喩表現として使用されているかを判定するために、補助的な文脈を生成してターゲット文に付加する手法について述べる。
これまでの研究[4]では、前に追加する前提で文章を生成したが、その際に作成した前に生成した文を結合した文に対して、後ろの文に補助的な文脈を生成させ、結合させる。



2.1 補助文脈の生成

ChatGPT を用いてターゲット文に続く補助文を生成する。
モデルは[4]に合わせて、ChatGPT-3.5Turbo を使用する。
この際、2 種類のプロンプトを使用する。
プロンプト 1(Prompt1)以下に 1 種類目のプロンプトを示す。
プロンプト中の太字の単語は変数を表しており、それぞれの変数とその内容を表 1 に示す。
• 文章作成のプロンプト(Prompt1):"Generate a N-words sentence that Verbs"sentence" and in which ’target_word’ in "sentence"is m used as a metaphor."プロンプト 2(Prompt2) 2 種類目のプロンプトは以下の通りである。
文生成の基本的な指示はプロンプト 1 と同じであるが、プロンプト 1 の前に、ターゲット単語が比喩表現として使用されている例文と使用されていない例文を追加している。
それぞれの変数は表 1 に示したプロンプト 1 と同じである。
表 1 プロンプトの変数変数名内容N 追加される文の単語数Verb前に追加するときは “precede”、後ろに追加するときは “follow”sentence ターゲット文target_word ターゲット単語m比喩表現が含まれる場合は空白文字、含まれない場合は「not」• 例文を含む文を生成するプロンプト（Prompt2）："’derive’ in "For the moment let us use the aboveexpression for deriving Biot-Savart’s law." is used asa metaphor.""’derive’ in "The next section therefore attempts tosummarize what we do know; it is derived chieﬂyfrom the Earth System Sciences Committee (ESSC)(1988)." is not used as a metaphor.""Generate a N-words sentence that Verbs "sentence"and in which ’target_word’ in "sentence" is m usedas a metaphor."

2.2 文の結合

前節で生成した文とターゲット文を結合する方法について説明する。
この結合は「ターゲット文 + 生成された文」の形式で単純に配置する。


3 DataSet



3.1 元データセット

本節では、第 2 節で述べた通り、ターゲットの文は[4]で作成したデータセットを使用する。
その実験で使用したデータセット及び構造について説明する。
実験では、MOH-X[5]、VUA_All[6]、およびVUA_Verb[6]の 3 種類のデータセットを使用した。
MOH-X MOH-X は、動詞に焦点を当てたデータセットであり、比喩的意味と文字通りの意味の両方を含む動詞の用例が WordNet から収集されている。
VUA_All VUA とは、アムステルダム自由大学（Vrije Universiteit Amsterdam）および同大学で作成された VU アムステルダム比喩コーパス（VUAmsterdam Metaphor Corpus）を指す。
VUA は、BNCBaby Corpus から収集されたテキストを基にしており、学術、会話、小説、ニュースの 4 つのジャンルを含む。
ターゲット単語にはすべての品詞が含まれている。
VUA_Verb VUA_Verb は、VUA_All のうちターゲット単語が「VERB」とラベル付けされたデータである。
表 2 各データセットの情報 #Sent. は文数、#Target はターゲット単語数、%Met. は比喩を含む割合、Avg. Len は文の平均長を示す。
DataSet #Sent. #Target %Met. Avg. Len𝑉𝑈 𝐴_𝐴𝑙𝑙𝑡𝑟6,323 116,622 11.19 18.4𝑉𝑈 𝐴_𝐴𝑙𝑙𝑣𝑎𝑙1,550 38,628 11.62 24.9𝑉𝑈 𝐴_𝐴𝑙𝑙𝑡𝑒2,694 50,175 12.44 18.6𝑉𝑈 𝐴_𝑉𝑒𝑟𝑏𝑡𝑟7,479 15,516 27.9 20.2𝑉𝑈 𝐴_𝑉𝑒𝑟𝑏𝑣𝑎𝑙1,541 1,724 26.91 25.0𝑉𝑈 𝐴_𝑉𝑒𝑟𝑏𝑡𝑒2,694 5,873 29.98 18.6𝑀𝑂𝐻 − 𝑋 647 647 48.69 8.0

3.2 MisNet のデータ形式

第 4.2 節で述べる通り、今回の実験は MisNet[3]を用いる。
そのため、MisNet のデータ形式について説明する。
文献[3]では、データは csv 形式で提供されており、これらのデータセットを MisNet で使用するために再フォーマットされている（表 3 参照）。
表 3 MisNet のデータ形式列名内容sentence ターゲット文label比喩の有無を示すラベル0: 含まれない 1: 含まれるtarget_positionターゲット単語の文中での位置target_word ターゲット単語pos_tag ターゲット単語の品詞gloss ターゲット単語の定義eg_sent ターゲット単語の例文

4 実験



4.1 追 加 の 補 助 的 文 脈 を 含 む デ ー タ



セット

各文に対して、第 2 節で説明されている方法を使用して文脈補足文を生成し、元の文と生成された文を組み合わせて文脈補足文を作成する。
本研究では、生成された文を MisNet データセットの形式に統合している。
4.1.1 生成手順追加の補助文脈を含むデータセットを作成する手順について述べる。
まず、MOH-X、VUA_All、または VUA_Verb のデータセットを読み込み、これに基づいてプロンプトを作成する。
次に、ChatGPT を使用して補助文を生成し、生成された文をターゲット文と結合する。
最後に、データを MisNet データセット形式にまとめ、csv 形式で出力する。
本研究では、ChatGPT が使用するトークン数をプロンプト1 では 20、プロンプト 2 では 50 に設定している。
これらは第 2 節で述べたプロンプト内の変数と対応しており、プロンプトの sentence および target_word には、データセットの sentence および target_word が対応する。

4.2 実験方法

Transformer を用いた比喩検出モデル MisNet[3]1）を、各データセットにおいて以下の 3 つの状況で実行した。
(1)何も追加しない場合、(2)第 2 節で示したプロンプト 1 によって生成された補助文脈を追加した場合、(3)プロンプト 2 によって生成された補助文脈を追加した場合、という 3 つの状況である。
それぞれのデータセット内のすべての文について、比喩の有無を予測し、予測ラベルを出力として取得した。
本実験では、事前学習済みの BERT モデルとして RoBERTa の基本モデル2）を使用した。



5 結果と考察



5.1 実験結果

5.1.1 元のラベルと予測ラベルの精度以下に、元のデータセットおよび補足文を追加したデータセットにおける元のラベルと予測ラベルの精度を示す。
太字の数字は各行の各項目における最大値を表している。
行名 P1 および P2 は、それぞれプロンプト 1 およびプロンプト 2 を使用した文を示し、5words および 10words は、前に 5 単語または 10単語の文を追加したことを示している。
数値内の太字は、各列における最大値を示す。
全体的に、補助文が追加された場合に各スコアが元のデータよりも高い傾向がある。
特に、正解率と F1 スコアは全て元データより今回の手法を使用した方が高かった。
1） MisNet の詳細は付録にて説明する。
2） RoBERTa のウェブサイトhttps://huggingface.co/FacebookAI/roberta-base表 4 MOH-X における正答率、適合率、再現率、および f1 スコアの平均Acc Prec Rec F1original data 0.828565 0.819046 0.844503 0.827488P1_5words 0.851078 0.854915 0.839839 0.844435P1_10words 0.84529 0.820463 0.88696 0.84934P2_5words 0.85295 0.8601 0.835703 0.846013P2_10words 0.838578 0.824779 0.858565 0.838502表 5 VUA_All のテストデータにおける正答率、適合率、再現率、および f1 スコアの平均Acc Prec Rec F1original data 0.940933 0.771933 0.75507 0.761333P1_5words 0.94886 0.826496 0.745475 0.7839P1_10words 0.947683 0.827125 0.732661 0.777032P2_5words 0.947922 0.821923 0.742271 0.780069P2_10words 0.94854 0.83036 0.736985 0.780889表 6 VUA_All の検証データにおける正答率、適合率、再現率、および f1 スコアの平均Acc Prec Rec F1original data 0.940933 0.771933 0.755067 0.761333P1_5words 0.95172 0.806882 0.76822 0.78708P1_10words
0.951149 0.8122 0.753733 0.781875P2_5words 0.950735 0.799768 0.768219 0.783676P2_10words 0.951201 0.811542 0.755293 0.782408表 7 VUA_Verb のテストデータにおける正答率、適合率、再現率、および f1 スコアの平均Acc Prec Rec F1original data 0.802133 0.679867 0.7374 0.6972P1_5words 0.840116 0.748489 0.70301 0.725037P1_10words 0.84454 0.76566 0.693924 0.728031P2_5words 0.841818 0.740462 0.727428 0.73389P2_10words 0.836881 0.739416 0.704145 0.72135表 8 VUA_Verb の検証データにおける正答率、適合率、再現率、および f1 スコアの平均Acc Prec Rec F1original data 0.8112 0.653267 0.760133 0.6932P1_5words 0.866589 0.75 0.756466 0.753219P1_10words 0.87587 0.78409 0.743534 0.76327P2_5words 0.867169 0.748414 0.76293 0.755603P2_10words 0.862529 0.750552 0.732759 0.7415495.1.2 t 検定による優位性の評価各データセットについて、予測ラベルの平均値が 0.5 未満の場合は 0、0.5 を超える場合は 1 とするデータを作成した。
帰無仮説は、「状況の異なる 2つの場合について、結果に有意な差がないこと」であり、t 検定を実施した。
P(T<=t)両側値は以下の通りである。
テストデータの結果について述べる。
MOH-X では、値が 0.1%未満であった 2 つのケースは、元のデータとプロンプト 1 の前に追加の 10 単語の文を加えた場合のみである。
他のケースでは大部分が 0.2 から 0.9 の範囲であり、有意水準の 5%または 1%を下回るものはなかった。
VUA_All では、プロンプト 1 で前後に 5 単語ずつ追加したデータとプロンプト2で5単語ずつ追加したデータの場合、プロンプト 2 で前後に 5 単語ずつ追加したデータとプロンプト 2 で前後に 10 単語ずつ追加したデータの場合が有意水準を上回った。
しかし、それ以外は全て 10%の優位水準を下回り、1%の優位水準を下回るケースが多い。
VUA_Verb では、過半数が 1%の優位水準を下回っている。
図 1 MOH-X の t 検定結果(𝑃(𝑇 ≤ 𝑡)両側)図 2 VUA_All のテストデータ t 検定結果(𝑃(𝑇 ≤ 𝑡)両側)図 3 VUA_All の検証データ t 検定結果(𝑃(𝑇 ≤ 𝑡)両側)

5.2 考察

第 5.1.1 節の結果から、補助文を追加することで比喩検出の精度が向上することが確認された。
特に適合率の向上により、比喩がある文を正しく予測する能力が向上した。
しかし、再現率が低下してお図 4 VUA_Verb のテストデータ t 検定結果(𝑃(𝑇 ≤ 𝑡)両側)図 5 VUA_Verb の検証データ t 検定結果(𝑃(𝑇 ≤ 𝑡)両側)り、比喩がある文を比喩なしと誤予測する傾向が示唆された。
これは、真陽性の増加に比べて偽陰性の増加が大きかったためと考えられる。
また、t 検定の結果から、文脈を追加した効果を明確に判定するのは難しく、多くの場合有意水準を下回っていた。
ただし、元データと比較すると 1%の有意水準を達成しており、文脈の追加が効果を持つことは示されている。
一方で、プロンプト 1 とプロンプト 2 の間に明確な差は見られず、文字数の違いについての効果も今後の課題といえる。
特に、動詞に注目したメタファー検出では効果が限定的であり、動詞の多義性や文脈に応じた使い分けの多さが原因と考えられる。
また、動詞のすべての意味を網羅しているわけではないため、正確な意味認識が難しいことも一因である。
これらの課題を踏まえ、動詞におけるメタファー検出の改善が今後の重要な研究課題である。


6 まとめ

本論文では、比喩検出の精度を向上させる手法において、補助的な文脈を前と後ろに追加した場合の有効性について検証した。
提案手法を用いて補助文を追加したデータセットと元のデータセットについて、比喩検出モデルである MisNet を用いた予測結果を比較した。
その結果、比喩検出の精度が向上することが示された。
特に、補助的な文脈を前に追加した場合よりも、全体的に精度が向上した。
今後の課題としては、文の後ろのみに追加した場合や補助的な文脈の単語を増やす場合が挙げられる。
また、使用する ChatGPT モデルを最新モデルにした際の結果も調査したい。



参考文献


[1] Minjin Choi, Sunkyung Lee, Eunseong Choi, Heesoo Park,Junhyuk Lee, Dongwon Lee, and Jongwuk Lee. Melbert:Metaphor detection via contextualized late interaction us-ing metaphorical identiﬁcation theories. In Proceedings ofthe 2021 Conference of the North American Chap-ter of the Association for Computational Linguistics:Human Language Technologies, pp. 1763–1773, On-line, 2021. Association for Computational Linguistics.
[2] Wei Song, Shuhui Zhou, Ruiji Fu, Ting Liu, and LizhenLiu. Verb metaphor detection via contextual relation learn-ing. In Proceedings of the 59th Annual Meeting ofthe Association for Computational Linguistics andthe 11th International Joint Conference on NaturalLanguage Processing (Volume 1: Long Papers), pp.4240–4251, Online, 2021. Association for ComputationalLinguistics.
[3] Shenglong Zhang and Ying Liu. Metaphor detection vialinguistics enhanced siamese network. In Proceedings ofthe 29th International Conference on ComputationalLinguistics, pp. 4149–4159, Gyeongju, Republic of Korea,2022. International Committee on Computational Linguis-tics.
[4] Takuya Hayashi and Minoru Sasaki. Metaphor detectionwith additional auxiliar y context. In2024 16th IIAI Inter-national Congress on Advanced Applied Informatics(IIAI-AAI), pp. 121–126, 2024.
[5] Saif Mohammad, Ekaterina Shutova, and Peter Turney.Metaphor as a medium for emotion: An empirical study. InProceedings of the Fifth Joint Conference on Lexi-cal and Computational Semantics, pp. 23–33, Berlin,Germany, 2016. Association for Computational Linguistics.
[6] Gerard Steen. A Method for Linguistic Metaphor Iden-tiﬁcation: From MIP to MIPVU , Vol. 14. John Ben-jamins Publishing, 2010.




A 参考情報

本節には、本文にて説明しきれなかった技術について説明する。


A.1 MisNet

A.1.1 MisNet とはMisNet (Metaphor Identiﬁcation from Siamese Net-work)は、Shenglong Zhang と Ying Liu による論文"Metaphor Detection via Linguistics Enhanced SiameseNetwork" [3]3）で提案された比喩検出モデルである。
このモデルは、MIP と SPV の 2 つの言語規則に基づいて計算を行い、その結果を合算して比喩を含むかを判定する。
MisNet はいくつかのデータセットで従来のモデルより優れた性能を示した。
MIP とは MIP (Metaphor Identiﬁcation Procedure)は、比喩を識別する手続きを示す。
この研究では、文脈的な意味と対象単語の基本的な意味の類似度を計算する。
基本的な意味は辞書から取得する。
SPV とは SPV (Selectional Preference Violation)は、選択的優先違反を指し、単語が文脈で一般的に使用されない状況を表す。
この研究では、対象単語と文脈の不一致度を計算する。
MisNet の構造 MisNet の構造は図 6 に示される。
右側の入力は表 9 の形式で BERT エンコーダーに入力され、その出力は ℎ𝑀 𝐼 𝑃と ℎ𝑃𝑂𝑆の計算に使用される。
左側の入力は表 10 の形式で同じ重みを共有する BERT エンコーダーに入力され、ℎ𝑆𝑃𝑉と ℎ𝑀 𝐼 𝑃の計算に使用される。
特徴タグ GF、LF、POS、TARは、それぞれグローバル特徴、ローカル特徴、品詞特徴、ターゲット単語を示すものである。
以下の式で ℎ𝑀 𝐼 𝑃、ℎ𝑆𝑃𝑉、ℎ𝑃𝑂𝑆を統合する。
𝑦 = 𝜎(𝑊𝑇[ℎ𝑀 𝐼 𝑃; ℎ𝑆𝑃𝑉; ℎ𝑃𝑂𝑆] + 𝑏)(1)ここで、𝑊 は重み、𝑏 はバイアス、𝜎 はソフトマックス関数である。
𝑦 ∈ ℝ2の値で比喩の有無を判別する。
表 9 右側の BERT への入力形式先頭タグ対象の文章文末タグ一行目の各単語の座標一行目の各単語の特徴タグ3） https://github.com/silasthu/misnet にてプログラムが公開されている。
図 6 MisNet の構造([3]より引用)表 10 左側の BERT への入力形式先頭タグ対象単語文末タグ品詞文末タグ対象の文文末タグ一行目の各単語の座標一行目の各単語の品詞タグまた、分類タスクでは、最適化基準としてクロスエントロピー損失を使用する。
𝐿 = −1𝑁𝑁∑𝑖=1𝑤𝑦𝑖log( ˆ𝑦𝑖)(2)上記の式の N はトレーニングサンプルの数である。
𝑦𝑖と ˆ𝑦𝑖はそれぞれ 𝑖 番目のサンプルの正解ラベルと予測スコアを表す。
𝑤𝑦𝑖はクラスの重みで、データの不均衡問題を緩和するためのものである。
A.1.2 MisNet のトレーニング・Metaphor の判定モデルのトレーニング 4.2 節で示した形式のトレーニングデータを抽出し、4.1 節で述べた構造のモデルに入力して(1)式を計算する。
その後、計算された変数 𝑦 とトレーニングデータの真のラベルとの差異を評価するために(2)式で示す損失関数を適用する。
この損失を用いて、勾配の計算が行われ、その勾配を元にモデルのパラメータを更新する。
これらの手順を各エポックごとに繰り返す。
Metaphor の判定未知の文から Metaphor の判定をする際は、トレーニングと同じようにデータを抽出し、Transformer を使用してロジットを計算する。
その後、ロジットの各行において最大の値と対応したラベルを抽出する。
このラベルが表 3 の label に相当する。