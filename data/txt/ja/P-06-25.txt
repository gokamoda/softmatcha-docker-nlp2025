未知の知識に対する事前学習済み言語モデルが持つ推論能力の調査

坂井 優介

1

上垣外 英剛

1

林 克彦

2

渡辺 太郎

11

奈良先端科学技術大学院大学

2

東京大学



{sakai.yusuke.sr9,kamigaito.h, taro}@is.naist.jp



katsuhiko-hayashi@g.ecc.u-tokyo.ac.jp



掲載号の情報

31 巻 4 号 pp. 1427-1457.doi: https://doi.org/10.5715/jnlp.31.1427

概要

事前学習済み言語モデル(Pre-trained LanguageModels; PLM)は事前学習時に獲得した言語理解能力と知識を活用して、既知の事象に対して推論を行う。
一方未知の事象に対しては PLM の推論能力のみで解を導き出す必要がある。
そのため言語モデルの推論能力のみを評価するには、PLM が事前学習時に記憶した知識と獲得した推論能力を完全に切り分けた分析が必要となる。
しかし PLM は多種多様なデータを用いて事前学習を行うため、既存の推論能力測定用データセットの情報も直接的1）・間接的2）に事前学習用データに含まれる場合がある。
従って既存のデータセットによる純粋な推論能力の測定は、事前学習時の記憶が作用するため困難である。
本研究では PLM の純粋な推論能力のみに焦点を当て、未知の事象に対する PLM の推論能力を調査する。
分析に際して、知識グラフ(Knowledge Graph;KG)上の既知の関係から欠損している未知の関係を予測するタスクである知識グラフ補完(KnowledgeGraph Completion; KGC)を対象とする。
従来の埋め込みに基づく KGC 手法は推論能力のみから欠損箇所を予測する一方、近年利用されている PLM を用いた KGC 手法では、図 1 に示すように、事前学習時に記憶したエンティティに関する知識も利用している。
このように KGC は記憶した知識の利用と推論による解決との両側面を有することから PLM1） 下流タスクのデータセットが直接、事前学習用データに含まれている場合。
2） 下流タスクのデータセット自体は直接、事前学習用データに含まれていないが、下流タスクのデータセットの作成の元となったデータなど推論に有益な情報が含まれる場合。
Knowledge GraphPre-trained KnowledgeTruly Inferred?
ReuseInferfathermotherKylo RenLeia OrganaLeia OrganaDarth VadergrandfatherKylo RenDarth VaderKylo Ren aspires to be as powerful as his grandfather, Darth Vader.or 知識グラフ（KG）事前学習で獲得した知識推論記憶推論 or 記憶？図 1 PLM を用いた KGC 手法は知識の利用と推論による解決との両側面を有している。が記憶した知識の影響を測ることに適したタスクである。
しかし既存の KGC データセットは Web 上のデータから作成されているため、PLM を用いたKGC 手法が、問題を言語モデルの推論能力によって解決したのか、それとも言語モデルの記憶能力により解決したのか定かではない。
そこで我々はモデルの記憶能力に対する評価と推論能力に対する評価を切り分けた評価方法及びそのためのデータ構築手法を提案する。
この方法ではKG のグラフ構造を保持しつつ、エンティティや関係の表層表現を実際のものとは異なる表現に置換することで、PLM が事前学習で獲得した知識とは異なる環境を作り出す。
この処理によって PLM は事前学習時に記憶した知識に頼らず、純粋な推論能力のみを頼りに、エンティティ間のグラフ構造から KGCを行う必要が生じるため、言語モデルが持つ推論能力のみを測ることができる。
我々の提案手法を用いて作成した疑似データにより，PLM の学習過程やモデル構造の違い、事前学習の重みの有無、大規模言語モデルへの適用可能性など含めた、様々な設定下でのモデルの推論結果を分析することで、PLM が事前学習で得たエンティティに関する知識により推論を行っている箇所を明らかにした。
また PLM が持つ未知の関係に対する推論能力も同時に事前学習時に獲得していることを示唆する結果も得られた。