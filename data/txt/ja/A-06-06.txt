å¯¾ç…§æå¤±ã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ãŒ BERT ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚‚ãŸã‚‰ã™åŠ¹æœ

ç«¹ä¸­ èª 

1

â€ƒç€§ é›…äºº

21

ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾â€ƒ

2

ç«‹æ•™å¤§å­¦



Takenaka.Makoto@bc.MitsubishiElectric.co.jp taki m@rikkyo.ac.jp



æ¦‚è¦

æœ¬ç ”ç©¶ã§ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ BERT ã«å¯¾ã™ã‚‹å¯¾ç…§æå¤±ã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ãŒã€ä¸‹æµã‚¿ã‚¹ã‚¯ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®Ÿé¨“çš„ã«èª¿æŸ»ã™ã‚‹ã€‚
å®Ÿé¨“ã§ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ BERT ã¨ã€ãã‚Œã‚’ SimCSE ã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã¨ãã®å­¦ç¿’ã®å®‰å®šæ€§ã¨ãƒ¢ãƒ‡ãƒ«ã®å¯å¡‘æ€§ã®äºŒã¤ã®è¦³ç‚¹ã§åˆ†æã—ãŸã€‚
å®Ÿé¨“ã®çµæœã€SimCSE ã§è¿½åŠ å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã¯ã€( ğ‘– )å¤§ãã„å­¦ç¿’ç‡ã§ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã‚ˆã‚Šå®‰å®šçš„ã«ãªã‚Šã€( ğ‘–ğ‘– )ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼æƒ…å ±è¡Œåˆ—ã®æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ãŒå›å¾©ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®å¯å¡‘æ€§ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚
1 ã¯ã˜ã‚ã«BERT[1]ã®ã‚ˆã†ãªäº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€æ§˜ã€…ãªè‡ªç„¶è¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ã«åºƒãç”¨ã„ã‚‰ã‚Œã¦ã„ã‚‹ä»£è¡¨çš„ãªæ‰‹æ³•ã®ä¸€ã¤ã§ã‚ã‚‹ã€‚
ã—ã‹ã—äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãã®ã¾ã¾ç”¨ã„ã‚‹ã¨ã€ä»»æ„ã®æ–‡ãƒšã‚¢ã®é¡ä¼¼åº¦ãŒå¤§ãããªã‚Šååˆ†ãªè¡¨ç¾åŠ›ã‚’æŒãŸãªã„ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹[2]ã€‚
ã“ã‚Œã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€æ§˜ã€…ãªæ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚
æ–‡åŸ‹ã‚è¾¼ã¿ã«å¾Œå‡¦ç†ã‚’æ–½ã™æ‰‹æ³•ã¨ã—ã¦ã€æ–‡åŸ‹ã‚è¾¼ã¿ã‚’ç­‰æ–¹çš„ãªã‚¬ã‚¦ã‚¹åˆ†å¸ƒã«å¤‰æ›ã™ã‚‹æ‰‹æ³•[2]ã‚„ã€æ–‡åŸ‹ã‚è¾¼ã¿ã®ç™½è‰²åŒ–[3]ãªã©ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚
BERT ã‚’è¿½åŠ å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã¨ã—ã¦ã¯ã€å¯¾ç…§æå¤±ã‚’ç”¨ã„ã‚‹æ‰‹æ³•ãŒåºƒãåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹[4, 5, 6, 7, 8]ã€‚
ã“ã‚Œã‚‰ã®å¤šãã®æ‰‹æ³•ã¯ã€æ–‡åŸ‹ã‚è¾¼ã¿ã®ç•°æ–¹æ€§ã‚’è§£æ¶ˆã™ã‚‹ã“ã¨ã‚’ä¸»ãªç›®çš„ã¨ã™ã‚‹ãŸã‚ã€STS ã‚¿ã‚¹ã‚¯ãªã©ã®æ„å‘³çš„é¡ä¼¼åº¦ã‚¿ã‚¹ã‚¯ã§ã¯é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™ä¸€æ–¹ã§ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ BERT ã‚’ä¸‹æµã‚¿ã‚¹ã‚¯ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å ´åˆã®æ€§èƒ½å‘ä¸Šã¯é™å®šçš„ã§ã‚ã‚‹[9, 5, 6, 10, 7]ã€‚
ãã“ã§ä¸€ã¤ã®ç–‘å•ãŒç”Ÿã˜ã‚‹ã€‚
æ„å‘³çš„é¡ä¼¼åº¦ã‚¿ã‚¹ã‚¯ãªã© BERT ã®åŸ‹ã‚è¾¼ã¿ã‚’ãã®ã¾ã¾åˆ©ç”¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™æ‰‹æ³•ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’åŠã¼ã™ã®ã‹ï¼BERT ã®æ´»ç”¨æ–¹æ³•ã¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ç”¨ã„ã‚‹ã“ã¨ã¯ä¸€èˆ¬çš„ã§ã‚ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ã“ã®ç–‘å•ã«ã¯ã‚ã¾ã‚Šæ³¨æ„ãŒæ‰•ã‚ã‚Œã¦ã“ãªã‹ã£ãŸã€‚
ãã“ã§æœ¬ç ”ç©¶ã§ã¯ã€å¯¾ç…§æå¤±ã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ãŒä¸‹æµã‚¿ã‚¹ã‚¯ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’åŠã¼ã™ã®ã‹ã‚’èª¿æŸ»ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚
æœ¬ç ”ç©¶ã®è²¢çŒ®ã¯ä»¥ä¸‹ã§ã‚ã‚‹ã€‚
â€¢ SimCSE ã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ã¯ã€æå¤±é–¢æ•°ã®ãƒ˜ã‚·ã‚¢ãƒ³ã®ãƒ©ãƒ³ã‚¯ã‚’å›å¾©ã•ã›ã‚‹åŠ¹æœã‚’æŒã¤ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ãŸã€‚
â€¢ SimCSE ã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®ãƒ˜ã‚·ã‚¢ãƒ³ã®ãƒ©ãƒ³ã‚¯ã®ä¸€æ§˜æ€§ã‚’ç¶­æŒã•ã›ã‚‹åŠ¹æœã‚’æŒã¤ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ãŸã€‚
â€¢ ã“ã‚Œã‚‰ã®åŠ¹æœãŒãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šåŒ–ã‚„ä¸‹æµã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æ€§èƒ½å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’å®šæ€§çš„ã«ç¤ºã—ãŸã€‚
2 åˆ†ææ–¹é‡æœ¬ç ”ç©¶ã§ã¯ã€ä»£è¡¨çš„ãªå¯¾ç…§å­¦ç¿’æ‰‹æ³•ã§ã‚ã‚‹SimCSE[5]1ï¼‰ãŒä¸‹æµã‚¿ã‚¹ã‚¯ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‚ˆã¼ã™å½±éŸ¿ã‚’ã€å®‰å®šæ€§ã¨å¯å¡‘æ€§ã®äºŒã¤ã®è¦³ç‚¹ã§åˆ†æã™ã‚‹ã€‚
2.1 SimCSESimCSE ã§ã¯ä»¥ä¸‹ã§å®šç¾©ã•ã‚Œã‚‹ InfoNCE[11]æå¤±ã‚’æœ€å°åŒ–ã™ã‚‹ã€‚
L= âˆ’1ğ‘ğ‘Ã•ğ‘–=1logexp(sim(hğ‘–, h+ğ‘–)/ğœ)Ãğ‘ğ‘—=1exp(sim(hğ‘–, hğ‘—)/ğœ)ã“ã“ã§ã€ğ‘ ã¯ãƒŸãƒ‹ãƒãƒƒãƒå†…ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¡¨ã—ã€hğ‘–ã¯å…¥åŠ›æ–‡ ğ‘– ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã€h+ğ‘–ã¯æ–‡ ğ‘– ã«å¯¾ã™ã‚‹æ­£ä¾‹ã§ã‚ã‚Š SimCSE ã§ã¯åŒã˜å…¥åŠ›æ–‡ã«å¯¾ã—ç•°ãªã‚‹ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆãƒã‚¹ã‚¯ã‚’é©ç”¨ã—ãŸåŸ‹ã‚è¾¼ã¿ã‚’æ­£ä¾‹ã¨ã™ã‚‹ã€‚
ã¾ãŸã€hğ‘—ã¯æ–‡ ğ‘– ã«å¯¾ã™ã‚‹è² ä¾‹ã§ã‚ã‚Šã€æ•™å¸«ãª1ï¼‰ æœ¬ç ”ç©¶ã§ã¯æ•™å¸«ãªã— SimCSE ã«é™å®šã™ã‚‹ã€‚
â€• 2215 â€•

ã—
SimCSE
ã§
ã¯
ãƒŸãƒ‹ãƒãƒƒãƒå†…ã®ä»–ã®æ–‡ã®åŸ‹ã‚è¾¼ã¿ã‚’åˆ©ç”¨ã™ã‚‹ã€‚
sim(u, v)ã¯ã€ãƒ™ã‚¯ãƒˆãƒ« u ã¨ v ã®é¡ä¼¼åº¦ã§SimCSE ã§ã¯ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒä½¿ç”¨ã•ã‚Œã‚‹ã€‚
æœ€å¾Œã«ã€ğœ ã¯æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚‹ã€‚
SimCSE ã§ã¯ã€æ­£ä¾‹å¯¾ï¼ˆhğ‘–ã¨ h+ğ‘–ï¼‰ã€ã¤ã¾ã‚Šä¼¼ãŸæ„å‘³ã®æ–‡ã®é¡ä¼¼åº¦ã‚’æœ€å¤§åŒ–ã—ã€ãã†ã§ãªã„è² ä¾‹å¯¾ï¼ˆhğ‘–ã¨ hğ‘—ï¼‰ã¨ã®é¡ä¼¼åº¦ã‚’æœ€å°åŒ–ã™ã‚‹ã‚ˆã†ã«æœ€é©åŒ–ã‚’è¡Œã†ã€‚
2.2 å®‰å®šæ€§ãƒ¢ãƒ‡ãƒ« ğ‘“ ã®å®‰å®šæ€§ ğ‘†( ğ‘“ )ã¯[12]ã‚’è¸è¥²ã—ã€ç•°ãªã‚‹ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ ğ‘Ÿ ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦å¾—ã‚‰ã‚Œã‚‹è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ« { ğ‘“ğ‘Ÿ} ã®è©•ä¾¡æŒ‡æ¨™ã®ã°ã‚‰ã¤ãã¨ã—ã¦å®šç¾©ã™ã‚‹:ğ‘†( ğ‘“ ) =pVarğ‘Ÿ[ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦( ğ‘“ğ‘Ÿ)].æœ¬ç¨¿ã§ã¯ RTE ã‚¿ã‚¹ã‚¯ã® validation ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹Accuracy ã®ã°ã‚‰ã¤ãã§è©•ä¾¡ã™ã‚‹ã€‚
BERT ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€å±¤æ•°ãŒå¤šããªã‚‹ã»ã©å‹¾é…æ¶ˆå¤±ã®å½±éŸ¿ãŒé¡•è‘—ã«ãªã‚Šå­¦ç¿’ã¯ä¸å®‰å®šã«ãªã‚‹[12]ã€‚
ã—ãŸãŒã£ã¦æœ¬ç¨¿ã®å®Ÿé¨“ã§ã¯ 24 å±¤ã® large ãƒ¢ãƒ‡ãƒ«ã‚’åˆ†æå¯¾è±¡ã¨ã™ã‚‹ã€‚
2.3 å¯å¡‘æ€§ãƒ¢ãƒ‡ãƒ«ã®å¯å¡‘æ€§ã¨ã¯ã€ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯ã§ç¶™ç¶šå­¦ç¿’ã™ã‚‹ã¨ãã®ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã¸ã®é©å¿œæ€§ã®ã“ã¨ã§ã‚ã‚‹ã€‚
[13]ã§ã¯ã€æå¤±é–¢æ•°ã®ãƒ˜ã‚·ã‚¢ãƒ³ H = âˆ‡2ğœ½ğ¿(ğœ½)ã®æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ãŒå¤§ãã„ã»ã©ãƒ¢ãƒ‡ãƒ«ã®å¯å¡‘æ€§ã¯å¤§ãããªã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚
æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã¯ H ã®å›ºæœ‰å€¤{ğœ†ğ‘–, ğ‘– = 1, . . . , ğ‘‘} ã‚’é™é †ã«ä¸¦ã¹ãŸã¨ãã®ç´¯ç©å¯„ä¸ç‡ãŒ99%ã‚’è¶…ãˆã‚‹æœ€å°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦å®šç¾©ã™ã‚‹:erank(H) = minnğ‘—î˜Œî˜Œî˜ŒÃğ‘—ğ‘–=1ğœ†ğ‘–Ãğ‘‘ğ‘–=1ğœ†ğ‘–> 0.99o,(ğœ†1> ğœ†2> Â· Â· Â· > ğœ†ğ‘‘).ç›´è¦³çš„ã«ã¯ã€ãƒ˜ã‚·ã‚¢ãƒ³ã®æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã¯æå¤±é–¢æ•°ä¸Šã®æœ€é©åŒ–æ–¹å‘ã®æœ‰åŠ¹ãªè‡ªç”±åº¦ã¨è§£é‡ˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
ã¤ã¾ã‚Šã€ç¶™ç¶šå­¦ç¿’ã®éš›ã®æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã¯ã€ãã®ã‚¿ã‚¹ã‚¯ã¸ã®é©å¿œæ€§ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã«ãªã‚Šå¾—ã‚‹ã€‚
æœ¬ç ”ç©¶ã§ã¯ã“ã®æ€§è³ªã«ç€ç›®ã—ã€æå¤±é–¢æ•°ã®ãƒ˜ã‚·ã‚¢ãƒ³ã®æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã§è¿½åŠ å­¦ç¿’ã®å¯å¡‘æ€§ã®ç‰¹å¾´ä»˜ã‘ã‚’è©¦ã¿ã‚‹ã€‚
ä¸€èˆ¬ã«å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ãƒ˜ã‚·ã‚¢ãƒ³ã®è¨ˆç®—ã‚³ã‚¹ãƒˆã¯è†¨å¤§ã§ã‚ã‚‹ã€‚
æœ¬ç¨¿ã®è¨ˆç®—å¯¾è±¡ã§ã‚ã‚‹ BERT ã®å ´åˆã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯O(108)ã§ã‚ã‚‹ãŸã‚ãƒ˜ã‚·ã‚¢ãƒ³ã‚’ä¿æŒã™ã‚‹ã ã‘ã§ã‚‚ 1016ç›¸å½“ã® RAM ã‚„ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãŒå¿…è¦ã¨ãªã‚Šè¨ˆç®—å›°é›£ã§ã‚ã‚‹ã€‚
ãã“ã§æœ¬ç ”ç©¶ã§ã¯ã€ãƒ˜ã‚·ã‚¢ãƒ³ã‚’çµŒé¨“ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼æƒ…å ±è¡Œåˆ—Ë†F ã§è¿‘ä¼¼ã™ã‚‹ã€‚
H â‰ˆË†F =1ğ‘ğ‘Ã•ğ‘–=1î˜€âˆ‡ğœ½log ğ‘(yğ‘–|xğ‘–; ğœ½)âˆ‡ğœ½log ğ‘(yğ‘–|xğ‘–; ğœ½)âŠ¤î˜.ã“ã“ã§ ğ‘ ã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºã€ğœ½ âˆˆ â„ğ‘‘ã¯ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€(xğ‘–, yğ‘–)ã¯ãƒ‡ãƒ¼ã‚¿ç‚¹ã€âˆ‡ğœ½log ğ‘(yğ‘–|xğ‘–; ğœ½)ã¯å„ãƒ‡ãƒ¼ã‚¿ç‚¹ã®å¯¾æ•°å°¤åº¦ã®å‹¾é…ã§ã‚ã‚‹ã€‚
G = âˆ‡ğœ½log ğ‘(yğ‘–|xğ‘–; ğœ½) âˆˆâ„ğ‘‘Ã—ğ‘ã¨ãŠãã¨Ë†F = GGTâˆˆ â„ğ‘‘Ã—ğ‘‘ã¨æ›¸ã‘ã‚‹ã€‚
G ã¯ãƒŸãƒ‹ãƒãƒƒãƒå†…ã®å„ãƒ‡ãƒ¼ã‚¿ç‚¹ã«ãŠã‘ã‚‹ ğ‘‘ æ¬¡å…ƒã®å‹¾é…ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¸¦ã¹ãŸè¡Œåˆ—ã§ã‚ã‚‹ã€‚
erank(Ë†F)ã®è©•ä¾¡ã¯ rank(Ë†F) = rank(GGT) = rank(GTG)ã®é–¢ä¿‚ã‚’ä½¿ã†ã¨ GTG âˆˆ â„ğ‘ Ã— ğ‘ã®å›ºæœ‰å€¤åˆ†è§£ã«å¸°ç€ã™ã‚‹ã“ã¨ãŒã§ãè¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«ä½æ¸›ã§ãã‚‹(âˆµ ğ‘ â‰ª ğ‘‘)ã€‚
ãªãŠã€æœ¬ç¨¿ã§ã¯Ë†F ã¯å±¤æ¯ã«ãƒ–ãƒ­ãƒƒã‚¯å¯¾è§’å¯èƒ½(Ë†F â‰ˆ diag(Ë†F1,Ë†F2, . . . ,Ë†Fğ¿))ã§ã‚ã‚‹ã“ã¨ã‚’ä»®å®šã—ã€å„å±¤ã®çµŒé¨“ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼Ë†Fğ‘™âˆˆ [1,24]= GTğ‘™Gğ‘™ã®æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ã€‚
BERT ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã¯ä¸‹ä½å±¤ã«æ¯”ã¹ã¦ä¸Šä½å±¤ãŒã‚ˆã‚Šå¤‰æ›´ã‚’å—ã‘ã‚‹ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ãŠã‚Š[14, 15, 16]ã€æœ¬ç¨¿ã®å®Ÿé¨“ã§ã‚‚å±¤æ¯ã®æŒ¯ã‚‹èˆã„ã®é•ã„ã‚’è¦³å¯Ÿã™ã‚‹ãŸã‚ã§ã‚ã‚‹ã€‚
3 å®Ÿé¨“3.1 SimCSE

ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’

äº‹å‰å­¦ç¿’æ¸ˆã¿ BERT ãƒ¢ãƒ‡ãƒ«ã¯ hugging face ã‹ã‚‰å…¥æ‰‹å¯èƒ½ãª google-bert/bert-large-uncased2ï¼‰ã‚’ç”¨ã„ã‚‹ã€‚
SimCSE ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¯åŸè‘—è«–æ–‡[5]ã®å®Ÿè£…ã¨ã‚³ãƒ¼ãƒ‘ã‚¹3ï¼‰ã‚’ä½¿ç”¨ã—ã€google-bert/bert-large-uncased ã«å¯¾ã—ã¦è¿½åŠ å­¦ç¿’ã—ãŸã‚‚ã®ã‚’ç”¨ã„ã‚‹ã€‚
SimCSE å­¦ç¿’æ™‚ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯[5]ã«å¾“ã†ã€‚
ãŸã ã—ã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡ã¯ ğ‘ âˆˆ {0.05, 0.1, 0.3, 0.5} ã¨ã—ã¦ãã‚Œãã‚Œå­¦ç¿’ã™ã‚‹ã€‚
[5]ã§ã¯ STS ã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½ãŒæœ€å¤§ã¨ãªã‚‹ã‚ˆã†ã«å®Ÿé¨“çš„ã« ğ‘ = 0.1 ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚
ä»¥é™ã§ã¯ã€google-bert/bert-large-uncased ã‚’ãŸã‚“ã« vanillaï¼ŒSimCSEãƒ¢ãƒ‡ãƒ«ã¯ğ‘ã®å€¤ã‚’æŒ‡å®šã—ã¦SimCSE(0.1)ãªã©ã¨è¡¨è¨˜ã™ã‚‹ã€‚
3.2 ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã¯ RTE[17, 18, 19, 20]ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
RTE ã‚¿ã‚¹ã‚¯ã¯ãƒ‡ãƒ¼ã‚¿æ•°ãŒæ¯”è¼ƒçš„å°‘ãªãå­¦ç¿’ãŒä¸å®‰å®šã§ã‚ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ãŸã‚[12]ã€å­¦ç¿’ã®å®‰å®šæ€§ã®åˆ†æã‚¿ã‚¹ã‚¯ã¨ã—ã¦é©å½“ã§ã‚ã‚‹ã¨åˆ¤æ–­ã—ãŸã€‚
ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ 16 ã¨ã—ã¦ã€3 ã‚¨2ï¼‰ https://huggingface.co/google-bert/bert-large-uncased3ï¼‰ https://github.com/princeton-nlp/SimCSEâ€• 2216 â€•

0.5 1.0 1.5 2.0 2.5 3.0Learning Rate1e 50.550.600.650.70AccuracySimCSE (0.05)SimCSE (0.1)SimCSE (0.3)SimCSE (0.4)SimCSE (0.5)vanillamajority baselineå›³ 1: RTE ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æ­£è§£ç‡ã®å­¦ç¿’ç‡ä¾å­˜æ€§ã€‚
å­¦ç¿’ç‡ã‚’ä¸Šã’ã¦ã„ãã¨ SimCSE(0.05)ã‚„ SimCSE(0.1)ã«æ¯”ã—ã¦ vanilla ãŒã‚ˆã‚Šæ—©ãæ¸›è¡°ã™ã‚‹ã€‚
ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ã¯ 30 å›è©¦è¡Œã® 95%ä¿¡é ¼åŒºé–“ã€‚
è¡¨ 1: Performance Comparison on diï¬€erent learning ratesLearning rate 1eâˆ’5 2eâˆ’5Model ğ‘†( ğ‘“ ) mean max #failure ğ‘†( ğ‘“ ) mean max #failurevanilla 9.6 64.6 74.0 7/30 3.2 50.5 56.7 25/30SimCSE (0.1) 2.2 70.8 74.0 0/30 9.5 58.3 72.9 14/30ãƒãƒƒã‚¯å­¦ç¿’ã™ã‚‹ã€‚
æœ€å¤§å­¦ç¿’ç‡ã¯[5eâˆ’6, 3eâˆ’5]ã®åŒºé–“ã‹ã‚‰å®Ÿé¨“ã«å¿œã˜ã¦ä½•ç‚¹ã‹æŒ‡å®šã™ã‚‹ã€‚
å­¦ç¿’ç‡ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¯ã€0.3 ã‚¨ãƒãƒƒã‚¯æ™‚ç‚¹ã§æœ€å¤§å­¦ç¿’ç‡ã¨ãªã‚‹ã‚ˆã†ã« 0 ã‹ã‚‰ç·šå½¢ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã€ãã®å¾Œ 3 ã‚¨ãƒãƒƒã‚¯æ™‚ç‚¹ã§ 0 ã«ãªã‚‹ã‚ˆã†ã«ç·šå½¢æ¸›è¡°ã•ã›ã‚‹ã€‚
ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã¯ AdamW[21]ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯transformers.AdamW ã‚¯ãƒ©ã‚¹4ï¼‰ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’æŒ‡å®šã™ã‚‹ã€‚
ãŸã ã—ãƒã‚¤ã‚¢ã‚¹è£œæ­£ã¯ç„¡åŠ¹åŒ–ã™ã‚‹ã€‚
ã“ã‚Œã¯ã€ãƒã‚¤ã‚¢ã‚¹è£œæ­£ã«ã‚ˆã‚‹å­¦ç¿’ã®å®‰å®šåŒ–ã«ã‚ˆã£ã¦ SimCSEã®åŠ¹æœãŒè¦‹ãˆã¥ã‚‰ããªã‚‹ã“ã¨ã‚’é˜²ããŸã‚ã§ã‚ã‚‹ã€‚
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æˆå¦[12]ã‚’è¸è¥²ã—ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹ majoritybaseline ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æˆå¦ã®é–¾å€¤ã¨ã™ã‚‹ã€‚
majority baseline ã¨ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹æœ€å¤šãƒ©ãƒ™ãƒ«ã‚’å¸¸ã«äºˆæ¸¬çµæœã¨ã—ãŸã¨ãã®è©•ä¾¡å€¤ã®ã“ã¨ã§ã€RTE ã‚¿ã‚¹ã‚¯ã®å ´åˆã¯æ­£è§£ç‡ 0.53 ä»¥ä¸‹ã®ã¨ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¤±æ•—ã¨å®šç¾©ã™ã‚‹ã€‚
4 çµæœSimCSE ã¯å­¦ç¿’ç‡ã®å®‰å®šé ˜åŸŸãŒåºƒã„å­¦ç¿’ç‡ã¨æ­£è§£ç‡ã®é–¢ä¿‚ã‚’å›³ 1 ã«ç¤ºã™ã€‚
ã¾ãŸã€è¡¨ 1ã«æœ€å¤§å­¦ç¿’ç‡ 1eâˆ’5, 2eâˆ’5 ã«ãŠã‘ã‚‹ã€æ­£è§£ç‡ã®å¹³å‡ã€4ï¼‰ https://huggingface.co/docs/transformers/v4.44.2/en/main classes/optimizer schedules#transformers.AdamW0Â°15Â°30Â°45Â°60Â°75Â°90Â°105Â°0.00.20.40.60.81.014794141188235282329376423468success, simcse, 2e-5(a)æˆåŠŸ(SimCSE)0Â°15Â°30Â°45Â°60Â°75Â°90Â°105Â°0.00.20.40.60.81.014794141188235282329376423468failure, simcse, 2e-5(b)å¤±æ•—(SimCSE)0Â°15Â°30Â°45Â°60Â°75Â°90Â°105Â°0.00.20.40.60.81.014794141188235282329376423468failure, vanilla, 2e-5(c)å¤±æ•—(vanilla)å›³ 2: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æœ€é©åŒ–è»Œè·¡ã€‚
å„ç‚¹ã®æ¨ªã®æ•°å€¤ã¯ã‚¹ãƒ†ãƒƒãƒ—æ•°ã€è‰²ã¯è¨“ç·´æå¤±å€¤ã‚’è¡¨ã™ã€‚
47 ã‚¹ãƒ†ãƒƒãƒ—ã¾ã§ãŒå­¦ç¿’ç‡ã®ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æœŸé–“ã§ã‚ã‚Šã€ãã‚Œä»¥é™ã¯å­¦ç¿’çµ‚äº†æ™‚ã«å­¦ç¿’ç‡ 0 ã¨ãªã‚‹ã‚ˆã†ã«ç·šå½¢æ¸›è¡°ã™ã‚‹ã€‚
ç°è‰²ã®èƒŒæ™¯ã¯å­¦ç¿’å¤±æ•—ã‚’æ„å‘³ã™ã‚‹ã€‚
æ¨™æº–åå·®ã€æœ€å¤§å€¤ã€å¤±æ•—å›æ•°ã‚’ç¤ºã™ã€‚
1eâˆ’5 ã§ã¯ã€æ­£è§£ç‡ã®æœ€å¤§å€¤ã¯åŒç¨‹åº¦ã§ã‚ã‚‹ãŒæ¨™æº–åå·®ã¨å¹³å‡å€¤ã¯SimCSE (0.1)ãŒæœ‰åˆ©ã§ã‚ã‚‹ã€‚
2eâˆ’5 ã§ã¯ã€vanilla ã®æ–¹ãŒæ¨™æº–åå·®ã¯å°ã•ã„ãŒã€ã“ã‚Œã¯ vanilla ã§ã¯ã»ã¨ã‚“ã©ã®è©¦è¡Œã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¤±æ•—ã—ã¦ã„ã‚‹ãŸã‚ã§ã‚ã‚‹ã€‚
ä»¥ä¸Šã®çµæœã‚ˆã‚Š SimCSE (0.1)ã¯ã‚ˆã‚Šå¤§ããªå­¦ç¿’ç‡ã«å¯¾ã—ã¦ã‚‚ã‚ˆã‚Šå®‰å®šã§ã‚ã‚‹ã¨ã„ãˆã‚‹ã€‚
SimCSE ã®å­¦ç¿’åˆæœŸã®æœ€é©åŒ–è»Œè·¡ã¯ç­‰æ–¹çš„å›³ 2 ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®è»Œè·¡ã‚’(ğ‘Ÿğ‘¡, ğœ‘ğ‘¡) =î˜âˆ¥Î” ğœƒğ‘¡âˆ¥âˆ¥Î” ğœƒğ‘–ğ‘›ğ‘–ğ‘¡âˆ¥,cosâˆ’1î˜€Î” ğœƒğ‘¡Â·Î” ğœƒğ‘–ğ‘›ğ‘–ğ‘¡âˆ¥Î” ğœƒğ‘¡âˆ¥ âˆ¥Î” ğœƒğ‘–ğ‘›ğ‘–ğ‘¡âˆ¥î˜î˜‘ã® 2 æ¬¡å…ƒæ¥µåº§æ¨™ã§è¡¨ç¤ºã™ã‚‹ã€‚
ã“ã“ã§ã€ğ‘¡ ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã€Î”ğœƒğ‘¡= ğœƒğ‘¡âˆ’ ğœƒğ‘“ ğ‘–ğ‘›ã§ã‚ã‚‹ã€‚
ã“ã®å¯è¦–åŒ–æ‰‹æ³•ã¯[22]ã§ææ¡ˆã•ã‚ŒãŸæ–¹æ³•ã§ã€å­¦ç¿’ã®çµ‚ç‚¹ã‹ã‚‰ã¿ãŸã¨ãã®åˆæœŸå€¤ã«å¯¾ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®è»Œè·¡ã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚
å›³ 2b å›³ 2c ã‚ˆã‚Šã€å­¦ç¿’å¤±æ•—æ™‚ã¯å­¦ç¿’åˆæœŸã«ãŠã„ã¦ ğœ‘ æ–¹å‘ã«å¤§ããå¤‰ä½ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚
å­¦ç¿’ç‡ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ 0 ã‹ã‚‰æœ€å¤§å­¦ç¿’ç‡ã¾ã§ç·šå½¢ã«ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚å­¦ç¿’åˆæœŸã«ãŠã„ã¦ã¯å­¦ç¿’ç‡ã¯å°ã•ã„ã€‚
ã‚ˆã£ã¦ã€ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ä¸­ã®å¤§ããªåè§’ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®ç‰¹å®šæ–¹å‘ã«åã£ã¦å¤‰ä½ã—ãŸã“ã¨ã‚’æ„å‘³ã™ã‚‹ã€‚
ã“ã®æŒ¯ã‚‹èˆã„ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®æ›²ç‡ãŒå¤§ãã„ã“ã¨ã‚’ç¤ºå”†ã™ã‚‹ã€‚
ä¸€æ–¹ã€å­¦ç¿’æˆåŠŸæ™‚ã®è»Œè·¡å›³ 2a ã¯ã€å­¦ç¿’åˆæœŸã«ã¯ç­‰æ–¹çš„ã« ğœƒğ‘“ ğ‘–ğ‘›ã«å‘ã‹ã†ã€‚
ã“ã‚Œã¯å­¦ç¿’åˆæœŸã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ãŒã‚ˆã‚Šå¹³å¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã™ã‚‹ã€‚
SimCSE ã® erank(

Ë†



F) ã¯ã‚ˆã‚Šå¤§ãã„

å„ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å‰ã®å„å±¤ã®erank(Ë†Fğ‘™)ã‚’å›³ 3 ã«ç¤ºã™ã€‚
ã“ã“ã§ã€æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã¯æœ€å¤§ãƒ©ãƒ³ã‚¯ã§æ­£è¦åŒ–ã—ã¦ã„ã‚‹ã€‚
å›³ã‚ˆã‚Šã€SimCSE(0.05)ã‚„SimCSE(0.1)ï¼ŒSimCSE(0.3)ã¯ã™ã¹ã¦ã®å±¤ã§ vanilla ã¨æ¯”ã¹ã¦æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã¯å¤§ãã„ã€‚
ã¾ãŸã€SimCSE(0.5)ã¯ã€å‡ºåŠ›å´ã§ erank(Ë†Fğ‘™)ãŒå¤§ããæ¸›å°‘ã—å±¤æ–¹å‘ã®éä¸€æ§˜æ€§ãŒå¢—å¤§ã—ã¦ã„ã‚‹ã€‚
ã“ã®çµæœã¨å›³ 1 ã‚ˆã‚Šã€å¯å¡‘æ€§ã¯â€• 2217 â€•

0 5 10 15 20 25layer_id0.00.20.40.60.81.0Nomalized effrank(F)SimCSE(0.05)SimCSE(0.1)SimCSE(0.3)SimCSE(0.4)SimCSE(0.5)vanillaå›³ 3: erank(Ë†Fğ‘™)ã®å¹³å‡ï¼ˆ30 å›è©¦è¡Œï¼‰ã€‚
å¸¯ã¯ 95%ä¿¡é ¼åŒºé–“ã€‚
æœ€å¤§ãƒ©ãƒ³ã‚¯ã§è¦æ ¼åŒ–ã—ã¦ã„ã‚‹ã€‚
æ¨ªè»¸ã¯ BERT ã®å„å±¤ã«å¯¾å¿œã—ã¦ãŠã‚Šæ•°å­—ãŒå°ã•ã„ã»ã©å…¥åŠ›å´ã«è¿‘ã„ã“ã¨ã‚’æ„å‘³ã™ã‚‹ã€‚
è¡¨ 2: BERT å…¨ä½“ã®Ë†F ã®æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã€‚
SimCSE(0.1)ãªã©ã¯å˜ã« 0.1ã¨è¡¨è¨˜ã™ã‚‹ã€‚
Model 0.05 0.1 0.3 0.4 0.5 vanillaerank(Ë†F) 23.20 23.43 23.39 21.23 8.17 20.06erank(Ë†Fğ‘™)ã®å¤§ãã•ã‚„éä¸€æ§˜æ€§ã«ä¾å­˜ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚
ä»¥ä¸Šã‚ˆã‚Šã€é©åˆ‡ãªãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡ã«ã‚ˆã£ã¦ SimCSE ã§è¿½åŠ å­¦ç¿’ã™ã‚‹ã“ã¨ã¯ erank(Ë†Fğ‘™)ã®å›å¾©ã‚’ã‚‚ãŸã‚‰ã—çµæœã¨ã—ã¦å¯å¡‘æ€§ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚
ã¾ãŸã€BERT å…¨ä½“ã® erank(Ë†F)ã¯è¡¨ 2ã¨ãªã‚‹5ï¼‰ï¼ğ‘ ãŒå°ã•ã„é ˜åŸŸã§ erank(Ë†F)ã¯ vanilla ã‚ˆã‚Šå¤§ãããªã‚Šå¯å¡‘æ€§ãŒå¤§ãã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚
ã“ã®çµæœã¯å›³ 1 ã®çµæœã¨æ¦‚ã­æ•´åˆã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚



ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æˆåŠŸæ™‚ã¯ erank(



Ë†



F)



ã¯ä¿å­˜ã•ã‚Œã‚‹

ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã® erank(Ë†Fğ‘™)ã®é€²åŒ–ã‚’å›³ 4 ã«ç¤ºã™ã€‚
ã“ã“ã§ã¯ã€{SimCSE(0.1), vanilla} Ã— {1eâˆ’5, 2eâˆ’5, 3eâˆ’5} ã® 6 ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™ã€‚
å›³ã‚ˆã‚Šã€æœ€ã‚‚æ€§èƒ½ãŒè‰¯ã„(Sim-CSE(0.1), lr=1e-5)ã®ã¨ãã¯ã€erank(Ë†Fğ‘™)ã®å€¤ã¨å±¤æ–¹å‘ã®ä¸€æ§˜æ€§ã¯å­¦ç¿’å¾Œã‚‚ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã€‚
æœ€å¤§å­¦ç¿’ç‡ã‚’ä¸Šã’ã‚‹ã¨å±¤æ–¹å‘ã®éä¸€æ§˜æ€§ãŒå¢—å¤§ã—ã€(vanilla, 2eâˆ’5)ã¨ 3eâˆ’5 ã®ä¸¡ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’ãŒå¤±æ•—ã™ã‚‹ã€‚
å­¦ç¿’å¤±æ•—æ™‚ã§ã¯ã€ã‚ã‚‹æ™‚åˆ»ã‚’çš®åˆ‡ã‚Šã«ä¸­å±¤ã€œä¸Šä½å±¤ã«ãŠã„ã¦å±¤æ–¹å‘ã®éä¸€æ§˜æ€§ãŒã•ã‚‰ã«å¢—å¤§ã— erank(Ë†Fğ‘™)ãŒå´©å£Šã™ã‚‹ã€‚
ã“ã‚Œã‚ˆã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å¤±æ•—ã¯ erank(Ë†Fğ‘™)ã®ãƒ©ãƒ³ã‚¯å´©å£Šã¨ã—ã¦ç¾ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚
ä¸Šè¨˜ã®çµæœã‚ˆã‚Šã€SimCSE ã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ã«ã¯erank(Ë†Fğ‘™)ã®å±¤æ–¹å‘ã®éä¸€æ§˜æ€§ã®å¢—å¤§ã‚’æŠ‘åˆ¶ã—ã€çµæœ5ï¼‰Ë†F ãŒãƒ–ãƒ­ãƒƒã‚¯å¯¾è§’å¯èƒ½ã®ä»®å®šã®ã‚‚ã¨ã§ã¯ã€rank (Ë†F) =Ãğ‘™rank(Ë†Fğ‘™)0 5 10 15 20 25layer_id0.00.20.40.60.81.0Nomalized effrank(F)SimCSE(0.1), lr=1e-5, Acc=0.710 5 10 15 20 25layer_id0.00.20.40.60.81.0Nomalized effrank(F)vanilla, lr=1e-5, Acc=0.680 5 10 15 20 25layer_id0.00.20.40.60.81.0Nomalized effrank(F)SimCSE(0.1), lr=2e-5, Acc=0.700 5 10 15 20 25layer_id0.00.20.40.60.81.0Nomalized effrank(F)vanilla, lr=2e-5, Acc=0.530 5 10 15 20 25layer_id0.00.20.40.60.81.0Nomalized effrank(F)SimCSE(0.1), lr=3e-5, Acc=0.530 5 10 15 20 25layer_id0.00.20.40.60.81.0Nomalized effrank(F)vanilla, lr=3e-5, Acc=0.5312344794141188235282329376423468å›³ 4: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã® erank(Ë†Fğ‘™)ã®é€²åŒ–ã€‚
æ¨ªè»¸ã¯BERT ã®å„å±¤ã«å¯¾å¿œã—ã€æ•°å­—ã®å°ã•ã„æ–¹ãŒå…¥åŠ›å´ã‚’æ„å‘³ã™ã‚‹ã€‚
å·¦åˆ—ãŒ SimCSE(0.1)ã€å³åˆ—ãŒ vanillaã€ä¸Šã‹ã‚‰æœ€å¤§å­¦ç¿’ç‡ãŒ1eâˆ’5, 2eâˆ’5, 3eâˆ’5 ã®ã¨ãã®çµæœã§ã‚ã‚‹ã€‚
ã¾ãŸç·šã®è‰²ã¯ã‚¹ãƒ†ãƒƒãƒ—æ•°ã€ç°è‰²ã®èƒŒæ™¯ã¯å­¦ç¿’å¤±æ•—ã‚’è¡¨ã™ã€‚
çš„ã«å´©å£Šã‚’é…ã‚‰ã›ã‚‹åŠ¹æœãŒã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚
5 ãŠã‚ã‚Šã«æœ¬ç ”ç©¶ã§ã¯ã€BERT ã«å¯¾ã™ã‚‹ SimCSE ã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ãŒãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚‚ãŸã‚‰ã™å½±éŸ¿ã‚’å®Ÿé¨“çš„ã«èª¿æŸ»ã—ãŸã€‚
å®Ÿé¨“ã§ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹æ›²ç‡æƒ…å ±ã‚’ä¿æŒã™ã‚‹ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼æƒ…å ±è¡Œåˆ—ã®æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã«ç€ç›®ã—ã€å®‰å®šæ€§ã¨å¯å¡‘æ€§ã®è¦³ç‚¹ã§åˆ†æã—ãŸã€‚
å®Ÿé¨“ã®çµæœã€é©åˆ‡ãªè¨­å®šã§ã® SimCSE ã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ã«ã¯( ğ‘– )å¤§ãã„å­¦ç¿’ç‡ã§ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šåŒ–åŠ¹æœã¨( ğ‘–ğ‘– ) erank(Ë†F)ã®å›å¾©ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã§å¯å¡‘æ€§ã‚’å‘ä¸Šã•ã›ã‚‹åŠ¹æœãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚
ä»Šå¾Œã®èª²é¡Œã¨ã—ã¦ã¯ã€( ğ‘– )ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼æƒ…å ±è¡Œåˆ—ã®ãƒ–ãƒ­ãƒƒã‚¯å¯¾è§’è¿‘ä¼¼ã®å¦¥å½“æ€§ã®è­°è«–ã€(ğ‘–ğ‘– )ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¿ã‚¹ã‚¯ã€è¿½åŠ å­¦ç¿’æ‰‹æ³•ã«ã‚ˆã‚‹æ¤œè¨¼ã€(ğ‘–ğ‘–ğ‘–)æœ¬ç¨¿ã®å®Ÿé¨“ã§ã¯ç°¡å˜ã®ãŸã‚å­¦ç¿’ç‡ã®ã¿å¤‰æ›´ã—ãŸãŒã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ã¯ã©ã®ã‚ˆã†ãªé–¢ä¿‚ã«ã‚ã‚‹ã®ã‹ã®èª¿æŸ»ã€(ğ‘–ğ‘£)å¯¾ç…§æå¤±ã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ãŒæœ‰åŠ¹ãƒ©ãƒ³ã‚¯ã®å›å¾©ã‚’ã‚‚ãŸã‚‰ã™ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®åŸç†çš„è§£æ˜ã€ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã€‚
â€• 2218 â€•



å‚è€ƒæ–‡çŒ®


[1] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and KristinaToutanova. BERT: Pre-training of deep bidirectional transform-ers for language understanding. In Jill Burstein, Christy Doran,and Thamar Solorio, editors, Proceedings of the 2019 Con-ference of the North American Chapter of the Associationfor Computational Linguistics: Human Languag e Technolo-gies, Volume 1 (Long and Short Papers), pp. 4171â€“4186, 2019.
[2] Bohan Li, Hao Zhou, Junxian He, Mingxuan Wang, Yiming Yang,and Lei Li. On the sentence embeddings from pre-trained languagemodels. In Bonnie Webber, Trevor Cohn, Yulan He, and YangLiu, editors, Proceedings of the 2020 Conference on Empir-ical Methods in Natural Language Processing (EMNLP), pp.9119â€“9130, 2020.
[3] Jianlin Su, Jiarun Cao, Weijie Liu, and Yangyiwen Ou. Whiten-ing Sentence Representations for Better Semantics and Faster Re-trieval. arXiv preprint arXiv:2103.15316, 2021.
[4] Yuanmeng Yan, Rumei Li, Sirui Wang, Fuzheng Zhang, Wei Wu,and Weiran Xu. ConSERT: A contrastive framework for self-supervised sentence representation transfer. In Chengqing Zong,Fei Xia, Wenjie Li, and Roberto Navigli, editors, Proceedingsof the 59th Annual Meeting of the Association for Compu-tational Linguistics and the 11th International Joint Confer-ence on Natural Language Processing (Volume 1: Long Pa-pers), pp. 5065â€“5075, 2021.
[5] Tianyu Gao, Xingcheng Yao, and Danqi Chen. SimCSE: Simplecontrastive learning of sentence embeddings. In Marie-FrancineMoens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih,editors, Proceedings of the 2021 Conference on EmpiricalMethods in Natural Language Processing, pp. 6894â€“6910,2021.
[6] Jiahao Xu, Wei Shao, Lihui Chen, and Lemao Liu. SimCSE++:Improving contrastive learning for sentence embeddings from twoperspectives. In Houda Bouamor, Juan Pino, and Kalika Bali,editors, Proceedings of the 2023 Conference on EmpiricalMethods in Natural Language Processing, pp. 12028â€“12040,2023.
[7] Yuhao Zhang, Hongji Zhu, Yongliang Wang, Nan Xu, Xiaobo Li,and Binqiang Zhao. A contrastive framework for learning sentencerepresentations from pairwise and triple-wise perspective in angu-lar space. In Smaranda Muresan, Preslav Nakov, and Aline Villav-icencio, editors,Proceedings of the 60th Annual Meeting ofthe Association for Computational Linguistics (Volume 1:Long Papers), pp. 4892â€“4903, 2022.
[8] Nils Reimers and Iryna Gurevych. Sentence-BERT: Sentence em-beddings using Siamese BERT-networks. In Kentaro Inui, JingJiang, Vincent Ng, and Xiaojun Wan, editors, Proceedings of the2019 Conference on Empirical Methods in Natural LanguageProcessing and the 9th International Joint Conference onNatural Language Processing (EMNLP-IJCNLP), pp. 3982â€“3992, 2019.
[9] Mingxin Li, Richong Zhang, and Zhijie Nie. Towards better under-standing of contrastive sentence representation learning: A uniï¬edparadigm for gradient. In Lun-Wei Ku, Andre Martins, and VivekSrikumar, editors, Proceedings of the 62nd Annual Meetingof the Association for Computational Linguistics (Volume1: Long Papers), pp. 14506â€“14521, 2024.
[10] Junjie Huang, Duyu Tang, Wanjun Zhong, Shuai Lu, Linjun Shou,Ming Gong, Daxin Jiang, and Nan Duan. WhiteningBERT: An easyunsupervised sentence embedding approach. In Marie-FrancineMoens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih,editors, Findings of the Association for Computational Lin-guistics: EMNLP 2021, pp. 238â€“244, 2021.
[11] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. RepresentationLearning with Contrastive Predictive Coding. arXiv e-prints, p.arXiv:1807.03748, 2018.
[12] Marius Mosbach, Maksym Andriushchenko, and Dietrich Klakow.On the stability of ï¬ne-tuning BERT: Misconceptions, explana-tions, and strong baselines. In International Conference onLearning Representations, 2021.
[13] Alex Lewandowski, Haruto Tanaka, Dale Schuurmans, and Mar-los C. Machado. Directions of Curvature as an Explanation forLoss of Plasticity. arXiv e-prints, p. arXiv:2312.00246, 2023.
[14] Amil Merchant, Elahe Rahimtoroghi, Ellie Pavlick, and Ian Ten-ney. What happens to BERT embeddings during ï¬ne-tuning? InAfra Alishahi, Yonatan Belinkov, Grzegorz Chrupa la, DieuwkeHupkes, Yuval Pinter, and Hassan Sajjad, editors, Proceedingsof the Third BlackboxNLP Workshop on Analyzing and In-terpreting Neural Networks for NLP, pp. 33â€“44, 2020.
[15] Yaru Hao, Li Dong, Furu Wei, and Ke Xu. Investigating learningdynamics of BERT ï¬ne-tuning. In Kam-Fai Wong, Kevin Knight,and Hua Wu, editors, Proceedings of the 1st Conference of theAsia-Paciï¬c Chapter of the Association for ComputationalLinguistics and the 10th International Joint Conference onNatural Language Processing, pp. 87â€“92, 2020.
[16] Yichu Zhou and Vivek Srikumar. A closer look at how ï¬ne-tuning changes BERT. In Smaranda Muresan, Preslav Nakov, andAline Villavicencio, editors, Proceedings of the 60th AnnualMeeting of the Association for Computational Linguistics(Volume 1: Long Papers), pp. 1046â€“1061, 2022.
[17] Ido Dagan, Oren Glickman, and Bernardo Magnini. The pascalrecognising textual entailment challenge. In Joaquin QuiËœnonero-Candela, Ido Dagan, Bernardo Magnini, and Florence dâ€™AlchÂ´e Buc,editors, Machine Learning Challenges. Evaluating PredictiveUncertainty, Visual Object Classiï¬cation, and RecognisingTectual Entailment, pp. 177â€“190, 2006.
[18] Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Gi-ampiccolo, Bernardo Magnini, and Idan Szpektor. The secondpascal recognising textual entailment challenge. 2006.
[19] Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and BillDolan. The third PASCAL recognizing textual entailment chal-lenge. In Satoshi Sekine, Kentaro Inui, Ido Dagan, Bill Dolan,Danilo Giampiccolo, and Bernardo Magnini, editors, Proceed-ings of the ACL-PASCAL Workshop on Textual Entailmentand Paraphrasing, pp. 1â€“9, 2007.
[20] Luisa Bentivogli, Bernardo Magnini, Ido Dagan, Hoa Trang Dang,and Danilo Giampiccolo. The ï¬fth PASCAL recognizing textualentailment challenge. In Proceedings of the Second Text Anal-ysis Conference, TAC 2009, Gaithersburg, Maryland, USA,November 16-17, 2009, 2009.
[21] Ilya Loshchilov and Frank Hutter. Decoupled weight decay reg-ularization. In International Conference on Learning Repre-sentations, 2019.
[22] Namuk Park and Songkuk Kim. How do vision transformers work?In International Conference on Learning Representations,2022.â€• 2219 â€•