多言語音声転写アプリと AI による外国語授業の自己分析 Multilingual Voice-to-Text App の開発   砂岡和子1 徐勤 2   1早稲田大学政治経済学術院 2京都大学文学研究科  ksunaoka@gmail.com  xu.qin.4f@kyoto-u.ac.jp   

概要 

生成系 AI を活用した自動音声認識技術（Automatic Speech Recognition：ASR）は飛躍的に進歩しているが、頻繁に言語コードが切り替わる自然発話（Code-switching：CS）の認識は依然として課題が残る。
筆者らは、Whisper large-v3 を用いた多人数CS 発話のテキスト転写技術に基づき、より操作性に優れた多言語対応音声テキスト化アプリ（Multilingual Voice-to-Text App）を開発した。
本アプリを使用することで、習得目標言語（Ｌ2）と母語（Ｌ1）が混じる外国語授業の発話を、授業実施者や学習者自身が随時可視化できる。
本稿では APP の開発経緯と、日本語と中国語が切り替わる授業発話に APP を用い、認識精度が向上した結果を示す。
さらに、ChatGPT を用いた発話内容の質的分析を通じて、簡便に授業を振り返る手法を提案する。 


1 研究目的 

講義における演者や聴衆の発話行為を分析するには、講演音声のテキスト変換が不可欠である[1][2] [3][4][5]。
近年の生成系 AI 技術を用いた自動音声認識（ASR）の精度向上により、音声の書き起こしコストは大幅に削減された[6][7]。
しかし、初中級レベルの外国語授業に典型的に見られるように、複数言語が頻繁に切り替わる発話では、ASR の認識率が大幅に低下し、外国語授業の発話分析の障害となっている[9][10][11]。
伝統的な分析手法（Action Reach）のもう一つの壁は，Communicative  Orientation  of  Language  Teaching（COLT）や FRINT System のように、その評価に高度な専門知識と膨大な時間がかかる点である[5] [11]。
高校や大学英語教育のように、授業用言語がほ ①https://book.st-hakky.com/data-science/whisper-transcription/ ぼ単一（英語）で、文字転写効率が良好な場合も、参与者自身の授業振り返りは容易ではない[6][7][8]。
我々は，Whisper の最新版モデル large-v3 とPyannote.audio を用いて、複数言語コードを含む発話の転写および話者分離の精度向上を試みてきた[13][14]。
複数の中国語授業に対し、実際にこれらのプログラムを適用した結果、これまでに以下の成果が得られた。
1. large-v3 の使用で、日本語と中国語の CS 発話における ASR 精度が約 8 割まで向上した。
2.多人数の CS 発話に対し、Pyannote.audio を用い話者分離（Speaker  Diarization：SD）を行った結果、従来手法に比べ SD の精度が向上した[13]。
ただし、Whisper や Pyannote.audio はプログラミングの知識が必要なため、授業実施者や学習者が利用しにくい難点があった。
そこで、本研究では分析ツールの操作を簡便化し、多くの授業参与者が直接発話データを分析でき、プログラミング不要のアプリ開発を目標に据えた。
アプリには発話中の複数言語（L1 と L2）の使用比率を自動で可視化する機能を備える。
これら量的分析に加え、ChatGPT を活用した転写テキストの質的分析を行い、教員や学習者が授業を振り返る手法を提案する。
アプリと AI の適用により、コードスイッチ方略を見直し[15][16]、外国語運用の向上に活かすことができる[17][18]。



2 Whipser Large V3 Turbo の概要 

Whipser Large V3 Turbo（以下 turbo と表記）は 2024年 10 月に OpenAI がリリースした高精度で高速な音声認識モデルである。
Whisper は、2022 年 9 月 22 日公開の汎用音声認識ツール①で，68 万時間の多言語音声データで学習・訓練された。
2022 年 12 月に large-v2 モデルが追加され、  2023 年 11 月には large  -v3 が登場した。
現在、Whisper の利用可能な学習済みモデルサイズは tiny, base, small, medium, large, turbo の 6種類あり、いずれも多言語書き起しに対応する（図 1)。
 
図1.Whisper のモデル② 図 2 は、Whisper の各モデルの推論速度（横軸：右ほど高速）と精度（縦軸：下ほど高精度）を示している。
large-v2，large-v3，turbo は最も精度が高い上位 3 モデルである。
Turbo は large-v3 のデコーダ層を 32 から 4 に削減し、large-v2 の精度を維持しつつ、大幅な高速化を実現している③．  図 2. Whisper モデルの推論速度と精度④ 

3 Large-v2/v3/turbo による APP 開発 

3. 1 Web 対応アプリケーションの開発 本実験では、Whisper の高精度モデル（large-v2, large-v3, turbo）を実装し、プログラミング不要で音声転写が可能なアプリを開発した。
表１にアプリ開発用の Python プログラムコードの一部を示す。
ローカルホストのポート 8090 で実行すると、Web 対応のアプリ画面図 3 が起動する。
Python プログラムをPyInstaller でアプリ化し、PC（デスクトップ）対応の「 Voice-to-Text」アプリを実装した。
アプリ画面で音声ファイルをアップロードし、Whisper の音声転写モデル（large-v2/v3/turbo）を選択後、「Analysis」ボタンをクリックすると、音声の文字変換が実行さ ②https://github.com/openai/whisper ③https://medium.com/axinc/whipser-large-v3-turbo-%E9%AB%98%E7%B2%BE%E5%BA%A6%E3%81%A7%E9%AB%98%E9%80%9F%E3%81%AA%E9%9F%B3れる。
転写結果の画面では、話者ごとに発話内容を表示するとともに、グラフ形式で言語別の比率が可視化される図 4。
現時点で Mac  OS 版のアプリが利用可能で、Web サイトでの公開を検討している。
表1. Python コードの一部 from flask import Flask, render_template, request, jsonifyimport whisper import matplotlib.pyplot as plt …… app = Flask(__name__) …… models = {} def load_models(): global models models = { "turbo": whisper.load_model("turbo"), "large-v2": whisper.load_model("large-v2"), "large-v3": whisper.load_model("large-v3"),} load_models() …… if __name__ == "__main__": app.run(debug=True, host='0.0.0.0', port=8090) 図 3.Web 対応アプリケーションの画面  図 4. APP（turbo）による音声転写の画面 %E5%A3%B0%E8%AA%8D%E8%AD%98%E3%83%A2%E3%83%87%E3%83%AB-249538d2665b ④https://github.com/openai/whisper/discussions/2363  3.2 書き起こしの比較実験 3.2.1 中国語初級授業の Transcription 図 5 は、 中国語初級授業の録音（A 大学 2022 年）約 30 秒間の音声クリップに対し、 それぞれ Large-v2, Large-v3, turbo で APP による transcription を行い、手作業による書き起こし内容を基に、3 種モデルの転写精度を比較した結果である。  
図 5.中国語初級授業 Transcription 結果比較  表中の「割合」は日本語（L1）と中国語（L2）の比率を、CRE（Character Error Rates：文字誤り率）の「1.0 - CER」⑤に準じ計算した結果で、数値が低いほど文字認識率（精度）が高いことを意味する。
図 5 から、turbo の転写結果は CRE6.54%で、最も高い認識率となった。
Transcription 全文は付録 1 を参照のこと。
そのため、次節の分析では主に turbo モデルを使用して音声転写を行う。
3.2.2 学生中国語プレゼンの Transcription 図 6 は、 中国語中級授業（B 大学 2024 年 12 月）で実施された、学生による口頭プレゼンテーションの音声ファイル（3 分 16 秒）を使用し、 APP で Whisperの Turbo モデルを用い音声転写を行った結果の一部である。
CRE の文字誤り率は 24.17%で、上記中国語初級授業における教員発話の転写結果と比べると、認識率はかなり低い。
原因として元の録音状態が劣り、学生の中国語音声に非正規表現が多いことが挙げられる。
書き起こしテキスト、 手動校正済の発話内容、 およびプレゼン用パワーポイント原文（一部）は、 付録 2 を参照のこと。  
⑤音声認識の CER(文字誤り率)の計算方法：https://qiita.com/Kchan/items/7bba1f066234ba24898b 

4 発話分析 

4.1 APP による発話の量的分析例 上掲 APP の書き起こし結果から、次のような発話の量的情報を得ることができる。
A.チャンクごと、発話者別に発話内容、発話量（文字数）と継続時間が表示され、教授者と学生間のインタラクションを可視化できる図 4&6、付録 1． B. 繰り返しや相槌、フィラーなど、自然発話に特有の現象がテキストとして文字化され、会話分析の基礎データに使用できる付録 1&2． C. L1 と L2 の比率をグラフで直感的に把握できる。
上掲、初級中国語授業の一場面における L1(日本語)対 L2 (中国語)の割合は 57.89%と 42.11%となり図 4、実際は中国語の使用率は 20.21%で，APP自動計算より低いが、日本の初修第二外国語では一般的な比率である[10]。
対して学生口頭プレゼン図6 では L2 (中国語)が 100％で、本授業は教科内容と外国語学習を統合した Content and Language Integrated Learning（CLIL）と言えよう。
このように本 APP で、教員自身が自身の L2 比率を可視化することで、CS 方略を見直し、L2 使用頻度の向上に活かすことができる。
D. ASR の誤認識結果から発話者の発音誤り（主にL2）を検出する。
上掲プレゼンを行った学生の中国語には不明瞭な発音が含まれる。
APP はこれを別の単語に聞き取っている表 2。
転写結果から発音誤りを発見し、発音矯正に役立てることができる。
 
図 6.学生口頭プレゼンの音声転写 表 2. 学生口頭プレゼン中の ASR 誤認識検出  []内は中国語の発⾳，斜体：ASR の誤認識箇所 4.2 ChatGPT による発話の質的分析例 App による転写結果は発話の量的情報を多く提供するが、発話内容の質的改善のヒントは読み取りにくい。
以下、生成 AI ツールを活用し、転写テキストから発話の質的特徴を抽出する方法を示す。
E. ChatGPT を用いて、プレゼン用 PPT のテキストを校正し、併せて修正理由を提示する図 7． F. 修正済テキストを口頭発表用スクリプトに書き換える。
中国語の発音表記（ピンイン）も加える図8。
このほか、AI で内容の論理構成検証、発話者の語学レベルに応じた語彙や文法を用いた表現の生成も可能である。
G. AI ツールで、APP 転写結果とプレゼン用 PPT テキストを Excel 形式で対照し、口頭 Speech と文章語の差分比較とその要因を挙げる(具体例略)。
 
以下の中国語によるプレゼン用 PPT の原文をより自然かつ規範的な中国語に校正して。
修正箇所にはそれぞれそのように修正した理由を述べて＃＃（以下 PPT原文を入力）  原文：中国是差别多的社会、富裕层用丰富的资金来购物不动产，有的人有几个房子、可是他们只住在这三个房子之一，别的是为了将来投资购物的。
修正：中国是一个贫富差距较大的社会、富裕阶层将大量资金投入房地产市场、许多人拥有多套房产、但只居住其中一套、其余房产作为投资持有。
理由：「差别多的社会」→「贫富差距较大的社会」：より規範的な表現で、一般的な経済用語を使いました。
（後略）図 7. PPT 校正 ChatGPT Prompt と⽣成結果 校正済プレゼン用 PPT の原稿を、口頭発表用の文章に書き換え、漢字に発音記号（ピンイン）を付けて。
＃＃（以下 PPT 原文を入力）  ⑥https://github.com/openai/whisper  4. 过度的投资 guò dù de tóu zī 中国的贫富差距比较大、富裕的人有钱投资房产、很多人买了好几套房子。
zhōng guó de pín fù chā jù bǐ jiào dà ，fù yù de（後略） 図 8.PPT 校正 ChatGPT Prompt と生成結果 

5  まとめと課題 

外国語授業の発話を素材に、Whisper  Large  V3 Turbo を用いて複数言語コードを含む発話音声の自動転写を行うアプリ（Multilingual Voice-to-Text APP）を開発した。
授業中の発話内容や文字数、L1 と L2の比率を自動集計し、言語運用を可視化できる（精度は約 7〜8 割）。
さらに、転写結果を ChatGPT で処理し、L2 の発音誤りや教師・学習者間のインタラクション、CS 頻度の分析に応用する手法を提案した。
現在、本 APP には以下の課題がある。
1。
起動速度が遅い：Whisper の 3 つの音声認識モデルを組み込み、大量のメモリと計算時間を要するため⑥。
計算時間は turbo が large-v2/v3 より高速である図 2． 2。
変換精度が 100%に達しない：公式レポートでもCER（文字誤り率）に関する報告がある⑦． 3。
日中漢字の識別精度の問題：漢字がすべて中国語と見なされ、ひらがな・カタカナのみを日本語に識別するため、中国語の比率が過大に表示される傾向がある。
4。
話者分離機能の未搭載：プログラム負荷軽減のため、話者分離は実装していない。
現状では発話者ごとに改行して転写するが、精度は高くない。
今後の課題として、多言語認識精度の向上やデータ処理遅延の解消が求められる。
本 APP の基本コンセプトは多言語音声データの簡便な文字転写と、AIによる質的分析への応用である。
COLT や FRINT System のような本格的な授業分析には、データ再処理や AI プロンプトの調整が必要となる。
APP 開発と並行して、質的分析の自動化も今後の課題とする。
語学教員や学生が、自身の授業中の言語活動を随時振り返り、CS 方略や授業デザインの改善に役立てるツールとして活用することを期待する。
⑦https://github.com/openai/whisper/discussions/2363 正解 ASR の誤認識（Turbo）男性[nanxing]是 22 岁以后 人生[rensheng]是二十 二歲以後 年轻人[nianqingren]为什么不结婚 您[nin]今天為什麼不結婚



謝辞 

本研究の一部は JSPS 科研費 23K18866,  24K16129（代表者：徐勤）と，JSPS 科研費 21K00773,  JP24K04091（代表者：砂岡和子）の助成を受けている。  

参考文献 

1. Spada, N., & Fröhlich, M. COLT Communicative Orientation of Language Teaching Observation Scheme, Coding Conventions and Applications. Sydney: Macquarie University.1995. 2. 石塚博規・横山吉樹・平田洋子・青木千加子・伊東優子・河合靖・高井収・新井良夫． CO LT Part A によるコミュニケーションを指向した英語プラグラムの授業分析，J Research Bulletin of Eng1ish Teaching，2，pp.41-63. 2005. https://doi.org/10.32150/00007077. 2024-12 閲覧. 3. 飯窪真也, 齊藤萌木, 白水始, 堀公彦，授業研究における教師と研究者の相互作用のリアリティ ，認知科学 27(4) ， pp.461-486 ， 2020 ．https://www.jstage.jst.go.jp/article/jcss/27/4/27_2020.043/_pdf/-char/ja，2024-11 閲覧. 4. 石野未架，教師の相互行為能力は記述可能か─英語授業の会話分析による試み，多賀出版，2023． 5. 曲明，砂岡和子汉语 Hyflex 课堂教学分析—教师与学生发 言行为 的分析，The Journal of Modernization of Chinese Language Education ，Vol.13 No.2. pp. 14-24，2024. 6. Ishizuka, H., & Kibler, R. Development of automatic language classroom analysis system. Proceedings of Ed Media: World Conference on Educational Media and Technology，Association for the Advancement of Computing in Education (AACE)．pp.626-630. 2018. 7. Hiroki Ishizuka ， Martine Pellerin ， Providing quantitative data with AI Mobile COLT to support the reflection process in language teaching and pre-service teacher training : a discussion,2020. https://research-publishing.net/manuscript?10.14705/rpnet.2020.48.1176．2024-11 閲覧. 8. 石塚博規, 越江 麻衣, 櫻井 靖子, 鎌田 亮祐,久保 稔，即時フィードバック可能な授業分析ツールによる外国語授業改善の試み : Mobile COLTを用いて，北海道教育大学紀要（人文科学・社会科学編）第 72 巻第 1 号，2021． 9. 砂岡和子, 徐勤.生成系 AI と初級外国語学習者の Code Switching 発話 「聴取」パフォーマンス，電子情報通信学会技術研究報告（ET2023-23）, pp.33-37, 2023. 10. 砂岡和子,王松,杉江聡子,徐勤.中国語授業のCode-Switching―包摂的メンバーシップと L2 習得最適化. 日本中国語学会第 72 回全国大会予稿集, pp. 253-257．2023． 11. 砂岡和子,譚翠玲,向凌萱(2023).Code Switching による多言語混在日本語資源と言語処理, 言語処理学会第 29 回年次大会ワークショップ１，on Zoom. 12. 飯野厚，語学授業観察法の概観―FLint, COLT, FOCUS に焦点をあてて，清泉女学院短期大学紀要，第 27 号，pp.13- 29，2009． 13. 徐勤,砂岡和子.複数言語コードを含む発話転写と話者分離：Whisper＋Pyannote.audio による自動音声認識の高度化，言語処理学会第 30 回年次大会, 2024 14. 砂冈和子,徐勤,多语码汉语教学课堂中的话者分离与文本转录 ―Whisper 和 Pyannote.audio 的应用研究,The 12th International Conference and Workshops on Technology and Chinese Language Teaching(TCLT12), 2024. http://tclt.us/tclt12/proceedings.php. 2024-12 閲覧. 15. 田崎敦子,コードスイッチング研究の概観: 多言語社会のコミュニケーション分析に向けて，言語文化と日本語教育. 増刊特集号, 第二言語習得・教育の研究最前線, p.54-84． 2006. 16. Gardner- Chloro ．Code-switching, Cambridge, UK ; New York : Cambridge University Press．2009． 17. Macaro, Ernesto ， Multilingual Matters First Language Use in Second and Foreign Language Learning, p.35-49. 2018． 18. Moskowitz，G. Interaction analysis: a new modern language for supervisors. Foreign Language Annals. 11-21. 1971．  




A  付録 

1. APP（turbo モデル）による中国語初級授業の Transcription Proportion of L1 (Japanese) usage: 57.89% Proportion of L2 (Chinese) usage: 42.11% Voice-to-text: [00:00.000 --> 00:01.920]シェは四声 [00:01.920 --> 00:04.260]後ろ軽声だからね [00:04.260 --> 00:09.100]シェって四声四声で書かないようにしてね [00:09.100 --> 00:09.360]
はい [00:09.360 --> 00:10.860]眼鏡 [00:10.860 --> 00:11.700]そう [00:11.700 --> 00:12.920]眼鏡 [00:12.920 --> 00:17.220]あの後で目が出てきますからね [00:17.220 --> 00:20.860]目と眼鏡は成長だけ違う [00:20.860 --> 00:23.920]発音一緒だから気をつけてね [00:23.920 --> 00:24.500]はい [00:24.500 --> 00:26.600]第三個比較少 [00:26.600 --> 00:27.440]じゃあ [00:27.440 --> 00:29.640]看一下第四課 Full text:  シェは四声後ろ軽声だからねシェって四声四声で書かないようにしてねはい眼鏡そう眼鏡あの後で目が出てきますからね目と眼鏡は成長だけ違う発音一緒だから気をつけてねはい第三個比較少じゃあ看一下第四課 L1 (Japanese) :  シェはろだからねシェってでかないようにしてねはいそうあのでがてきますからねとはだけうだからをつけてねはいじゃあ L2 (Chinese)
:  四声後軽声四声四声書眼鏡眼鏡後目出目眼鏡成長違発音一緒気第三個比較少看一下第四課 

 

2. APP と手動による学生プレゼンの Transcription Turbo 総字数：484 （CRE: 24.17%） 大家好、我是莎莎楊卜嗯我來介紹一下中國單身人口增加的餐品三、 三、 三、 三、 三 掃掃掃 首先、請看一下這個圖表就是這這個圖表是那個中國單身人口的推移推移 OK,推移的嗯從2022 年到 2024 年嗯如果考慮年齡能結婚還是單身的人人生是二十二歲以後嗯能結婚女性的話二十歲的人口增加了可是全單身人口也增加了嗯那您今天為什麼不結婚嗯不結婚的原因是住房長扁高嗯 那住房長扁高的原因在哪這個原因分為人口集聚職地不是職地嗯嗯國際的投資經濟的激進的三個部分嗯第一個部分是人口集聚這幾十年中國城市化進行的很快所以大量人口從農村和三線城市到一二線城市嗯比如說北京上海嗯但那個一線城市然後那現在是有很多嗯這份需求急劇增加了嗯第二個部分國度的投資中國是差別多的社會所以不用用豐富的資金來購物購買那個不懂有的人有幾個房子 所以嗯可是他們 只住在這三個房子所以他們買的盤子別的盤子是為了將來投資過後的第三個部分經濟嗯今年中國經濟有通貨緊鎖的動向可是消費值的路價 越來越多一般人們要是分錢購買自己的房子嗯就中國家福應該要做什麼呢可是我還沒 沒寫完應該要做什麼呢你覺得應該做什麼呢應該要做解決這三個問題提到一些措施嗯 好的 OK 這個時間已經到了 手動転写総字数：509 大家好我是＊＊＊＊ 嗯 我来介绍一下中国单身人口增加的三个原因三三个原因 そうそうそう 首先请看一下这个图表这是啊这这个图表表示 嗯 那个中国单身人口的 嗯 推 推移
OK推移 推移 嗯 从2022 年到 2024 年 嗯 如果考虑年龄能结婚可还是单身的人 嗯 男性是22岁以后 嗯 能结婚女性的话 20 岁 嗯 的人口增加了可是全单身人口也增加 嗯 那年轻人为什么不结婚 嗯 不结婚的原因是住房成本高 嗯 那住房成本高的原因在哪这个原因分为嗯人口集聚土地啊不是土地过度的投资 嗯 经济等经济等那个三个部分第一个部分是人口集聚 这几十年中国城市化进行得很快所以大量人口从农村和三线城市到一二线城市 嗯 比如说北京 上海 嗯 等那个一线城市 嗯 然后那些城市有很多 嗯 住房需求嗯急剧增加了 嗯 第二个部分过度的投资中国是差别多的社会 嗯 所以富裕层用丰富的资资金来购入购购买那个不 不动产有的人有几个房子 嗯 所以 嗯 可是他们只住在三这三个房子之一 嗯 所以嗯他们 嗯买的房子别的房子是 嗯 为了将来投资购物的 嗯 第三个部分经济 嗯 近年中国经济有通货紧缩的动向 嗯 可是消费者的物价越来越多一般人没有十分钱购买自己的房子 嗯 中国政府应该要做什么呢 嗯 这是我还没写完 应该要做什么呢 你觉得 应该做什么呢 应该要做解决这三个问题 的一些措施 嗯  OK 好的  OK これも時間なりましたので PPT（部分） 総字数：328 中国单身人口增加的三个原因 ＊班 ＊＊＊＊ 中国单身人口比较 ▪ 从 2022 到 2024、如果考虑年龄能结婚可还是单身的人（男性：22 岁、女性：20 岁）增加了、而全单身人口也增加了。
（後略） 注：手動転写の斜体赤字は学生プレゼンに対し、教師が相槌や応答している箇所。
匿名処理＊＊を含め補正済。