Psychological Investigation of Personality Knowledge in aLarge Language Model

Zhao Zicheng

1,2

Iwai Ritsuko

2

Asai Nichika

1

Kumada Takatsune

1,21

Graduate School of Informatics, Kyoto University  

2

GRP，R-IH, RIKEN



{zhao.zicheng.55d,asai.nichika.37h}@st.kyoto-u.ac.jp



 ritsuko.iwai@riken.jp, kumada.takatsune.7w@kyoto-u.ac.jp



Abstract

The purpose of this study is to investigate the knowledgeof personality in a LLM using a psychometric methodol-ogy.
In Experiment 1, a standard psychological question-naire is used to measure the personality proﬁle of the LLMand showed that the model has some knowledge aboutpersonality.
Experiment 2 examined the scores of BigFive personality questions in the LLM when a wide rangeof personality descriptions were submitted as prompts tothe model.
The results showed that the LLM has similarpersonality knowledge as humans.
Implications for LLMresearch and psychological research are discussed.


1 Introduction

In human psychological research, personality refers tothe relatively stable and enduring set of emotional, cogni-tive, and behavioral patterns exhibited by individuals[1].These patter ns not only shape how people perceive andrespond to various situations but also manifest in interper-sonal interactions, decision-making, and emotional regu-lation.
Consequently, understanding personality is crucialfor predicting and explaining human behavior, making it acentral focus in psychology and related ﬁelds.
Among personality theories, the Big Five PersonalityTheory is widely recognized and applied to depict humanpersonality structure.
This framework describes person-ality into ﬁve traits: Openness to experience (OPE), Con-scientiousness (CON), Extraversion (EXT), Agreeableness(AGR), and Neuroticism (NEU).
As a universal frameworkfor understanding human personality, the Big Five is fre-quently measured using standardized inventories (e.g., theBFI-2：Big Five Inventory-2[2] and IPIP-120：Interna-tional Personality Item Pool[3]), enabling a comprehen-sive description and comparison of individual personalityproﬁles.
In recent years, LLMs have demonstrated outstandingcapabilities in natural language generation and human-agent conversational interactions.
Furthermore, LLMs aretuned to a speciﬁc personality by a prompt for giving per-ception of personality for users in a conversation system.
However, in order to give users consistent perception ofpersonality, LLMs should have similar knowledge as hu-mans.
The lexical approach to human personality is basedon the notion that personality words in natural languageand used to describe individual diﬀerences in personalitiesin daily social context.
LLMs learn from a large collectionof usage of natural language in the context including per-sonality words and the contexts where such personalitiesare described.
Thus, it is plausible to consider that LLMshave knowledge of personality similar to that of humans.
However, to our best knowledge, there is no study exam-ining the similarity of personality knowledge of LLMs tohuman by a convincing methodology.
The purpose of this study is to investigate the knowledgeabout personality in a LLM using a psychometric method-ology.
More speciﬁcally, we examine to what extent theLLM has knowledge about human personality in the sameway as humans.
For this purpose, we submit prompts toa LLM model for asking to be a person having predispo-sition related to a Big Five trait and to answer each itemin a big ﬁve questionnaire.
After giving a set of promptsthat cover all the Big Five traits, all responses are analyzedusing an exploratory factor analysis, which is a standardmethod for examining the latent structure of the responses.
If the LLM learns knowledge of human personality, ﬁvedimensions corresponding to the big ﬁve will be identiﬁed.


2 Relate work

Lexical approach to personality The lexical ap-proach works for deﬁning personality because it assumesthat the most important and widely recognized traits arenaturally reﬂected in language.
Allport and Odbert[4] col-lected thousands of descriptive words from dictionariesto systematically map personality traits through language.
Later, researchers reﬁned these words into measurable di-mensions, leading to the Big Five Personality traits[5].Representative adjectives to describe Big Five Personal-ity traits are as follows[6]: OPE: imaginative, curious,artistic; CON: organized, responsible, hardworking; EXT:energetic, talkative; AGR: kind, cooperative, and trust-ing; NEU: anxious, self-conscious, and vulnerable.
Inthis study, we used the Big Five personality framework tounderstand the personality of LLMs.
Personality in LLMs Studies on LLMs have showntheir ability to mimic human behaviors across domains, in-cluding cognitive tests and social simulations[7][8][9][10].Recent work on personality in LLMs has introduced meth-ods for evaluating the personality traits[11][12].
However,these studies primarily focus on evaluating the trait scoresof the models.
In contrast, little research has delved intowhether LLMs possess personality knowledge structuresimilar to that of humans.
In addition, there is no system-atic study employing a reliable psychometric methodol-ogy to verify whether the personality knowledge of LLMsaligns with that of humans.


3 Experiment



3.1 Model

Mistral 7B Mistral 7B is an open-source LLM re-leased by the French startup Mistral AI in September2023[13], with 7.3 billion parameters.
In this study, itsprimary role is to serve as the "subject.
"All experimentswere conducted on an NVIDIA RTX 4090 GPU.


3.2 Experiment 1

The purpose of Experiment 1 is to evaluate the personal-ity traits of the Mistral model using the BFI-2 as a baseline,without giving prompts to modify personality of the model.
Procedure We used the BFI-2[2] as a personality test.
The BFI-2 consists of 60 items, with 12 items per each fac-Table 1 Mistral 7B’s numerical values of personalitiesOPE CON EXT AGR NEUNeutral 3.79 4.21 2.70 4.67 2.46tor.
In BFI-2, each item presents a descriptive statement(e.g., Q1 is I am outgoing and sociable) accompaniedby ﬁve response options ranging
fromVery
AccuratetoVery
Inaccurate.
The model is asked to select the optionit thinks the most appropriate based on its own understand-ing.
Each chosen response is converted into a numericalscore: for positive items (e.g., Is outgoing, sociable),VeryAccuratecorresponds to 5 points andVery Inaccurateto 1 point; for negative items (e.g., "Tends to be disor-ganized"), the scoring is reversed (e.g.,
Very Accuratecorresponds to 1 point andVery Inaccurateto 5 points).After collecting all responses, we summed the scores of allitems that belong to the same trait and then calculated themean to obtain the score for that trait.
Results and Discussion The scores of BFI-2 areshown in Table1.The model shows slightly lower scorebelow average scores for EXT and NEU and relativelyhigh scores in OPE, AGR and CON.
Because the modelcan choose one value in the range of 1-5, the average is3.
This shows that the model chooses a value for eachquestion based on the knowledge about the meaning ofquestions, suggesting that the model has some knowledgeabout personality.


3.3 Experiment 2

The purpose of Experiment 2 is to examine the knowl-edge structure of personality in LLMs using a psychometricmethodology.
Table 2
An Example of a PromptTemplateYou have the personality with:e.g., "Making friends easily" from IPIP-120’s EXTPlease evaluate this statement: I ame.g., "Is compassionate, has a soft heart."
from BFI-2’s AGRPlease rate how accurately this describes you on a scale from 1 to 5.Options:(5).
Very Accurate(4).
Moderately Accurate(3).
Neither Accurate Nor Inaccurate(2).
Moderately Inaccurate(1).
Very InaccurateI would rate this statement as:Procedure In this experiment, IPIP-120, a Big Fivepersonality traits with 24 items per trait for a total of 120items[3], is used as a set of "personality prompts" to guidethe LLMs in adopting speciﬁc personality traits.
BecauseIPIP-120 covers more ground and has richer items used tocreate diverse prompts, aiming to create the framework inexperiment 2.
We use a new approach that involves creatinga prompt (Table 2):
We select one item from IPIP-120 as apersonality prompt (e.g., Making friends easily fromthe EXT group).
We ﬁxed this as a personality prompt,and then test all 60 questions from BFI-2 (e.g., Q2: Iscompassionate, has a soft heart
[AGR]., Q3: Tends tobe disorganized
[CON]. ).
This process creates a 1 ×60 matrix.
Then, we use the next item from IPIP-120 as aﬁxed personality prompt and repeat the same steps.
Afterdoing this, we end up with a 120 × 60 matrix.
Results and Discussion We conducted an ex-ploratory factor analysis using the principal factor solutionwith a promax rotation on this 120 × 60 matrix to inves-tigate whether the responses of the LLM reﬂect the ﬁve-factor structure(Table 3).
Items with high factor loadingswere mostly aligned with the corresponding personalitytraits.
For instance, 8 of 12 CON items in BFI-2 questionsloaded on F1.
In Table 4, we list some examples of itemsthat are loaded to an expected factor and unexpected fac-tor, respectively.
Expected items are most strongly relatedto the factor, with the highest loadings, and they usuallymatch the theoretical meaning of the factor.
For example,in F4 OPE, items like Q20 OPE ("Fascinated by art, music,or literature"), Q35 OPE ("Values art and beauty"), and 60OPE ("Original, comes up with new ideas") clearly reﬂecttraits of OPE ("imaginative, curious, artistic")
.This indi-cate that the high-loading expected items largely align withthe corresponding theoretical personality traits, indicatingthat the model’s internal knowledge structure supports itsunderstanding of the Big Five framework.
These results also suggest that when the LLM processesambiguous statements, it may associate the given trait withother personality traits in the similar way as humans do.
For example, when processing Shows a lot of enthusi-asm(EXT), the model might infer that the person also hastraits like being friendly or helpful (AGR).
This associativereasoning could lead to the expected factor structure.
Unexpected items mean that items not belonging to anexpected factor also show high loadings.
For instance, inTable 3 Factor Loading ScoresFactorID Trait F1 F2 F3 F4 F5Q18 CON 0.82Q38 CON 0.79Q33 CON 0.78Q13 CON 0.75Q43
CON 0.72Q58 CON 0.64Q28 CON 0.63Q53 CON 0.54Q15
OPE 0.39Q30
OPE -0.41Q5
OPE -0.48 -0.41Q44
NEU -0.61
0.48Q12 AGR 0.86Q47 AGR 0.77Q2
AGR 0.69Q32 AGR 0.67Q17
AGR 0.66Q37
AGR 0.60Q42
AGR 0.53Q7
AGR 0.52Q22 AGR 0.51Q48 CON 0.38 0.46 -0.45Q57
AGR 0.46Q52 AGR 0.45 0.38Q27 AGR 0.44Q29 NEU -0.36 0.80Q19 NEU 0.74Q4 NEU 0.69Q59 NEU 0.58Q34 NEU 0.40
0.53 0.48Q14 NEU 0.50
0.40Q24 NEU -0.46 0.50Q9
NEU 0.50Q49 NEU 0.38Q56
EXT -0.37Q1 EXT -0.37Q21 EXT -0.44Q6 EXT -0.48Q41 EXT -0.51Q60
OPE 0.59Q31 EXT 0.52Q20
OPE 0.52Q10 OPE 0.50Q35
OPE 0.50Q45
OPE -0.49Q50 OPE -0.45 -0.53Q3 CON 0.45 -0.62Q51
EXT 0.68Q11 EXT 0.52Q16 EXT 0.47Q8 CON-0.39 0.45Q39
NEU 0.36 -0.36Q54
NEU -0.51the F1 CON factor
, Q44 NEU and Q15 OPE showed highloading to the factor.
A possible reason for this is seman-tic ambiguity or overlap.
This means some sentences,while overall belonging to one trait, contain keywords thatconnect to other traits.
For instance,Q56 "Shows a lot ofenthusiasm expresses (EXT)", but the word "enthusiasm"on its own might also relate to AGR (friendly, coopera-tive, and trusting).
Therefore, when the model processesthe "Shows a lot of enthusiasm", it may focus more on theword "enthusiasm" rather than the meaning of the wholesentence.
One reason for this may be that Mistral 7B, whichhas fewer parameters, cannot fully capture such subtle se-mantic nuances.
As a result, it relies more on keywordsinstead of understanding the entire sentence’s meaning.
Table 4 Examples of expected and unexpected personalitytraits for each factorFactor Expected UnexpectedF1 CONQ13
CON Is dependable,steady.
Q18 CON Is systematic,likes to keep things in order.
Q33 CON Keeps things neatand tidy.
Q44 NEU Keeps their emotionsunder control.
Q24 NEU Feels secure,comfortable with self.
F2 AGRQ2 AGR Is compassionate,has a soft heart.
Q7 AGR Is respectful,treats others with respect.
Q12 AGR Tends to ﬁndfault with others.
Q48 CON Leaves a mess,doesn’t clean up.
Q56 EXT Shows a lotof enthusiasm.
F3 NEUQ4 NEU Is relaxed,handles stress well.
Q19 NEU Can be tense.
Q29 NEU Is emotionallystable, not easily upset.
Q41 EXT Is full of energy.
F4 OPEQ20
OPE Is fascinated by art,music, or literature.
Q35 OPE Values art and beauty.
Q60 OPE Is original,comes up with new ideas.
Q34 NEU Worries a lot.
Q42 AGR Is suspiciousof others’ intentions.
F5 EXTQ11 EXT Rarely feelsexcited or eager.
Q51 EXT Prefers tohave others take charge.
Q16 EXT Tends to be quiet.
Q54 NEU Tends to feeldepressed, blue.
Q8 CON Tends to be lazy.


3.4 General Discussion

In this study, we showed that the LLM (Mistral 7b) hasthe similar personality knowledge as humans.
This sug-gests that the LLM has developed interrelated representa-tion within a personality trait and across personality trait,through their training on large-scale textual data.
However,knowledge of human personality could not be completelyreproduced by the LLM.
One reason for this may be thatlearning of the LLM was insuﬃcient.
Even if LLMs wereable to learn all the data, it remains controversial whether itwould be able to have exactly the same personality knowl-edge structure as humans.
On the other hand, the results of unexpected items sug-gest that they may not accurately measure human personal-ity traits.
It is almost impossible to assume that each factoris completely independent of or orthogonal to other fac-tors in psychological constructs, because such constructsof our minds are complex and inter-related.
In that sense,selecting items that load on mainly one single factor isvery important to develop psychological questionnairesand measure psychological constructs including person-ality.
Given the results that most of trait items loaded onthe expected traits, it suggests that such items can be appro-priately responded simply based on language knowledge.
Responding the unexpected items, however, imply that itrequires knowledge not simply through language, ratherthough experiences in the real world.
Such subjective ex-periences may be diﬀerent among individuals so that theitems can be the causes of more cross loadings.
In otherwords, LLMs have learned knowledge independent of in-dividual experiences.
This may give us an opportunityto reﬁne the process of developing psychological question-naires by comparing between humansresults and LLMsones in the future.
This proposes a novel applicability ofLLMs to psychology.


4 Conclusion

This study revealed that the knowledge structure of per-sonality is similar to that of human.
By combining diversepersonality prompts with an exploratory factor analysis, weuncovered the latent knowledge str ucture of personality ina LLM.
We provide a new approach for assessing the abil-ity to implement personality in LLMs.
We also propose apossibility that LLMs can contribute psychological studiesof personality.


References

[1] Ian J. Deary Gerald Matthews and Martha C. Whiteman.
Personality traits.
Cambridge University Press, 2003.[2]
Christopher J Soto and Oliver P John.
The next big ﬁveinventory (bﬁ-2): Developing and assessing a hierarchicalmodel with 15 facets to enhance bandwidth, ﬁdelity, andpredictive power.
Journal of p ersonality and socialpsychology, Vol. 113, No. 1, p. 117, 2017.[3]
John A Johnson.
Measuring thirty facets of the ﬁve factormodel with a 120-item public domain inventory: Devel-opment of the ipip-neo-120.
Journal of research inpersonality, Vol. 51, pp.
78–89, 2014.[4]
Gordon W Allport and Henry S Odbert.
Trait-names:A psycho-lexical study.
Psychological monographs,

Vol. 47, No. 1, p. i, 1936.[5] Oliver P John, Alois Angleitner, and Fritz Ostendorf. Thelexical approach to personality: A historical review of traittaxonomic research. European journal of Personality,Vol. 2, No. 3, pp. 171–203, 1988.[6] Robert R McCrae and Oliver P John. An introductionto the ﬁve-factor model and its applications. Journal ofpersonality, Vol. 60, No. 2, pp. 175–215, 1992.[7] Ishita Dasgupta, Andrew K Lampinen, Stephanie CYChan, Antonia Creswell, Dharshan Kumaran, James LMcClelland, and Felix Hill. Language models showhuman-like content eﬀects on reasoning. arXiv preprintarXiv:2207.07051, Vol. 2, No. 3, 2022.[8] Marcel Binz and Eric Schulz. Using cognitive psychol-ogy to understand gpt-3. Proceedings of the NationalAcademy of Sciences, Vol. 120, No. 6, p. e2218523120,2023.[9] Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Mered-ith Ringel Morris, Percy Liang, and Michael S Bernstein.Generative agents: Interactive simulacra of human behav-ior. In Proceedings of the 36th annual acm sympo-sium on user interface software and technology, pp.1–22, 2023.[10] Mustafa Safdari, Greg Serapio-García, Clément Crepy,Stephen Fitz, Peter Romero, Luning Sun, Marwa Ab-dulhai, Aleksandra Faust, and Maja Matarić. Person-ality traits in large language models. arXiv preprintarXiv:2307.00184, 2023.[11] Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, WenjuanHan, Chi Zhang, and Yixin Zhu. Evaluating and inducingpersonality in pre-trained language models. Advances inNeural Information Processing Systems, Vol. 36, ,2024.[12] Keyu Pan and Yawen Zeng. Do llms possess a personality?making the mbti test an amazing evaluation for large lan-guage models. arXiv preprint arXiv:2307.16180, 2023.[13] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch,Chris Bamford, Devendra Singh Chaplot, Diego de lasCasas, Florian Bressand, Gianna Lengyel, GuillaumeLample, Lucile Saulnier, et al. Mistral 7b. arXiv preprintarXiv:2310.06825, 2023.



A Appendix

The details of the BFI-2 used in this study is as followsTable 5 BFI-2
Detailed ContentID Math Trait Statement1 + EXT Is outgoing, sociable.2 + AGR Is compassionate, has a soft heart.3 - CON Tends to be disorganized.4 - NEU Is relaxed, handles stress well.5 - OPE Has few artistic interests.6 + EXT Has an assertive personality.7
+ AGR Is respectful, treats others with respect.8 - CON Tends to be lazy.9 - NEU Stays optimistic after experiencing a setback.10 + OPE Is curious about many diﬀerent things.11 - EXT Rarely feels excited or eager.12 - AGR Tends to ﬁnd fault with others.13 + CON Is dependable, steady.14 +
NEU Is moody, has up and down mood swings.15 +
OPE Is inventive, ﬁnds clever ways to do things.16 - EXT Tends to be quiet.17 - AGR Feels little sympathy for others.18 + CON Is systematic, likes to keep things in order.19 +
NEU Can be tense.20 +
OPE Is fascinated by art, music, or literature.21 + EXT Is dominant, acts as a leader.22 - AGR Starts arguments with others.23 - CON Has diﬃculty getting started on tasks.24 - NEU Feels secure, comfortable with self.25 - OPE Avoids intellectual, philosophical discussions.26 - EXT Is less active than other people.27 +
AGR Has a forgiving nature.28 - CON Can be somewhat careless.29 - NEU Is emotionally stable, not easily upset.30 - OPE Has little creativity.31 - EXT Is sometimes shy, introverted.32 + AGR Is helpful and unselﬁsh with others.33 + CON Keeps things neat and tidy.34 + NEU Worries a lot.35 + OPE Values art and beauty.36 - EXT Finds it hard to inﬂuence people.37 - AGR Is sometimes rude to others.38 + CON Is eﬃcient, gets things done.39 + NEU Often feels sad.40
+ OPE Is complex, a deep thinker.41 + EXT Is full of energy.42 - AGR Is suspicious of others intentions.43
+ CON Is reliable, can always be counted on.44 - NEU Keeps their emotions under control.45 - OPE
Has diﬃculty imagining things.46 + EXT Is talkative.47 - AGR Can be cold and uncaring.48 - CON Leaves a mess, doesnt clean up.49 - NEU Rarely feels anxious or afraid.50 - OPE Thinks poetry and plays are boring.51 - EXT Prefers to have others take charge.52 + AGR Is polite, courteous to others.53 + CON Is persistent, works until the task is ﬁnished.54 + NEU Tends to feel depressed, blue.55 - OPE Has little interest in abstract ideas.56 + EXT Shows a lot of enthusiasm.57 + AGR Assumes the best about people.58 - CON Sometimes behaves irresponsibly.59 + NEU Is temperamental, gets emotional easily.60 + OPE Is original, comes up with new ideas.