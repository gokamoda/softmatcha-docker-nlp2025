Dispersion Measures as Predictors of Lexical Decision Time,Word Familiarity, and Lexical Complexity

Adam Nohejl Taro Watanabe



Nara Institute of Science and Technology



{nohejl.adam.mt3, taro}@is.naist.jp



Abstract

Various measures of dispersion have been proposed topaint a fuller picture of a word’s distribution in a corpus,but only little has been done to validate them externally.
Weevaluate a wide range of dispersion measures as predictorsof lexical decision time, word familiarity, and lexical com-plexity in ﬁve diverse languages.
We ﬁnd that the logarithmof range is not only a better predictor than log-frequencyacross all tasks and languages, but that it is also the mostpowerful additional variable to log-frequency, consistentlyoutperforming the more complex dispersion measures.
Wediscuss the eﬀects of corpus part granularity and logarith-mic transformation, shedding light on contradictory resultsof previous studies.


1 Introduction

Measures of dispersion have been proposed in corpuslinguistics to complement frequency, a measure of centraltendency.
While a word’s frequency tells us how commonthe word is in the whole corpus, its dispersion tells us howevenly it is spread.
For instance, the words very and yeah,or came and data may have similar overall frequencies, butyeah and data would likely have lower dispersions, as theyare speciﬁc to a certain register or domain.
The conceptually simplest dispersion measure is therange: the number of corpus parts in which a word occurs.
The parts may be of diﬀerent granularity and function,e.g. individual texts, authors, domains, or registers.
In theTUBELEX corpus [1], which is based on YouTube videos,our example words have the following frequencies (in thou-sands of occurrences) and ranges (in thousands of YouTubechannels): very: 332 and 35; yeah:
333 and 19; came: 64and 17; data: 64 and 7, conﬁrming our expectations.
The number of texts in which a word appears was usedto organize pedagogical word lists as early as in 1920by Keniston
[2] and mentioned as “range” by Thorndike(2021)[3].
Gries (2008)[4] lists thirteen more advanceddispersion measures that have been proposed over thedecades, often theoretically motivated or considering in-tuitive interpretability.
What is critically missing, as Gries[4] also argues, is external validation.
We aim to bridge this gap between theoretical corpus dis-persion research, psycholinguistics, and NLP applications,with a comprehensive evaluation of dispersion measureson ﬁve languages, three tasks, and three levels of corpuspart granularity.
Two of the tasks predict psycholinguisticdata, lexical decision time (LDT) and word familiarity, andone is an NLP task, lexical complexity prediction.


2 Related Research

Adelman et al.
(2006)[5] evaluated log-range on Englishword naming and LDT, concluding that log-range1）is abetter predictor than log-frequency.
Brysbaert and New (2009)[8] replicated the results ofAdelman et al.
on the SUBTLEX-US subtitle corpus.
Mostlater studies on ﬁlm subtitles reached similar conclusions[9, 10, 11, 12, 13], but a few of them did not ﬁnd a statisticalsigniﬁcant diﬀerence on individual datasets [14, 15, 16].All of these studies investigated only log-range across sub-title ﬁles (typically thousands of ﬁles corresponding toﬁlms or show episodes) as a dispersion measure, and eval-uated it on LDT or word naming times, essentially repli-cating Brysbaert and New’s study [8] on other languages.
Gries (2010)[17] evaluated multiple dispersion mea-sures on English word naming and LDT data.
The studydid not reach a conclusive result on the two datasets.
Gries (2021)[18] experimented with log-frequency,1）
Adelman et al. call range “contextual diversity”, avoiding theterms “dispersion” and “range”, which is arguably confusing [6, 7],but does not detract anything from the practical value of their study.

Dispersion Measures as Predictors of Lexical Decision Time,Word Familiarity, and Lexical Complexity

Adam Nohejl Taro Watanabe



Nara Institute of Science and Technology



{nohejl.adam.mt3, taro}@is.naist.jp



Abstract

Various measures of dispersion have been proposed topaint a fuller picture of a word’s distribution in a corpus,but only little has been done to validate them externally.
Weevaluate a wide range of dispersion measures as predictorsof lexical decision time, word familiarity, and lexical com-plexity in ﬁve diverse languages.
We ﬁnd that the logarithmof range is not only a better predictor than log-frequencyacross all tasks and languages, but that it is also the mostpowerful additional variable to log-frequency, consistentlyoutperforming the more complex dispersion measures.
Wediscuss the eﬀects of corpus part granularity and logarith-mic transformation, shedding light on contradictory resultsof previous studies.


1 Introduction

Measures of dispersion have been proposed in corpuslinguistics to complement frequency, a measure of centraltendency.
While a word’s frequency tells us how commonthe word is in the whole corpus, its dispersion tells us howevenly it is spread.
For instance, the words very and yeah,or came and data may have similar overall frequencies, butyeah and data would likely have lower dispersions, as theyare speciﬁc to a certain register or domain.
The conceptually simplest dispersion measure is therange: the number of corpus parts in which a word occurs.
The parts may be of diﬀerent granularity and function,e.g. individual texts, authors, domains, or registers.
In theTUBELEX corpus [1], which is based on YouTube videos,our example words have the following frequencies (in thou-sands of occurrences) and ranges (in thousands of YouTubechannels): very: 332 and 35; yeah:
333 and 19; came: 64and 17; data: 64 and 7, conﬁrming our expectations.
The number of texts in which a word appears was usedto organize pedagogical word lists as early as in 1920by Keniston
[2] and mentioned as “range” by Thorndike(2021)[3].
Gries (2008)[4] lists thirteen more advanceddispersion measures that have been proposed over thedecades, often theoretically motivated or considering in-tuitive interpretability.
What is critically missing, as Gries[4] also argues, is external validation.
We aim to bridge this gap between theoretical corpus dis-persion research, psycholinguistics, and NLP applications,with a comprehensive evaluation of dispersion measureson ﬁve languages, three tasks, and three levels of corpuspart granularity.
Two of the tasks predict psycholinguisticdata, lexical decision time (LDT) and word familiarity, andone is an NLP task, lexical complexity prediction.


2 Related Research

Adelman et al.
(2006)[5] evaluated log-range on Englishword naming and LDT, concluding that log-range1）is abetter predictor than log-frequency.
Brysbaert and New (2009)[8] replicated the results ofAdelman et al.
on the SUBTLEX-US subtitle corpus.
Mostlater studies on ﬁlm subtitles reached similar conclusions[9, 10, 11, 12, 13], but a few of them did not ﬁnd a statisticalsigniﬁcant diﬀerence on individual datasets [14, 15, 16].All of these studies investigated only log-range across sub-title ﬁles (typically thousands of ﬁles corresponding toﬁlms or show episodes) as a dispersion measure, and eval-uated it on LDT or word naming times, essentially repli-cating Brysbaert and New’s study [8] on other languages.
Gries (2010)[17] evaluated multiple dispersion mea-sures on English word naming and LDT data.
The studydid not reach a conclusive result on the two datasets.
Gries (2021)[18] experimented with log-frequency,1）
Adelman et al. call range “contextual diversity”, avoiding theterms “dispersion” and “range”, which is arguably confusing [6, 7],but does not detract anything from the practical value of their study.word length, and multiple dispersion measures as featuresfor a random forest model of English auditory LDT.


3 Examined Measures

As we have noted, both frequency and range are com-monly log-transformed to achieve better correlation withpsycholinguistic variables.
Since our evaluation will in-clude words not present in the corpus, which would resultin undeﬁned values (log 0), we take the following steps toexamine the log-transformation of all examined measuresand frequency: Using 𝑛 = number of corpus parts, we applysmoothing in the form (𝑑𝑛 + 1)/(𝑛 + 1) to each dispersionmeasure 𝑑 if we log-transform it.
Therefore, with a slightabuse of notation, we always use “log 𝑑” in the followingtext to refer to log((𝑑𝑛 +1)/(𝑛
+ 1)).
For (log-)frequency,we always use Laplace-smoothed frequency [19].We use all measures in forms appropriate for unequallysized corpus parts and normalized to the range
[0, 1],adapting Gini index and Gries’s DP to 𝑑 = 1 − 𝑑∗fromtheir original formulas 𝑑∗, so that high values indicate highdispersion.
We use the following variables, given a word𝑤: 𝑛 is the number of corpus parts; 𝑣𝑖is the number ofoccurrences of 𝑤 in part 𝑖; 𝑘𝑖is the number of tokens inpart 𝑖; 𝑠𝑖= 𝑘𝑖/Ík is the proportion of part 𝑖; 𝑟𝑖= 𝑣𝑖/Ívis the proportion of occurrences of 𝑤 in part 𝑖; 𝑝𝑖= 𝑣𝑖/𝑘𝑖is the relative frequency of 𝑤 in part 𝑖, i.e. frequency nor-malized per part; 𝑞𝑖= 𝑝𝑖/Íp is the frequency normalizedper part and per word.
For each variable 𝑥𝑖indexed bycorpus part, we understand x
= (𝑥𝑖)𝑛𝑖=1as the correspond-ing vector with sumÍx =Í𝑛𝑖=1𝑥𝑖, mean 𝜇x=Íx/𝑛, andstandard deviation 𝜎x=pÍ𝑛𝑖=1(𝑥𝑖− 𝜇x)2/𝑛.We examine the following dispersion measures:Range 𝑅 =Í𝑛𝑖=1[𝑣𝑖> 0]𝑛(1)Gini index 𝐺 = 1 −Í𝑛𝑖=1Í𝑛𝑗=1𝑞𝑖− 𝑞𝑗2𝑛(2)Juilland’s [20] 𝐷 = 1 −𝜎p𝜇p√𝑛 − 1(3)Lyne’s
[21] 𝐷3= 1 −Í𝑛𝑖=1(𝑟𝑖− 𝑠𝑖)24(4)Gries’s [4] DP = 1 −Í𝑛𝑖=1|𝑟𝑖− 𝑠𝑖|2(5)Rosengren’s
[22] 𝑆 =Í𝑛𝑖=1√𝑞𝑖2𝑛(6)Carroll’s
[23] 𝐷2=−Í𝑛𝑖=1𝑞𝑖log 𝑞𝑖log 𝑛(7)Regardless of the formulas above, we deﬁne each mea-sure as 0 for words missing from the corpus.2）Gini index is the discrete variant of the well-know in-dex of inequality.
It was proposed as a dispersion mea-sure independently by Murayama et al.
(2018)[24](asWord GINI = −log 𝐺) and Burch et al.
(2017)[25](as𝐷𝐴, later adjusted to unequally sized parts, with a slightlydiﬀerent normalization from our 𝐺
[26]).
We investigate𝐺 and log 𝐺 using the formula given by Glasser (1962)[27], which reduces computation time to 𝑂 (𝑛 log 𝑛).3）As far as we can tell, “distributional consistency” pro-posed by Zhang et al.
(2004)[28], is simply equal to Rosen-gren’s 𝑆 (6).4）Finally, we observe that inverse document frequency(idf) and variation coeﬃcient (vc) can be expressed as lin-ear functions of log-range (1) and Juilland’s D (3), respec-tively, and therefore do not need to be examined separatelyin terms of linear correlation:idf = log1𝑅𝑠 = −log 𝑅 (8)vc =𝜎p𝜇p=√𝑛 − 1 (1 − 𝐷)(9)

4 Evaluation

We evaluate the measures on TUBELEX [1], a largeYouTube subtitle corpus for English, Chinese, Spanish, In-donesian, and Japanese.
Word frequency in TUBELEXwas already demonstrated to achieve correlation with psy-cholinguistic variables on par with or superior to ﬁlm sub-title corpora
[1].
TUBELEX also provides three levelsof linguistically valid corpus parts: videos, channels, andcategories (tens of thousands, thousands, and 15 parts re-spectively).
We use TUBELEX in its default tokenization.
For evaluation, we use the same datasets for LDT (3 lan-guages), word familiarity (5 languages), and lexical com-plexity (3 languages) as were used for extrinsic evaluationof TUBELEX log-frequency by Nohejl et al.
(2024)[1].Word familiarity and lexical complexity diﬀer from thecommonly employed LDT or word naming tasks by being2）
This is in line with the formulas for range, 𝑆, and 𝐷2, whichwould give 0 for a zero frequency word.
𝐷, 𝐷3, and DP would beundeﬁned, and Gini index would be 1.3）
We also use sparse arrays to represent q, resulting in 𝑂(𝑚 log 𝑚)time, where 𝑚 is the number of non-zero elements of q.
The sparse-ness of frequency vectors q grows with the number of corpus parts,keeping computation time reasonable.4） This seems to have escaped the attention of Zhang et al.
[28] andGries.
Gries only noted that it gives the same numerical result in anexample scenario [4] and appears similar in cluster analysis [17].

Dispersion Measures as Predictors of Lexical Decision Time,Word Familiarity, and Lexical Complexity

Adam Nohejl Taro Watanabe



Nara Institute of Science and Technology



{nohejl.adam.mt3, taro}@is.naist.jp



Abstract

Various measures of dispersion have been proposed topaint a fuller picture of a word’s distribution in a corpus,but only little has been done to validate them externally.
Weevaluate a wide range of dispersion measures as predictorsof lexical decision time, word familiarity, and lexical com-plexity in ﬁve diverse languages.
We ﬁnd that the logarithmof range is not only a better predictor than log-frequencyacross all tasks and languages, but that it is also the mostpowerful additional variable to log-frequency, consistentlyoutperforming the more complex dispersion measures.
Wediscuss the eﬀects of corpus part granularity and logarith-mic transformation, shedding light on contradictory resultsof previous studies.


1 Introduction

Measures of dispersion have been proposed in corpuslinguistics to complement frequency, a measure of centraltendency.
While a word’s frequency tells us how commonthe word is in the whole corpus, its dispersion tells us howevenly it is spread.
For instance, the words very and yeah,or came and data may have similar overall frequencies, butyeah and data would likely have lower dispersions, as theyare speciﬁc to a certain register or domain.
The conceptually simplest dispersion measure is therange: the number of corpus parts in which a word occurs.
The parts may be of diﬀerent granularity and function,e.g. individual texts, authors, domains, or registers.
In theTUBELEX corpus [1], which is based on YouTube videos,our example words have the following frequencies (in thou-sands of occurrences) and ranges (in thousands of YouTubechannels): very: 332 and 35; yeah:
333 and 19; came: 64and 17; data: 64 and 7, conﬁrming our expectations.
The number of texts in which a word appears was usedto organize pedagogical word lists as early as in 1920by Keniston
[2] and mentioned as “range” by Thorndike(2021)[3].
Gries (2008)[4] lists thirteen more advanceddispersion measures that have been proposed over thedecades, often theoretically motivated or considering in-tuitive interpretability.
What is critically missing, as Gries[4] also argues, is external validation.
We aim to bridge this gap between theoretical corpus dis-persion research, psycholinguistics, and NLP applications,with a comprehensive evaluation of dispersion measureson ﬁve languages, three tasks, and three levels of corpuspart granularity.
Two of the tasks predict psycholinguisticdata, lexical decision time (LDT) and word familiarity, andone is an NLP task, lexical complexity prediction.


2 Related Research

Adelman et al.
(2006)[5] evaluated log-range on Englishword naming and LDT, concluding that log-range1）is abetter predictor than log-frequency.
Brysbaert and New (2009)[8] replicated the results ofAdelman et al.
on the SUBTLEX-US subtitle corpus.
Mostlater studies on ﬁlm subtitles reached similar conclusions[9, 10, 11, 12, 13], but a few of them did not ﬁnd a statisticalsigniﬁcant diﬀerence on individual datasets [14, 15, 16].All of these studies investigated only log-range across sub-title ﬁles (typically thousands of ﬁles corresponding toﬁlms or show episodes) as a dispersion measure, and eval-uated it on LDT or word naming times, essentially repli-cating Brysbaert and New’s study [8] on other languages.
Gries (2010)[17] evaluated multiple dispersion mea-sures on English word naming and LDT data.
The studydid not reach a conclusive result on the two datasets.
Gries (2021)[18] experimented with log-frequency,1）
Adelman et al. call range “contextual diversity”, avoiding theterms “dispersion” and “range”, which is arguably confusing [6, 7],but does not detract anything from the practical value of their study.word length, and multiple dispersion measures as featuresfor a random forest model of English auditory LDT.


3 Examined Measures

As we have noted, both frequency and range are com-monly log-transformed to achieve better correlation withpsycholinguistic variables.
Since our evaluation will in-clude words not present in the corpus, which would resultin undeﬁned values (log 0), we take the following steps toexamine the log-transformation of all examined measuresand frequency: Using 𝑛 = number of corpus parts, we applysmoothing in the form (𝑑𝑛 + 1)/(𝑛 + 1) to each dispersionmeasure 𝑑 if we log-transform it.
Therefore, with a slightabuse of notation, we always use “log 𝑑” in the followingtext to refer to log((𝑑𝑛 +1)/(𝑛
+ 1)).
For (log-)frequency,we always use Laplace-smoothed frequency [19].We use all measures in forms appropriate for unequallysized corpus parts and normalized to the range
[0, 1],adapting Gini index and Gries’s DP to 𝑑 = 1 − 𝑑∗fromtheir original formulas 𝑑∗, so that high values indicate highdispersion.
We use the following variables, given a word𝑤: 𝑛 is the number of corpus parts; 𝑣𝑖is the number ofoccurrences of 𝑤 in part 𝑖; 𝑘𝑖is the number of tokens inpart 𝑖; 𝑠𝑖= 𝑘𝑖/Ík is the proportion of part 𝑖; 𝑟𝑖= 𝑣𝑖/Ívis the proportion of occurrences of 𝑤 in part 𝑖; 𝑝𝑖= 𝑣𝑖/𝑘𝑖is the relative frequency of 𝑤 in part 𝑖, i.e. frequency nor-malized per part; 𝑞𝑖= 𝑝𝑖/Íp is the frequency normalizedper part and per word.
For each variable 𝑥𝑖indexed bycorpus part, we understand x
= (𝑥𝑖)𝑛𝑖=1as the correspond-ing vector with sumÍx =Í𝑛𝑖=1𝑥𝑖, mean 𝜇x=Íx/𝑛, andstandard deviation 𝜎x=pÍ𝑛𝑖=1(𝑥𝑖− 𝜇x)2/𝑛.We examine the following dispersion measures:Range 𝑅 =Í𝑛𝑖=1[𝑣𝑖> 0]𝑛(1)Gini index 𝐺 = 1 −Í𝑛𝑖=1Í𝑛𝑗=1𝑞𝑖− 𝑞𝑗2𝑛(2)Juilland’s [20] 𝐷 = 1 −𝜎p𝜇p√𝑛 − 1(3)Lyne’s
[21] 𝐷3= 1 −Í𝑛𝑖=1(𝑟𝑖− 𝑠𝑖)24(4)Gries’s [4] DP = 1 −Í𝑛𝑖=1|𝑟𝑖− 𝑠𝑖|2(5)Rosengren’s
[22] 𝑆 =Í𝑛𝑖=1√𝑞𝑖2𝑛(6)Carroll’s
[23] 𝐷2=−Í𝑛𝑖=1𝑞𝑖log 𝑞𝑖log 𝑛(7)Regardless of the formulas above, we deﬁne each mea-sure as 0 for words missing from the corpus.2）Gini index is the discrete variant of the well-know in-dex of inequality.
It was proposed as a dispersion mea-sure independently by Murayama et al.
(2018)[24](asWord GINI = −log 𝐺) and Burch et al.
(2017)[25](as𝐷𝐴, later adjusted to unequally sized parts, with a slightlydiﬀerent normalization from our 𝐺
[26]).
We investigate𝐺 and log 𝐺 using the formula given by Glasser (1962)[27], which reduces computation time to 𝑂 (𝑛 log 𝑛).3）As far as we can tell, “distributional consistency” pro-posed by Zhang et al.
(2004)[28], is simply equal to Rosen-gren’s 𝑆 (6).4）Finally, we observe that inverse document frequency(idf) and variation coeﬃcient (vc) can be expressed as lin-ear functions of log-range (1) and Juilland’s D (3), respec-tively, and therefore do not need to be examined separatelyin terms of linear correlation:idf = log1𝑅𝑠 = −log 𝑅 (8)vc =𝜎p𝜇p=√𝑛 − 1 (1 − 𝐷)(9)

4 Evaluation

We evaluate the measures on TUBELEX [1], a largeYouTube subtitle corpus for English, Chinese, Spanish, In-donesian, and Japanese.
Word frequency in TUBELEXwas already demonstrated to achieve correlation with psy-cholinguistic variables on par with or superior to ﬁlm sub-title corpora
[1].
TUBELEX also provides three levelsof linguistically valid corpus parts: videos, channels, andcategories (tens of thousands, thousands, and 15 parts re-spectively).
We use TUBELEX in its default tokenization.
For evaluation, we use the same datasets for LDT (3 lan-guages), word familiarity (5 languages), and lexical com-plexity (3 languages) as were used for extrinsic evaluationof TUBELEX log-frequency by Nohejl et al.
(2024)[1].Word familiarity and lexical complexity diﬀer from thecommonly employed LDT or word naming tasks by being2）
This is in line with the formulas for range, 𝑆, and 𝐷2, whichwould give 0 for a zero frequency word.
𝐷, 𝐷3, and DP would beundeﬁned, and Gini index would be 1.3）
We also use sparse arrays to represent q, resulting in 𝑂(𝑚 log 𝑚)time, where 𝑚 is the number of non-zero elements of q.
The sparse-ness of frequency vectors q grows with the number of corpus parts,keeping computation time reasonable.4） This seems to have escaped the attention of Zhang et al.
[28] andGries.
Gries only noted that it gives the same numerical result in anexample scenario [4] and appears similar in cluster analysis [17].Table 1 Mean improvement in 𝑅2aof the log-transformed mea-sure over the non-log-transformed (number of datasets of total 11with positive improvement, if any, in parentheses).
Cases wherelogarithm improves 𝑅2aby at least 0.001 are printed in bold.(a)
Dispersion measures as single predictors.
Dispersion Δ𝑅2aof log 𝑑 vs. 𝑑 (#Datasets: Δ𝑅2a> 0)Measure 𝑑 Videos Channels CategoriesRange 0.356 (11) 0.329 (11) −0.060 (1)Gini Index 0.361
(11) 0.340 (11) −0.000 (5)Juilland’s 𝐷 −0.230 −0.213 −0.202Gries’s DP −0.095 −0.102 −0.169Rosengren’s𝑆0.362(11)0.341(11)−0.273Carroll’s 𝐷2−0.218 −0.176 (1) −0.241Lyne’s
𝐷3−0.112 −0.089 (1) −0.043Frequency (for comparison): 0.389 (11)(b) Two predictors: dispersion measure and log-frequency.
Dispersion Δ𝑅2aof log 𝑑 vs. 𝑑 (#Datasets: Δ𝑅2a> 0)Measure 𝑑 Videos Channels CategoriesRange 0.016 (8) 0.023 (10) −0.010 (3)Gini Index 0.003 (4) 0.002 (5) 0.002 (6)Juilland’s 𝐷 −0.006 (3) −0.006 (3) −0.010 (1)Gries’s DP −0.002 (3) 0.000 (7) −0.005 (3)Rosengren’s 𝑆 0.009 (5) 0.009 (6) −0.018 (1)Carroll’s 𝐷2−0.010
(5) −0.006 (4) −0.014 (1)Lyne’s 𝐷3−0.002 (3) −0.004 (2) −0.001 (4)based on subjective ratings as opposed to reaction time,while the lexical complexity used in this case diﬀers fromthe other data by being rated by non-native speakers or amix of natives and non-natives.
We evaluate the dispersions in two scenarios: as singlepredictors, and as one of two predictors, the other one beinglog-frequency.
In both cases, we measure adjusted 𝑅2[29]:𝑅2a= 1 − (1 − 𝑅2)𝑛 − 1𝑛 − 𝑝 − 1(10)where 𝑛 is the number of examples (dataset size) and 𝑝 isthe number of variables (1 or 2).
We compute 𝑅2(coef-ﬁcient of determination) for linear least squares (multiple)regression ﬁtted to the whole dataset, which allows us tointerpret it as measure of (multiple) correlation strength.5）We predict mean LDT from three studies: the En-glish Lexicon Project
[30], restricted to lower-case wordsfollowing the approach of Brysbaert and New
[8]; theMELD-SCH database
[31] of simpliﬁed Chinese words;and SPALEX [32] for Spanish.
For English and Chinese,5）
Using 𝑅2instead of Pearson’s (multiple) correlation coeﬃcient 𝑟(𝑅) allows us to ignore the diﬀerent polarity of the tasks (rare wordshave low familiarity but high complexity).
The adjustment is appro-priate for comparing diﬀerent numbers of independent variables.we use the published mean LDT.
SPALEX only providesraw participant data, which we process by removing timesout of the range
[200 ms, 2000 ms][32], and comput-ing the means.
We predict mean word familiarity fromﬁve databases: Chinese familiarity ratings [33], EnglishMRC lexical database
[34, 35], Indonesian lexical norms[36], Japanese word familiarity ratings for reception [37],and Spanish lexical norms
[38].
Lastly, we predict lexicalcomplexity for English, Spanish and Japanese using theevaluation sets of the MultiLS dataset [39].
In total, we areevaluating on 11 datasets (task-language combinations).


4.1 To Log or Not to Log

In Table 1, we compare each dispersion measure with itslog-transformed version.
Perhaps surprisingly, which oneis a better predictor does not depend solely on the mea-sure, but also on corpus part granularity, and whether themeasure is used as a single predictor or with log-frequency.
When used as single predictors (Table 1a), the logarith-mic transformation beneﬁts range, Gini index, and Rosen-gren’s 𝑆, resulting in stronger correlations on all 11 datasets– but only if videos and channels are used as parts.
For allthree measures, the diﬀerence between using and not usinglog-transformation is critical (0.340 to 0.362), comparableto that between log-frequency and frequency (0.389).When dispersion measures are employed along with log-frequency (Table 1b), applying logarithm is moderatelybeneﬁcial for the same measures as above and for Giniindex for categories, but the improvements are not robustacross datasets.
We will report and discuss each measure with logarithmapplied or not applied according to these results.


4.2 Results

As shown in Figure 1 (solid bars), the only dispersionmeasure robustly stronger than log-frequency as predictorsof LDT, word familiarity, and lexical complexity is log-range for channels and videos.
Although it does not comenear in correlation strength, Gries’s DP is worth noting asthe only measure performing the best with categories (thecoarsest part granularity).When used along with log-frequency, the followingmeasures result in particularly robust improvements (indecreasing order): log-range for channels, log-range forvideos, range for categories, and Rosengren’s 𝑆 for cate-

Dispersion Measures as Predictors of Lexical Decision Time,Word Familiarity, and Lexical Complexity

Adam Nohejl Taro Watanabe



Nara Institute of Science and Technology



{nohejl.adam.mt3, taro}@is.naist.jp



Abstract

Various measures of dispersion have been proposed topaint a fuller picture of a word’s distribution in a corpus,but only little has been done to validate them externally.
Weevaluate a wide range of dispersion measures as predictorsof lexical decision time, word familiarity, and lexical com-plexity in ﬁve diverse languages.
We ﬁnd that the logarithmof range is not only a better predictor than log-frequencyacross all tasks and languages, but that it is also the mostpowerful additional variable to log-frequency, consistentlyoutperforming the more complex dispersion measures.
Wediscuss the eﬀects of corpus part granularity and logarith-mic transformation, shedding light on contradictory resultsof previous studies.


1 Introduction

Measures of dispersion have been proposed in corpuslinguistics to complement frequency, a measure of centraltendency.
While a word’s frequency tells us how commonthe word is in the whole corpus, its dispersion tells us howevenly it is spread.
For instance, the words very and yeah,or came and data may have similar overall frequencies, butyeah and data would likely have lower dispersions, as theyare speciﬁc to a certain register or domain.
The conceptually simplest dispersion measure is therange: the number of corpus parts in which a word occurs.
The parts may be of diﬀerent granularity and function,e.g. individual texts, authors, domains, or registers.
In theTUBELEX corpus [1], which is based on YouTube videos,our example words have the following frequencies (in thou-sands of occurrences) and ranges (in thousands of YouTubechannels): very: 332 and 35; yeah:
333 and 19; came: 64and 17; data: 64 and 7, conﬁrming our expectations.
The number of texts in which a word appears was usedto organize pedagogical word lists as early as in 1920by Keniston
[2] and mentioned as “range” by Thorndike(2021)[3].
Gries (2008)[4] lists thirteen more advanceddispersion measures that have been proposed over thedecades, often theoretically motivated or considering in-tuitive interpretability.
What is critically missing, as Gries[4] also argues, is external validation.
We aim to bridge this gap between theoretical corpus dis-persion research, psycholinguistics, and NLP applications,with a comprehensive evaluation of dispersion measureson ﬁve languages, three tasks, and three levels of corpuspart granularity.
Two of the tasks predict psycholinguisticdata, lexical decision time (LDT) and word familiarity, andone is an NLP task, lexical complexity prediction.


2 Related Research

Adelman et al.
(2006)[5] evaluated log-range on Englishword naming and LDT, concluding that log-range1）is abetter predictor than log-frequency.
Brysbaert and New (2009)[8] replicated the results ofAdelman et al.
on the SUBTLEX-US subtitle corpus.
Mostlater studies on ﬁlm subtitles reached similar conclusions[9, 10, 11, 12, 13], but a few of them did not ﬁnd a statisticalsigniﬁcant diﬀerence on individual datasets [14, 15, 16].All of these studies investigated only log-range across sub-title ﬁles (typically thousands of ﬁles corresponding toﬁlms or show episodes) as a dispersion measure, and eval-uated it on LDT or word naming times, essentially repli-cating Brysbaert and New’s study [8] on other languages.
Gries (2010)[17] evaluated multiple dispersion mea-sures on English word naming and LDT data.
The studydid not reach a conclusive result on the two datasets.
Gries (2021)[18] experimented with log-frequency,1）
Adelman et al. call range “contextual diversity”, avoiding theterms “dispersion” and “range”, which is arguably confusing [6, 7],but does not detract anything from the practical value of their study.word length, and multiple dispersion measures as featuresfor a random forest model of English auditory LDT.


3 Examined Measures

As we have noted, both frequency and range are com-monly log-transformed to achieve better correlation withpsycholinguistic variables.
Since our evaluation will in-clude words not present in the corpus, which would resultin undeﬁned values (log 0), we take the following steps toexamine the log-transformation of all examined measuresand frequency: Using 𝑛 = number of corpus parts, we applysmoothing in the form (𝑑𝑛 + 1)/(𝑛 + 1) to each dispersionmeasure 𝑑 if we log-transform it.
Therefore, with a slightabuse of notation, we always use “log 𝑑” in the followingtext to refer to log((𝑑𝑛 +1)/(𝑛
+ 1)).
For (log-)frequency,we always use Laplace-smoothed frequency [19].We use all measures in forms appropriate for unequallysized corpus parts and normalized to the range
[0, 1],adapting Gini index and Gries’s DP to 𝑑 = 1 − 𝑑∗fromtheir original formulas 𝑑∗, so that high values indicate highdispersion.
We use the following variables, given a word𝑤: 𝑛 is the number of corpus parts; 𝑣𝑖is the number ofoccurrences of 𝑤 in part 𝑖; 𝑘𝑖is the number of tokens inpart 𝑖; 𝑠𝑖= 𝑘𝑖/Ík is the proportion of part 𝑖; 𝑟𝑖= 𝑣𝑖/Ívis the proportion of occurrences of 𝑤 in part 𝑖; 𝑝𝑖= 𝑣𝑖/𝑘𝑖is the relative frequency of 𝑤 in part 𝑖, i.e. frequency nor-malized per part; 𝑞𝑖= 𝑝𝑖/Íp is the frequency normalizedper part and per word.
For each variable 𝑥𝑖indexed bycorpus part, we understand x
= (𝑥𝑖)𝑛𝑖=1as the correspond-ing vector with sumÍx =Í𝑛𝑖=1𝑥𝑖, mean 𝜇x=Íx/𝑛, andstandard deviation 𝜎x=pÍ𝑛𝑖=1(𝑥𝑖− 𝜇x)2/𝑛.We examine the following dispersion measures:Range 𝑅 =Í𝑛𝑖=1[𝑣𝑖> 0]𝑛(1)Gini index 𝐺 = 1 −Í𝑛𝑖=1Í𝑛𝑗=1𝑞𝑖− 𝑞𝑗2𝑛(2)Juilland’s [20] 𝐷 = 1 −𝜎p𝜇p√𝑛 − 1(3)Lyne’s
[21] 𝐷3= 1 −Í𝑛𝑖=1(𝑟𝑖− 𝑠𝑖)24(4)Gries’s [4] DP = 1 −Í𝑛𝑖=1|𝑟𝑖− 𝑠𝑖|2(5)Rosengren’s
[22] 𝑆 =Í𝑛𝑖=1√𝑞𝑖2𝑛(6)Carroll’s
[23] 𝐷2=−Í𝑛𝑖=1𝑞𝑖log 𝑞𝑖log 𝑛(7)Regardless of the formulas above, we deﬁne each mea-sure as 0 for words missing from the corpus.2）Gini index is the discrete variant of the well-know in-dex of inequality.
It was proposed as a dispersion mea-sure independently by Murayama et al.
(2018)[24](asWord GINI = −log 𝐺) and Burch et al.
(2017)[25](as𝐷𝐴, later adjusted to unequally sized parts, with a slightlydiﬀerent normalization from our 𝐺
[26]).
We investigate𝐺 and log 𝐺 using the formula given by Glasser (1962)[27], which reduces computation time to 𝑂 (𝑛 log 𝑛).3）As far as we can tell, “distributional consistency” pro-posed by Zhang et al.
(2004)[28], is simply equal to Rosen-gren’s 𝑆 (6).4）Finally, we observe that inverse document frequency(idf) and variation coeﬃcient (vc) can be expressed as lin-ear functions of log-range (1) and Juilland’s D (3), respec-tively, and therefore do not need to be examined separatelyin terms of linear correlation:idf = log1𝑅𝑠 = −log 𝑅 (8)vc =𝜎p𝜇p=√𝑛 − 1 (1 − 𝐷)(9)

4 Evaluation

We evaluate the measures on TUBELEX [1], a largeYouTube subtitle corpus for English, Chinese, Spanish, In-donesian, and Japanese.
Word frequency in TUBELEXwas already demonstrated to achieve correlation with psy-cholinguistic variables on par with or superior to ﬁlm sub-title corpora
[1].
TUBELEX also provides three levelsof linguistically valid corpus parts: videos, channels, andcategories (tens of thousands, thousands, and 15 parts re-spectively).
We use TUBELEX in its default tokenization.
For evaluation, we use the same datasets for LDT (3 lan-guages), word familiarity (5 languages), and lexical com-plexity (3 languages) as were used for extrinsic evaluationof TUBELEX log-frequency by Nohejl et al.
(2024)[1].Word familiarity and lexical complexity diﬀer from thecommonly employed LDT or word naming tasks by being2）
This is in line with the formulas for range, 𝑆, and 𝐷2, whichwould give 0 for a zero frequency word.
𝐷, 𝐷3, and DP would beundeﬁned, and Gini index would be 1.3）
We also use sparse arrays to represent q, resulting in 𝑂(𝑚 log 𝑚)time, where 𝑚 is the number of non-zero elements of q.
The sparse-ness of frequency vectors q grows with the number of corpus parts,keeping computation time reasonable.4） This seems to have escaped the attention of Zhang et al.
[28] andGries.
Gries only noted that it gives the same numerical result in anexample scenario [4] and appears similar in cluster analysis [17].Table 1 Mean improvement in 𝑅2aof the log-transformed mea-sure over the non-log-transformed (number of datasets of total 11with positive improvement, if any, in parentheses).
Cases wherelogarithm improves 𝑅2aby at least 0.001 are printed in bold.(a)
Dispersion measures as single predictors.
Dispersion Δ𝑅2aof log 𝑑 vs. 𝑑 (#Datasets: Δ𝑅2a> 0)Measure 𝑑 Videos Channels CategoriesRange 0.356 (11) 0.329 (11) −0.060 (1)Gini Index 0.361
(11) 0.340 (11) −0.000 (5)Juilland’s 𝐷 −0.230 −0.213 −0.202Gries’s DP −0.095 −0.102 −0.169Rosengren’s𝑆0.362(11)0.341(11)−0.273Carroll’s 𝐷2−0.218 −0.176 (1) −0.241Lyne’s
𝐷3−0.112 −0.089 (1) −0.043Frequency (for comparison): 0.389 (11)(b) Two predictors: dispersion measure and log-frequency.
Dispersion Δ𝑅2aof log 𝑑 vs. 𝑑 (#Datasets: Δ𝑅2a> 0)Measure 𝑑 Videos Channels CategoriesRange 0.016 (8) 0.023 (10) −0.010 (3)Gini Index 0.003 (4) 0.002 (5) 0.002 (6)Juilland’s 𝐷 −0.006 (3) −0.006 (3) −0.010 (1)Gries’s DP −0.002 (3) 0.000 (7) −0.005 (3)Rosengren’s 𝑆 0.009 (5) 0.009 (6) −0.018 (1)Carroll’s 𝐷2−0.010
(5) −0.006 (4) −0.014 (1)Lyne’s 𝐷3−0.002 (3) −0.004 (2) −0.001 (4)based on subjective ratings as opposed to reaction time,while the lexical complexity used in this case diﬀers fromthe other data by being rated by non-native speakers or amix of natives and non-natives.
We evaluate the dispersions in two scenarios: as singlepredictors, and as one of two predictors, the other one beinglog-frequency.
In both cases, we measure adjusted 𝑅2[29]:𝑅2a= 1 − (1 − 𝑅2)𝑛 − 1𝑛 − 𝑝 − 1(10)where 𝑛 is the number of examples (dataset size) and 𝑝 isthe number of variables (1 or 2).
We compute 𝑅2(coef-ﬁcient of determination) for linear least squares (multiple)regression ﬁtted to the whole dataset, which allows us tointerpret it as measure of (multiple) correlation strength.5）We predict mean LDT from three studies: the En-glish Lexicon Project
[30], restricted to lower-case wordsfollowing the approach of Brysbaert and New
[8]; theMELD-SCH database
[31] of simpliﬁed Chinese words;and SPALEX [32] for Spanish.
For English and Chinese,5）
Using 𝑅2instead of Pearson’s (multiple) correlation coeﬃcient 𝑟(𝑅) allows us to ignore the diﬀerent polarity of the tasks (rare wordshave low familiarity but high complexity).
The adjustment is appro-priate for comparing diﬀerent numbers of independent variables.we use the published mean LDT.
SPALEX only providesraw participant data, which we process by removing timesout of the range
[200 ms, 2000 ms][32], and comput-ing the means.
We predict mean word familiarity fromﬁve databases: Chinese familiarity ratings [33], EnglishMRC lexical database
[34, 35], Indonesian lexical norms[36], Japanese word familiarity ratings for reception [37],and Spanish lexical norms
[38].
Lastly, we predict lexicalcomplexity for English, Spanish and Japanese using theevaluation sets of the MultiLS dataset [39].
In total, we areevaluating on 11 datasets (task-language combinations).


4.1 To Log or Not to Log

In Table 1, we compare each dispersion measure with itslog-transformed version.
Perhaps surprisingly, which oneis a better predictor does not depend solely on the mea-sure, but also on corpus part granularity, and whether themeasure is used as a single predictor or with log-frequency.
When used as single predictors (Table 1a), the logarith-mic transformation beneﬁts range, Gini index, and Rosen-gren’s 𝑆, resulting in stronger correlations on all 11 datasets– but only if videos and channels are used as parts.
For allthree measures, the diﬀerence between using and not usinglog-transformation is critical (0.340 to 0.362), comparableto that between log-frequency and frequency (0.389).When dispersion measures are employed along with log-frequency (Table 1b), applying logarithm is moderatelybeneﬁcial for the same measures as above and for Giniindex for categories, but the improvements are not robustacross datasets.
We will report and discuss each measure with logarithmapplied or not applied according to these results.


4.2 Results

As shown in Figure 1 (solid bars), the only dispersionmeasure robustly stronger than log-frequency as predictorsof LDT, word familiarity, and lexical complexity is log-range for channels and videos.
Although it does not comenear in correlation strength, Gries’s DP is worth noting asthe only measure performing the best with categories (thecoarsest part granularity).When used along with log-frequency, the followingmeasures result in particularly robust improvements (indecreasing order): log-range for channels, log-range forvideos, range for categories, and Rosengren’s 𝑆 for cate-Lyne's D3Gries's DPJuilland's DGini IndexCarroll's D2Rosengren's SRangeDispersion Measure (DM)0.00.10.20.30.40.5R2a (Mean Over 11 Datasets)log-frequency: 0.4270.4310.1140.4310.1220.4300.1140.4430.2910.4340.2720.4360.1520.4390.2850.4370.3810.4360.3670.4410.337 (log)0.438 (log)0.421 (log)0.440 (log)0.432 (log)0.4450.3310.4380.4220.4410.4330.451 0.3880.445 (log)0.436 (log)0.446 (log)0.441 (log)0.452 0.4010.459 (log) 0.450 (log) 0.453 (log) 0.446 (log)
Single Variable (DM)CategoriesChannelsVideosTwo Variables (DM, log-freq.)CategoriesChannelsVideosFigure
1 Mean 𝑅2acomputed over 11 datasets for each dispersion measure, part granularity, and prediction with/without log-frequencyas a second variable, where “(log)” indicates log-transformed measures.
Stars indicate robust predictors, namely:⋆single predictorsthat were not signiﬁcantly (𝑝 < 0.001) worse than log-frequency for any dataset, and⋆predictors that, when used with log-frequency,improved the prediction by Δ𝑅2a≥ 0.01 for at least 8 of 11 datasets.gories, as shown in Figure 1 (hatched bars).


5 Discussion

We extended the previous results of Adelman et al.(2006)[5] and ﬁlm subtitle studies (e.g. [8]), which showedthat log-range predicts LDT better than log-frequency, toword familiarity and lexical complexity prediction.
Moreimportantly, we found that the viability of range as a sin-gle predictor depends on (1) a ﬁne corpus part granularity,i.e. channels or videos in the case of TUBELEX, and (2)the log-transformation.
This explains the low correlationachieved using only non-log-transformed range in somestudies, e.g. Baayen (2010)[40].
When dispersion is usedalong with log-frequency, log-range for videos and chan-nels (ﬁne parts) are still the best choices, followed by rangeand Rosenberg’s 𝑆, both non-log-transformed and basedon categories (coarse parts).These ﬁnding oﬀer a guideline for choosing dispersionmeasures as model variables, based on the corpus parts areavailable.
The previous studies that we know of have notcompared multiple part granularities of a single corpus.
Besides three levels of granularity, our evaluation en-compassed 11 datasets (task-language combinations).
Asthe results generally agreed across datasets, we have notreported them individually.
For instance, the robust singlepredictors (marked⋆in Figure 1) were signiﬁcantly betterthan log-frequency on most datasets and not signiﬁcantlydiﬀerent on two to three of them.
We focused on the gen-eral, not the insigniﬁcant exceptions.
This highlights theimportance of evaluation on multiple datasets and puts intoperspective the insigniﬁcant diﬀerences between log-rangeand log-frequencies on individual datasets reported in afew previous studies [14, 15, 16].We believe that linear regression, which we used foranalysis, gives more widely applicable and interpretableresults than rank correlation (Gries, 2010
[17])6）or ran-dom forests (Gries, 2021
[18])7）.
We hope that futureinvestigations of what we have called “exceptions” or less“widely applicable” bring deeper insights into speciﬁc usecases and interactions with diﬀerent data and granularities.
Our results are immediately applicable to NLP tasks thathave relied on frequencies for modeling words perceived ascommon or simple, such as language learning applicationsor lexical simpliﬁcation.
Range data for TUBELEX, whichwe have used, is readily available as channels and videosin its word lists, and for most SUBTLEX language muta-tions as “contextual diversity” (CD), all based on corpusparts of comparable granularity.6）
Rank correlation is an appropriate evaluation method for applica-tions that require only ranking, but it obscures the diﬀerent “shapes”of dispersion metrics.7）
With enough training data a random forest may be more ﬁttingfor a practical application, but caution is needed when using it as anevaluation tool.
The experiment in [18] used the full data for bothtraining and testing.
Moreover, the features optimal for a randomforest and large training data may not perform well in other scenarios.



Acknowledgments

We are grateful to an anonymous reviewer of [1] forencouraging us to explore other dispersion metrics, giventhe curious result achieved by Gini index in our evaluation.

References


[1] Adam Nohejl, Frederikus Hudi, Eunike Andriani Kardinata, Shin-taro Ozaki, Maria Angelica Riera Machin, Hongyu Sun, Justin Vas-selli, and Taro Watanabe. Beyond Film Subtitles: Is YouTube theBest Approximation of Spoken Vocabulary? ArXiv preprint, Vol.arXiv:2410.03240v1 [cs], , October 2024.
[2] Hayward Keniston. Common Words in Spanish. Hispania, Vol. 3,No. 2, pp. 85–96, 1920.
[3] Edward Lee Thorndike. The Teacher’s Word Book. Teachers College,Columbia University, 1921.
[4] Stefan Th Gries. Dispersions and adjusted frequencies in corpora.International Journal of Corpus Linguistics, Vol. 13, No. 4, pp. 403–437, January 2008.
[5] James S. Adelman, Gordon D.A. Brown, and Jos´e F. Quesada. Con-textual Diversity, Not Word Frequency, Determines Word-Naming andLexical Decision Times. Psychological Science, Vol. 17, No. 9, pp.814–823, September 2006.
[6] Geoﬀ Hollis. Delineating linguistic contexts, and the validity of contextdiversity as a measure of a word’s contextual variability. Journal ofMemory and Language, Vol. 114, p. 104146, October 2020.
[7] Stefan Th. Gries. Analyzing Dispersion. In Magali Paquot and Ste-fan Th. Gries, editors, A Practical Handbook of Corpus Linguistics, pp.99–118. Springer International Publishing, Cham, 2020.
[8] Marc Brysbaert and Boris New. Moving beyond Kucera and Francis: Acritical evaluation of current word frequency norms and the introductionof a new and improved word frequency measure for American English.Behavior Research Methods, Vol. 41, No. 4, pp. 977–990, November2009.
[9] Qing Cai and Marc Brysbaert. SUBTLEX-CH: Chinese Word andCharacter Frequencies Based on Film Subtitles. PLoS ONE, Vol. 5,No. 6, p. e10729, June 2010.
[10] Maria Dimitropoulou, Jon Andoni Du˜nabeitia, Alberto Avil´es, Jos´eCorral, and Manuel Carreiras. Subtitle-based word frequencies as thebest estimate of reading behavior: The case of Greek. Frontiers inpsychology, Vol. 1, p. 218, 2010.
[11] Emmanuel Keuleers, Marc Brysbaert, and Boris New. SUBTLEX-NL: A new measure for Dutch word frequency based on ﬁlm subtitles.Behavior Research Methods, Vol. 42, No. 3, pp. 643–650, August 2010.
[12] Roger Boada, Marc Guasch, Juan Haro, Josep Demestre, and Pilar Ferr´e.SUBTLEX-CAT: Subtitle word frequencies and contextual diversity forCatalan. Behavior Research Methods, Vol. 52, No. 1, pp. 360–375,February 2020.
[13] Hien Pham, Benjamin V. Tucker, and R. Harald Baayen. Constructingtwo Vietnamese corpora and building a lexical database. LanguageResources and Evaluation, Vol. 53, No. 3, pp. 465–498, September2019.
[14] Walter J. B. van Heuven, Pawel Mandera, Emmanuel Keuleers, andMarc Brysbaert. SUBTLEX-UK: A new and improved word frequencydatabase for British English. The Quarterly Journal of ExperimentalPsychology, Vol. 67, No. 6, pp. 1176–1190, 2014.
[15] Pawe l Mandera, Emmanuel Keuleers, Zoﬁa Wodniecka, and MarcBrysbaert. Subtlex-pl: Subtitle-based word frequency estimates forPolish. Behavior Research Methods, Vol. 47, No. 2, pp. 471–483, June2015.
[16] Walter JB van Heuven, Joshua S Payne, and Manon W Jones.SUBTLEX-CY: A new word frequency database for Welsh. QuarterlyJournal of Experimental Psychology, pp. 1052–1067, August 2023.
[17] Stefan Th Gries. Dispersions and adjusted frequencies in corpora:Further explorations. In Corpus-Linguistic Applications, pp. 197–212.Brill, January 2010.
[18] Stefan Th Gries. What do (most of) our dispersion measures measure(most)? Dispersion? Journal of Second Language Studies, Vol. 5,No. 2, pp. 171–205, November 2021.
[19] Marc Brysbaert and Kevin Diependaele. Dealing with zero word fre-quencies: A review of the existing rules of thumb and a suggestion foran evidence-based choice. Behavior Research Methods, Vol. 45, No. 2,pp. 422–430, June 2013.
[20] A.G. Juilland, D.R. Brodin, and C. Davidovitch. Frequency Dictionaryof French Words. Romance Languages and Their Structures. Mouton,1971.
[21] Anthony A. Lyne. The Vocabulary of French Business Correspon-dence: Word Frequencies, Collocations, and Problems of LexicometricMethod. Travaux de Linguistique Quantitative. Slatkine, 1985.
[22] Inger Rosengren. The quantitative concept of language and its rela-tion to the structure of frequency dictionaries.´Etudes de linguistiqueappliqu´ee, Vol. 1, p. 103, 1971.
[23] John B. Carroll. An Alternative to Juilland’s Usage Coeﬃcient forLexical Frequencies. ETS Research Bulletin Series, Vol. 1970, No. 2,pp. i–15, 1970.
[24] Taichi Murayama, Shoko Wakamiya, and Eiji Aramaki. WORD GINI: Aproposal and application of an index to capture word usage bias [WORDGINI: Go no shiy¯o no katayori wo tsukamaeru shihy¯o no teian to sono¯oy¯o] (in Japanese). The 24th Annual Conference of the Associationfor Natural Language Processing [Gengoshori gakkai dai 24 kai nenjitaikai], pp. 698–701, 2018.
[25] Brent Burch, Jesse Egbert, and Douglas Biber. Measuring and interpret-ing lexical dispersion in corpus linguistics. Journal of Research Designand Statistics in Linguistics and Communication Science, Vol. 3, No. 2,pp. 189–216, October 2017.
[26] Jesse Egbert, Brent Burch, and Douglas Biber. Lexical dispersion andcorpus design. International Journal of Corpus Linguistics, Vol. 25,No. 1, pp. 89–115, April 2020.
[27] Gerald J. Glasser. Variance Formulas for the Mean Diﬀerence andCoeﬃcient of Concentration. Journal of the American Statistical Asso-ciation, Vol. 57, No. 299, pp. 648–654, September 1962.
[28] Huarui Zhang, Churen Huang, and Shiwen Yu. Distributional Con-sistency: As a General Method for Deﬁning a Core Lexicon. InMaria Teresa Lino, Maria Francisca Xavier, F´atima Ferreira, RuteCosta, and Raquel Silva, editors, Proceedings of the Fourth Interna-tional Conference on Language Resources and Evaluation (LREC’04),Lisbon, Portugal, May 2004. European Language Resources Associa-tion (ELRA).
[29] Mordecai Ezekiel. Methods of Correlation Analysis. Wiley, Oxford,England, 1930.
[30] David A. Balota, Melvin J. Yap, Michael J. Cortese, Keith A. Hutchison,Brett Kessler, Bjorn Loftis, James H. Neely, Douglas L. Nelson, Greg B.Simpson, and Rebecca Treiman. The English Lexicon Project. BehaviorResearch Methods, Vol. 39, No. 3, pp. 445–459, August 2007.
[31] Yiu-Kei Tsang, Jian Huang, Ming Lui, Mingfeng Xue, Yin-Wah FionaChan, Suiping Wang, and Hsuan-Chih Chen. MELD-SCH: A megas-tudy of lexical decision in simpliﬁed Chinese. Behavior Research Meth-ods, Vol. 50, No. 5, pp. 1763–1777, October 2018.
[32] Jose Armando Aguasvivas, Manuel Carreiras, Marc Brysbaert, Pawe lMandera, Emmanuel Keuleers, and Jon Andoni Du˜nabeitia. SPALEX:A Spanish Lexical Decision Database From a Massive Online DataCollection. Frontiers in Psychology, Vol. 9, , November 2018.
[33] Yongqiang Su, Yixun Li, and Hong Li. Familiarity ratings for 24,325simpliﬁed Chinese words. Behavior Research Methods, Vol. 55, No. 3,pp. 1496–1509, April 2023.
[34] Max Coltheart. The MRC psycholinguistic database. The Quar terlyJournal of Experimental Psychology A: Human Experimental Psychol-ogy, Vol. 33A, No. 4, pp. 497–505, 1981.
[35] M. (Max) Coltheart and Michael John Wilson. MRC PsycholinguisticDatabase Machine Usable Dictionary : Expanded Shorter Oxford En-glish Dictionary entries / Max Coltheart and Michael Wilson. OxfordText Archive, March 1987.
[36] Agnes Sianipar, Pieter van Groenestijn, and Ton Dijkstra. AﬀectiveMeaning, Concreteness, and Subjective Frequency Norms for Indone-sian Words. Frontiers in Psychology, Vol. 7, , December 2016.
[37] Masayuki Asahara. Word Familiarity Rate Estimation Using a BayesianLinear Mixed Model. In Silviu Paun and Dirk Hovy, editors, Proceed-ings of the First Workshop on Aggregating and Analysing CrowdsourcedAnnotations for NLP, pp. 6–14, Hong Kong, November 2019. Associa-tion for Computational Linguistics.
[38] Marc Guasch, Pilar Ferr´e, and Isabel Fraga. Spanish norms for aﬀectiveand lexico-semantic variables for 1,400 words. Behavior ResearchMethods, Vol. 48, No. 4, pp. 1358–1369, December 2016.
[39] Matthew Shardlow, Fernando Alva-Manchego, Riza Batista-Navarro,Stefan Bott, Saul Calderon Ramirez, R´emi Cardon, Thomas Franc¸ois,Akio Hayakawa, Andrea Horbach, Anna H¨ulsing, Yusuke Ide,Joseph Marvin Imperial, Adam Nohejl, Kai North, Laura Occhipinti,Nelson Per´ez Rojas, Nishat Raihan, Tharindu Ranasinghe, Martin SolisSalazar, SanjaˇStajner, Marcos Zampieri, and Horacio Saggion. TheBEA 2024 Shared Task on the Multilingual Lexical SimpliﬁcationPipeline. In Ekaterina Kochmar, Marie Bexte, Jill Burstein, AndreaHorbach, Ronja Laarmann-Quante, Ana¨ıs Tack, Victoria Yaneva, andZheng Yuan, editors, Proceedings of the 19th Workshop on InnovativeUse of NLP for Building Educational Applications (BEA 2024), pp.571–589, Mexico City, Mexico, June 2024. Association for Computa-tional Linguistics.
[40] R. H. Baayen. Demythologizing the word frequency eﬀect: A discrim-inative learning perspective. The Mental Lexicon, Vol. 5, No. 3, pp.436–461, January 2010.