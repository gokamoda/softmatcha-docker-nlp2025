Exploring User Feedback: A Thematic and Sentiment Analysisof User Interactions with LLM-Based Dialogue Robots

Muhammad Yeza Baihaqi

1,2

 Angel Garc



´



ıa Contreras

2

 Seiya Kawano

2,1

 Koichiro Yoshino

3,2,11

Nara Institute of Science and Technology  

2

Guardian Robot Project, RIKEN

3

Institute of Science Tokyo



muhammad yeza.baihaqi.lx2@naist.ac.jp



 {angel.garciacontreras, seiya.kawano}@riken.jp



 koichiro@c.titech.ac.jp



Abstract

Recent advancements in large language models (LLMs)have signiﬁcantly improved dialogue agents, enabling themto generate context-aware, human-like responses.
Whilequantitative evaluations eﬀectively compare performancebased on predeﬁned metrics, they may fail to capture nu-anced user experiences, such as memorable exchanges orunexpected opinions, which are crucial for reﬁning the sys-tem.
To address this issue, we conducted thematic and sen-timent analysis by collecting participant feedback throughdialogue experiments.
Speciﬁcally, we assessed GPT-3.5-Turbo and GPT-4o as dialogue models for dialogue robots.
Thematic analysis allowed us to identify recurring patternsin user experiences, while sentiment analysis helped gaugethe emotional tone of those interactions.
Our experimen-tal results provided rich insights in the form of themesand sub-themes, such as perceptions of knowledge depthand mistake correction.
Sentiment analysis complementedthese ﬁndings, showing that GPT-4o received a positiveimpression, while GPT-3.5-Turbo garnered mostly nega-tive feedback.


1 Introduction

The recent advancements in large language models(LLMs) have ushered in a new era for dialogue agents[1].
With LLM-based dialogue models, dialogue agentscan generate highly coherent, context-aware, and human-like responses, signiﬁcantly enhancing their conversationalcapabilities [2, 3, 4].
Nowadays, they are being utilized ina variety of scenarios, such as counseling [5], pharmaceu-ticals
[6], and small talk rapport agents
[7].To evaluate the performance of these dialogue agents,human evaluation through quantitative analysis is com-monly employed.
Our recent research utilized Likertscales and pairwise comparison questionnaires to assessthe rapport-building capabilities of dialogue agents throughquantitative analysis [8].
These methods quantify agents’performance in predeﬁned attributes, such as user satis-faction and engagement, providing insights into speciﬁcaspects of agent performance.
Quantitative analysis, while eﬀective for identifyingtrends and comparing performance, has notable limitationsin capturing the subtleties of the studied aspects [9].
Thisapproach is often conﬁned to predeﬁned variables, makingit inappropriate for capturing unpredictable events that mayarise during interactions [9, 10, 11].
For example, whilenumerical scores may show that one agent is perceived asmore natural than another, they fail to uncover the under-lying reasons―whether due to the joy it elicited, its abilityto maintain a logical ﬂow, or other unforeseen factors.
Additionally, a naturalness score alone cannot determinewhether users felt the agent was close to human-like ormerely an incremental improvement.
Without collectingparticipant feedback, these critical nuances remain unex-plored, limiting our ability to adapt to unexpected outcomesand reﬁne the system accordingly.
To address these limitations, qualitative analysis calledthematic analysis oﬀers a complementar y approach by ex-ploring user feedback in g reater depth.
This method in-volves analyzing qualitative data, such as user comments,to identify recurring themes and patterns that more holisti-cally describe the experiences and emotions of users duringtheir interactions [12].
These user comments often includeunique details, such as speciﬁc memorable exchanges, un-expected user opinions, or the agent’s handling of a partic-ular situation, which are diﬃcult to capture by quantitativemetrics alone [13].
Ultimately, this approach provides richand varied data that transcends expected variables [9].Thematic analysis is also commonly combined with sen-timent analysis.
Sentiment analysis involves analyzing peo-ple’s opinions and sentiments toward entities
[14].
Com-bining sentiment analysis with thematic analysis allowsresearchers to gain deeper insights into not only the over-arching themes present in the data but also the emotionaltone associated with those themes [15].
This combinationenables a more nuanced understanding of how participantsfeel about speciﬁc themes, helping to identify patterns ofsentiment within diﬀerent thematic categories
[16].Given these advantages, this study aims to leverage the-matic and sentiment analyses to gain a richer understand-ing of user experiences with dialogue robots.
Speciﬁcally,this experiment compares GPT-4o and GPT-3.5-Turbo asdialogue models for dialogue robots.
We conducted dia-logue experiments, gathering detailed participant feedbackto uncover nuanced user experiences and provide unique in-sights into the diﬀerences between the two dialogue robots.


2 Methodology



2.1 Participants


The study involved 20 participants, equally divided be-tween 10 males and 10 females, with an average age of23.35 years (SD = 1.02).
None had prior experience withrobot interactions.
Informed consent for data usage wasobtained from all participants before the experiment.


2.2 Dialogue systems and robots

In this research, we speciﬁcally utilized the GPT-3.5-Turbo and GPT-4o models.
Both large language modelsemployed a free-form approach to prompt rapport-buildingdialogue systems [7].
The dialogue strategy focused on in-tegrating rapport-building utterances into small talk.
Theseutterances, derived from proven human-to-human interac-tions, included techniques such as praising, encourage-ment, and recommendations, among others, to foster rap-port.
Additionally, the system employed two types of ques-tions―short questions and open-ended questions―to en-sure conversational continuity until 28 turns.
Figure 1 CommU robot.
The LLMs were integrated into dialogue robots namedCommU, as shown in Figure 1.
Participants communi-cated with the robots through voice interaction.
To enablethis, we utilized Julius-based automatic speech recognition(ASR)[17] to capture participants’ voices and employed atext-to-speech (TTS) system1）to generate the robot’s voice.
Dialogue robots powered by GPT-3.5-Turbo were referredto as BotA, while those using GPT-4o were named BotO.

2.3 Experimental procedure

In this experiment, we used a counterbalanced design.
Each participant engaged in a small talk with both BotAand BotO. After interacting with both robots, participantswere asked to provide their experiences in the form of shortor long comments for each robot.


2.4 Analyses

2.4.1 Thematic analysisThematic analysis was conducted by analyzing the par-ticipants’ comments for each robot.
First, user commentswere coded based on their characteristics.
Short comments,typically consisting of a single sentence, could be directlyclassiﬁed into a theme and sub-theme.
On the other hand,longer comments required a coding process before classiﬁ-cation.
If a user made a long comment like, “The reactionswere natural and similar to those of humans.
It was easy tohave a conversation because he introduced me to diﬀerenttopics and asked me questions to dig deeper,” we wouldﬁrst break the comment into shorter sentences and thenclassify them into relevant themes and sub-themes.1） https://pypi.org/project/gTTS/These comments were categorized into speciﬁc themesand sub-themes through an iterative process.
The themesand sub-themes emerged directly from participants’ com-ments, rather than being shaped by predetermined frame-works or theories [18].
This approach allows us to capturerich data reﬂecting the perspectives of the par ticipants.
Additionally, in this research, we speciﬁcally focused onassessing both LLMs as the dialogue models of a dia-logue robot, and comments outside these domains―suchas those related to the robot’s
appearance―were discardedto maintain focus on relevant aspects.2.4.2
Sentiment analysisSentiment analysis was performed to classify the senti-ment of each coded comment as positive or negative.
To dothis, the comments were initially fed into ChatGPT, whichprovided an automatic classiﬁcation based on the detectedemotional tone.
Afterward, the researchers manually veri-ﬁed the classiﬁcations to ensure accuracy and consistency.


3 Results



3.1 Thematic ﬁndings

After carefully going through each comment iteratively,we decided on three themes: Conversation Behavior (CB),Conversation Content (CC), and Conversation Flow (CF).For BotA, we had 19 comments, and for BotO, we had27 comments.
The example comments are shown in Ap-pendices A1 and A2.
The comparison of BotA and BotO,based on our thematic analysis, is shown in Table 1.3.1.1 Conversation behaviorFor BotA, the theme of CB emerged prominently, witha focus on Friendliness and Human-likeness.
Participantsexpressed dissatisfaction with the bot’s lack of friendliness,noting that it did not feel like conversing with a friendand lacked personal opinions.
Additionally, BotA wasperceived as less natural compared to BotO, indicatingshortcomings in its human-like qualities.
BotB exhibited stronger CB, particularly in Communi-cation Skills and Human-likeness.
While BotA and BotOalso used rapport-building strategies, participants praisedBotB’s natural joke delivery, topic guidance, and conver-sational style, which made it feel less robotic.
Many notedthat its reactions felt so natural it hardly seemed like amachine, with slight inconsistencies adding to its con-versational authenticity.
BotB also excelled in MistakeCorrection, demonstrating impressive comprehension andadaptability in handling errors.3.1.2 Conversation contentFor BotA, the theme of CC emerged with sub-themes ofEnjoyment and Knowledge Depth.
Participants mentionedfun discussions and surpr ising topics like “friendship
,” butopinions on knowledge depth were mixed.
While someappreciated recommendations like summer dishes, othersfound the content lacking depth.
In contrast, BotO exhibited stronger performance in CC,with sub-themes of Enjoyment, Knowledge Depth, and Sat-isfaction.
Participants frequently noted the bot’s humorousand lively storytelling, which made the conversations en-joyable.
The bot also displayed greater knowledge depth,surprising users with unique and detailed information, suchas lesser-known travel destinations and speciﬁc suggestionstailored to the conversation.
These qualities contributed toa higher level of satisfaction.3.1.3 Conversation ﬂowFor BotA, the theme of CF emerged with sub-themes ofConversation Ending and Eﬀort in Topic Transition.
Par-ticipants expressed confusion and awkwardness about howconversations ended, with repeated goodbyes and a lackof new topics leading to stagnation.
Additionally, usershighlighted diﬃculties in transitioning between topics, asthe robot often required them to introduce new topics orsimply echoed their statements.
This lack of proactiveengagement made conversations challenging to navigate.
In comparison, BotO demonstrated mixed performancein CF, also encompassing the sub-themes of ConversationEnding and Eﬀort in Topic Transition.
While some partic-ipants found the endings awkward, they noted that BotOshowed greater eﬀort in maintaining topic transitions.
Thebot’s use of relatable examples and consistent questioningmade it easier for users to continue conversations and feelengaged.
However, occasional abrupt topic changes andunclear progression were noted as areas for improvement.


3.2 Sentiment in comments

BotA shows predominantly negative sentiment in con-versation behavior and ﬂow (100%) and mixed sentimentTable 1 Comparison of BotA and BotO based on Thematic Analysis.
Theme Sub-theme BotA (GPT-3.5-Turbo) BotO (GPT-4o)CBFriendliness BotA lacked friendliness, with responses feel-ing neutral and impersonal.
Conversation with BotO feels like interactingwith a friend.
Human-likeness BotA is considered less natural than BotO. BotO was perceived as natural, with users feel-ing that the topic guidance and reactions werehuman-like, to the point where they did notrealize they were interacting with a robot.
Communication skill Not explicitly mentioned Users perceived the communication skills ofBotO were improved compared to BotA.Mistake correction Not explicitly mentioned BotO responded appropriately to corrections,showing understanding and adaptability whenusers identiﬁed mistakes.
CCEnjoyment Users found the conversations fun at times,with occasional sur prises.
Users consistently described conversations asfun, engaging, interactive, and entertainingwith humorous remarks and lively exchanges.
Knowledge depth BotA provided basic information, such as sea-sonal dish recommendations.
Content lackeddepth and could feel generic.
BotO demonstrated deeper knowledge by of-fering unique insights, detailed suggestions,and relevant keywords, which were useful forbroadening the conversation scope.
Satisfaction Not explicitly mentioned Users explicitly stated being more satisﬁedwith BotO conversations.
CFEﬀort in topic transition Users reported challenges with topic transi-tions, citing BotA’s passive responses, lackof questions, and repetitive agreement state-ments, which made it diﬃcult and confusingto move the conversation forward.
It was noted that continuing the conversationwith BotO was much easier than with BotAdue to its content and behavior.
However, auser noted that the topic changes were abrupt.
Ending the conversation Towards the end of the conversation, it feltawkward and stagnant, with no new topics todiscuss, repeated goodbyes, and a sense of con-fusion about how it concluded.
Towards the end of the conversation, therewere still two reports noting that it got stuckand involved repeated goodbyes, though thisoccurred less frequently than with BotA.Figure 2 Sentiment analysis of BotA.Figure 3 Sentiment analysis of BotO.in content (60% positive).
In contrast, BotO achieves pos-itive sentiment in behavior (100%) and content (91.7%),with moderate results in ﬂow (62.5% positive).
Theseresults suggest that BotO provides a more engaging andsatisfactory user experience compared to BotA.

4 Conclusion

In this research, we employed both thematic and sen-timent analyses to examine participants’ feedback on twoLLMs, GPT-3.5-Turbo and GPT-4o, as dialogue modelsfor a dialogue robot.
Our thematic analysis uncovered im-portant themes and sub-themes related to user experience,such as perceived friendliness and the eﬀort involved intopic transitions.
These insights provided a deeper under-standing of how participants engaged with the models, be-yond what could be captured through quantitative methodsalone.
It was found that GPT-4o outper formed GPT-3.5-Turbo in nearly all aspects.
While both models receivedpositive feedback regarding enjoyment, issues with conver-sation ﬂow persisted for both.
Sentiment analysis revealedthat GPT-4o generally receiving positive sentiment andGPT-3.5-Turbo receiving more negative feedback.
Futureresearch could replicate this study with a larger and morediverse sample, incorporating semi-structured interviewsto gather more detailed feedback.



Acknowledgement

A part of this work is supported by JSPS KAKEN-HIGrant Number 23K24910 and 23K19984.

References


[1] Hongru Wang, Lingzhi Wang, Yiming Du, Liang Chen,Jingyan Zhou, Yufei Wang, and Kam-Fai Wong. A sur-vey of the evolution of language model-based dialoguesystems, 2023.
[2] Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang,Adrian de Wynter, Yan Xia, Wenshan Wu, Ting Song,Man Lan, and Furu Wei. Llm as a mastermind: A surveyof strategic reasoning with large language models, 2024.
[3] Varun Nair, Elliot Schumacher, Geoﬀrey Tso, and AnithaKannan. DERA: Enhancing large language model comple-tions with dialog-enabled resolving agents. In Tristan Nau-mann, Asma Ben Abacha, Steven Bethard, Kirk Roberts,and Danielle Bitterman, editors, Proceedings of the 6thClinical Natural Language Processing Workshop,pp. 122–161, Mexico City, Mexico, June 2024. Associ-ation for Computational Linguistics.
[4] Z. Ma, Y. Mei, and Z. Su. Understanding the beneﬁtsand challenges of using large language model-based con-versational agents for mental well-being support. In Pro-ceedings of the AMIA Annual Symposium, pp. 1105–1114, January 2024.
[5] Michimasa Inaba, Mariko Ukiyo, and Keiko Takamizo.Can large language models be used to provide psychologi-cal counselling? an analysis of gpt-4-generated responsesusing role-play dialogues. In Proceedings of the In-ternational Workshop on Spoken Dialogue Systems(IWSDS), pp. 1–9, March 4–6 2024.
[6] Vania Amanda Samor, Muhammad Yeza Baihaqi, Ed-mun Halawa, Luh Rai Maduretno Asvinigita, Sarah NabilaHakim, and Mela Septi Roﬁka. Evaluating llms as phar-maceutical care decision support tools across multiple casescenarios. In Proceedings of the International Con-ference on Medical Science and Health (ICOMESH2024), pp. 273–282. Atlantis Press, 2024.
[7] Muhammad Yeza Baihaqi, Angel Garcia Contreras, SeiyaKawano, and Koichiro Yoshino. Rapport-driven virtualagent: Rapport building dialogue strategy for improvinguser experience at ﬁrst meeting. In Interspeech 2024,pp. 4059–4063, 2024.
[8] Muhammad Yeza Baihaqi, Angel Garc´ıa Contreras, SeiyaKawano, and Koichiro Yoshino. Comparing likert scaleand pairwise comparison for human evaluation in rapport-building dialogue systems. Technical Report 43, Nara In-stitute of Science and Technology / Guardian Robot ProjectRIKEN / Institute of Science Tokyo, December 5 2024.
[9] Daniel Eyisi. The usefulness of qualitative and quantitativeapproaches and methods in researching problem-solvingability in science education curriculum. Journal of Edu-cation and Practice, Vol. 7, No. 15, pp. 91–100, 2016.
[10] M. Denscombe. The Good Research for Small-Scale Social Research Project. Open University Press,Philadelphia, 1998.
[11] J. W. Creswell. Research Design: Qualitative, Quan-titative, and Mixed Methods Approaches. SAGEPublications, London, 3rd edition, 2009.
[12] T. Vandemeulebroucke, B. D. de Casterl´e, and C. Gast-mans. How do older adults experience and perceive so-cially assistive robots in aged care: a systematic review ofqualitative evidence. Aging & Mental Health, Vol. 22,No. 2, pp. 149–167, February 2018. Epub 2017 Feb 9.
[13] B. Zhao, J. Lam, H. M. Hollandsworth, A. M. Lee, N. E.Lopez, B. Abbadessa, S. Eisenstein, B. C. Cosman, S. L.Ramamoorthy, and L. A. Parry. General surgery trainingin the era of robotic surgery: a qualitative analysis of per-ceptions from resident and attending surgeons. SurgicalEndoscopy, Vol. 34, No. 4, pp. 1712–1721, April 2020.Epub 2019 Jul 8.
[14] Basant Agarwal and Namita Mittal. Optimal feature selec-tion for sentiment analysis. In Alexander Gelbukh, editor,Computational Linguistics and Intelligent Text Pro-cessing, pp. 13–24, Berlin, Heidelberg, 2013. SpringerBerlin Heidelberg.
[15] E. Ainley, C. Witwicki, A. Tallett, and C. Graham. Usingtwitter comments to understand people’s experiences ofuk health care during the covid-19 pandemic: Thematicand sentiment analysis. Journal of Medical InternetResearch, Vol. 23, No. 10, pp. 1–14, October 25 2021.
[16] E. L. Funnell, B. Spadaro, N. Martin-Key, T. Metcalfe, andS. Bahn. mhealth solutions for mental health screening anddiagnosis: A review of app user perspectives using sen-timent and thematic analysis. Frontiers in Psychiatry,Vol. 13, pp. 1–17, April 27 2022.
[17] Akinobu Lee and Tatsuya Kawahara. julius-speech/julius:Release 4.5, January 2019.
[18] Virginia Braun and Victoria Clarke. Using thematic analy-sis in psychology. Qualitative Research in Psychology,Vol. 3, No. 2, pp. 77–101, 2006.



A Appendix



A.1 Example comments for BotA

• Conversation behavior: Friendliness”I felt like I was not talking to a friend because it(robot) did not have a personal opinion.”
[Par ticipant2, age range: 23, female]• Conversation ﬂow: Ending the conversation”It felt awkward to have to say goodbye and hello somany times at the end of a conversation.”
[Participant9, age: 24, female]• Conversation content: Knowledge depth”It (robot) touched on various topics, but I felt thecontent lacked depth.”
[Participant 5, age: 23, male]

A.2 Example comments for BotO

• Conversation behavior: Mistake correction”When I answered the question, I said somethingwrong but later corrected my mistake.
I was sur-prised at how well he understood.”
[Participant 19,age: 23, male]• Conversation ﬂow: Eﬀort in topic transition”It was diﬃcult to follow the progression of the con-versation, as the topic suddenly changed, making ithard to continue.”
[Participant 12, age: 22, male]• Conversation content: Knowledge depth”I was surprised when it (robot) started talking aboutinformation about travel destinations that were notwell-known.”
[Participant 15, age: 24, male]